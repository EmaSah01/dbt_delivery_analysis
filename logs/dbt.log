[0m11:39:00.930236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC6FC24980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC706DCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC70D17D90>]}


============================== 11:39:00.966587 | 62c1d1e8-b40c-4ef0-aca1-8a5916122bf2 ==============================
[0m11:39:00.966587 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:39:00.967622 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'logs'}
[0m11:39:00.989349 [info ] [MainThread]: dbt version: 1.10.15
[0m11:39:00.990021 [info ] [MainThread]: python version: 3.13.3
[0m11:39:00.990630 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m11:39:00.991464 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m11:39:01.131578 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m11:39:01.132669 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m11:39:01.133224 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m11:39:01.134550 [info ] [MainThread]: Configuration:
[0m11:39:01.135123 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m11:39:01.135651 [info ] [MainThread]:   dbt_project.yml file [[31mERROR invalid[0m]
[0m11:39:01.136107 [info ] [MainThread]: Required dependencies:
[0m11:39:01.136628 [debug] [MainThread]: Executing "git --help"
[0m11:39:03.703129 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:39:03.703774 [debug] [MainThread]: STDERR: "b''"
[0m11:39:03.704220 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:39:03.704788 [info ] [MainThread]: Connection test skipped since no profile was found
[0m11:39:03.705410 [info ] [MainThread]: [31m2 checks failed:[0m
[0m11:39:03.705908 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "dbt_delivery_analytics", target "dev" invalid: 1234 is not of type 'string'


[0m11:39:03.706633 [info ] [MainThread]: Project loading failed for the following reason:
Runtime Error
  dbt_project.yml does not parse to a dictionary


[0m11:39:03.707974 [debug] [MainThread]: Command `dbt debug` failed at 11:39:03.707831 after 2.98 seconds
[0m11:39:03.708388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC7231CE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC722F7410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC72222E00>]}
[0m11:39:03.708788 [debug] [MainThread]: Flushing usage events
[0m11:39:04.688852 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:40:45.613509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964E8C4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964F36CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964F9A7D90>]}


============================== 11:40:45.617854 | 6792b6b5-c5a5-4799-9309-15e2b3bbb402 ==============================
[0m11:40:45.617854 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:40:45.618602 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:40:45.638747 [info ] [MainThread]: dbt version: 1.10.15
[0m11:40:45.639445 [info ] [MainThread]: python version: 3.13.3
[0m11:40:45.639916 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m11:40:45.640406 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m11:40:45.728115 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m11:40:45.728802 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m11:40:45.729522 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m11:40:45.730907 [info ] [MainThread]: adapter type: postgres
[0m11:40:45.731431 [info ] [MainThread]: adapter version: 1.9.1
[0m11:40:45.839369 [info ] [MainThread]: Configuration:
[0m11:40:45.840080 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:40:45.840628 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:40:45.841177 [info ] [MainThread]: Required dependencies:
[0m11:40:45.841691 [debug] [MainThread]: Executing "git --help"
[0m11:40:46.110288 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:40:46.110956 [debug] [MainThread]: STDERR: "b''"
[0m11:40:46.111375 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:40:46.111861 [info ] [MainThread]: Connection:
[0m11:40:46.112413 [info ] [MainThread]:   host: localhost
[0m11:40:46.112986 [info ] [MainThread]:   port: 5433
[0m11:40:46.113392 [info ] [MainThread]:   user: postgres
[0m11:40:46.113874 [info ] [MainThread]:   database: delivery_analytics
[0m11:40:46.114323 [info ] [MainThread]:   schema: analytics
[0m11:40:46.114746 [info ] [MainThread]:   connect_timeout: 10
[0m11:40:46.115297 [info ] [MainThread]:   role: None
[0m11:40:46.115786 [info ] [MainThread]:   search_path: None
[0m11:40:46.116251 [info ] [MainThread]:   keepalives_idle: 0
[0m11:40:46.116754 [info ] [MainThread]:   sslmode: None
[0m11:40:46.117246 [info ] [MainThread]:   sslcert: None
[0m11:40:46.117813 [info ] [MainThread]:   sslkey: None
[0m11:40:46.118360 [info ] [MainThread]:   sslrootcert: None
[0m11:40:46.118858 [info ] [MainThread]:   application_name: dbt
[0m11:40:46.119332 [info ] [MainThread]:   retries: 1
[0m11:40:46.120321 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:40:46.474860 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m11:40:46.593480 [debug] [MainThread]: Using postgres connection "debug"
[0m11:40:46.593925 [debug] [MainThread]: On debug: select 1 as id
[0m11:40:46.594209 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:40:46.740773 [debug] [MainThread]: SQL status: SELECT 1 in 0.146 seconds
[0m11:40:46.741971 [debug] [MainThread]: On debug: Close
[0m11:40:46.742429 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:40:46.743087 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:40:46.744658 [debug] [MainThread]: Command `dbt debug` succeeded at 11:40:46.744510 after 1.37 seconds
[0m11:40:46.745099 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:40:46.745892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019650FC2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196510996D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964FAA7CE0>]}
[0m11:40:46.746531 [debug] [MainThread]: Flushing usage events
[0m11:40:47.689720 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:45:57.529102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002260FD34980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226107ECB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610E27D90>]}


============================== 11:45:57.535392 | 304ef73a-6129-45b7-9ed8-d675138210ca ==============================
[0m11:45:57.535392 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:45:57.536426 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select staging', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:45:57.887994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '304ef73a-6129-45b7-9ed8-d675138210ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610198770>]}
[0m11:45:57.983603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '304ef73a-6129-45b7-9ed8-d675138210ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610CCEE00>]}
[0m11:45:57.984754 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:45:58.500227 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:45:58.501608 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:45:58.502232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '304ef73a-6129-45b7-9ed8-d675138210ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610F39850>]}
[0m11:46:00.223659 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:46:00.225936 [debug] [MainThread]: Command `dbt run` failed at 11:46:00.225764 after 2.91 seconds
[0m11:46:00.226577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226126597C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022612659310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610E2FE70>]}
[0m11:46:00.227160 [debug] [MainThread]: Flushing usage events
[0m11:46:01.344658 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:46:07.344705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B4940980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B53ECB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B5A37D90>]}


============================== 11:46:07.349543 | 456eaf34-f993-4609-91fe-da358f7a28a0 ==============================
[0m11:46:07.349543 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:46:07.350464 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select marts.core', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:46:07.610603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '456eaf34-f993-4609-91fe-da358f7a28a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B4DA8770>]}
[0m11:46:07.687838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '456eaf34-f993-4609-91fe-da358f7a28a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B58DEE00>]}
[0m11:46:07.689286 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:46:08.119298 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:46:08.121016 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:46:08.121747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '456eaf34-f993-4609-91fe-da358f7a28a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B6E69850>]}
[0m11:46:09.406988 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:46:09.408722 [debug] [MainThread]: Command `dbt run` failed at 11:46:09.408554 after 2.25 seconds
[0m11:46:09.409208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B72397C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B7239310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B5A3FE70>]}
[0m11:46:09.409665 [debug] [MainThread]: Flushing usage events
[0m11:46:10.347604 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:49:25.797287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD974A0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD97F4CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD98597D90>]}


============================== 11:49:25.803045 | f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc ==============================
[0m11:49:25.803045 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:49:25.804440 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:49:26.083893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD97908770>]}
[0m11:49:26.167721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD9843EE00>]}
[0m11:49:26.169330 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:49:26.619007 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:49:26.620390 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:49:26.621130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD99A49850>]}
[0m11:49:27.946544 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:49:27.948888 [debug] [MainThread]: Command `dbt run` failed at 11:49:27.948681 after 2.47 seconds
[0m11:49:27.949408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD99E197C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD99E19310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD9859FE70>]}
[0m11:49:27.949979 [debug] [MainThread]: Flushing usage events
[0m11:49:29.053301 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:51:34.783279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADAF00980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADB9ACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADBFEBD90>]}


============================== 11:51:34.788081 | 8e67c9ca-5b38-4a02-9e9c-d922793088d9 ==============================
[0m11:51:34.788081 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:51:34.788980 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:51:35.045404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e67c9ca-5b38-4a02-9e9c-d922793088d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADB368770>]}
[0m11:51:35.117685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e67c9ca-5b38-4a02-9e9c-d922793088d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADBE8EE00>]}
[0m11:51:35.119027 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:51:35.515165 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:51:35.517142 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:51:35.518348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8e67c9ca-5b38-4a02-9e9c-d922793088d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADD0C9850>]}
[0m11:51:36.653875 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:51:36.655459 [debug] [MainThread]: Command `dbt run` failed at 11:51:36.655315 after 2.13 seconds
[0m11:51:36.655868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADD8497C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADD849310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADBFEFE70>]}
[0m11:51:36.656269 [debug] [MainThread]: Flushing usage events
[0m11:51:37.699693 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:13.945713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656AE80980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656B92CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656BF7BD90>]}


============================== 12:25:13.953709 | e27b91c9-2c9c-45d2-b30c-7c9cd64b1605 ==============================
[0m12:25:13.953709 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:25:13.955705 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select marts.core', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:25:14.319441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e27b91c9-2c9c-45d2-b30c-7c9cd64b1605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656B2E8770>]}
[0m12:25:14.404468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e27b91c9-2c9c-45d2-b30c-7c9cd64b1605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656BE1EE00>]}
[0m12:25:14.406300 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:25:14.944330 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:25:14.945724 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:25:14.946595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e27b91c9-2c9c-45d2-b30c-7c9cd64b1605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656D429850>]}
[0m12:25:16.241544 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m12:25:16.243595 [debug] [MainThread]: Command `dbt run` failed at 12:25:16.243399 after 2.62 seconds
[0m12:25:16.244133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656D7F97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656D7F9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656BF7FE70>]}
[0m12:25:16.244609 [debug] [MainThread]: Flushing usage events
[0m12:25:17.368044 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:32.430866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3B2A4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3BD4CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3C397D90>]}


============================== 12:26:32.438699 | 39d1507c-397f-4c93-b6a3-7efef8d16296 ==============================
[0m12:26:32.438699 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:26:32.440034 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:26:32.478658 [info ] [MainThread]: dbt version: 1.10.15
[0m12:26:32.479901 [info ] [MainThread]: python version: 3.13.3
[0m12:26:32.480938 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m12:26:32.481822 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m12:26:32.638699 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m12:26:32.639633 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m12:26:32.640373 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m12:26:32.641965 [info ] [MainThread]: adapter type: postgres
[0m12:26:32.642520 [info ] [MainThread]: adapter version: 1.9.1
[0m12:26:32.843454 [info ] [MainThread]: Configuration:
[0m12:26:32.844470 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:26:32.845177 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:26:32.845858 [info ] [MainThread]: Required dependencies:
[0m12:26:32.846531 [debug] [MainThread]: Executing "git --help"
[0m12:26:33.525081 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:26:33.525803 [debug] [MainThread]: STDERR: "b''"
[0m12:26:33.526321 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:26:33.527039 [info ] [MainThread]: Connection:
[0m12:26:33.527826 [info ] [MainThread]:   host: localhost
[0m12:26:33.528500 [info ] [MainThread]:   port: 5433
[0m12:26:33.529141 [info ] [MainThread]:   user: postgres
[0m12:26:33.529813 [info ] [MainThread]:   database: delivery_analytics
[0m12:26:33.530485 [info ] [MainThread]:   schema: analytics
[0m12:26:33.531163 [info ] [MainThread]:   connect_timeout: 10
[0m12:26:33.532000 [info ] [MainThread]:   role: None
[0m12:26:33.532879 [info ] [MainThread]:   search_path: None
[0m12:26:33.533646 [info ] [MainThread]:   keepalives_idle: 0
[0m12:26:33.534247 [info ] [MainThread]:   sslmode: None
[0m12:26:33.534993 [info ] [MainThread]:   sslcert: None
[0m12:26:33.535836 [info ] [MainThread]:   sslkey: None
[0m12:26:33.536561 [info ] [MainThread]:   sslrootcert: None
[0m12:26:33.537406 [info ] [MainThread]:   application_name: dbt
[0m12:26:33.538007 [info ] [MainThread]:   retries: 1
[0m12:26:33.539275 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:26:34.131814 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m12:26:34.299492 [debug] [MainThread]: Using postgres connection "debug"
[0m12:26:34.300085 [debug] [MainThread]: On debug: select 1 as id
[0m12:26:34.300453 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:34.463907 [debug] [MainThread]: SQL status: SELECT 1 in 0.163 seconds
[0m12:26:34.465223 [debug] [MainThread]: On debug: Close
[0m12:26:34.465919 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:26:34.466881 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:26:34.468975 [debug] [MainThread]: Command `dbt debug` succeeded at 12:26:34.468786 after 2.26 seconds
[0m12:26:34.469692 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:26:34.470253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3D9B2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3DA896D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3C4B7CE0>]}
[0m12:26:34.470909 [debug] [MainThread]: Flushing usage events
[0m12:26:35.630461 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:41.714321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F7830980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F82DCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F8927D90>]}


============================== 12:26:41.719601 | 206981eb-d5a2-470f-9ca0-997803c9a5af ==============================
[0m12:26:41.719601 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:26:41.720723 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt source freshness', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:26:41.972655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '206981eb-d5a2-470f-9ca0-997803c9a5af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F7C98770>]}
[0m12:26:42.034752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '206981eb-d5a2-470f-9ca0-997803c9a5af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F87CEE00>]}
[0m12:26:42.036326 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:26:42.466553 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:26:42.467999 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:26:42.468762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '206981eb-d5a2-470f-9ca0-997803c9a5af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F9D79850>]}
[0m12:26:43.491770 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m12:26:43.493751 [debug] [MainThread]: Command `dbt source freshness` failed at 12:26:43.493526 after 1.95 seconds
[0m12:26:43.494553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194FA14E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194FA14C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F892CC90>]}
[0m12:26:43.495177 [debug] [MainThread]: Flushing usage events
[0m12:26:44.485942 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:28:40.348471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808CC18980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808D6BCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808DD07D90>]}


============================== 12:28:40.354458 | f7484a1b-bd5e-4e88-9730-d75ccb13b435 ==============================
[0m12:28:40.354458 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:28:40.355792 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt clean', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:28:40.553399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7484a1b-bd5e-4e88-9730-d75ccb13b435', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808D078770>]}
[0m12:28:40.593118 [debug] [MainThread]: Command `dbt clean` succeeded at 12:28:40.592927 after 0.55 seconds
[0m12:28:40.593799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808DBAFCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808DBAF680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808F24E150>]}
[0m12:28:40.594448 [debug] [MainThread]: Flushing usage events
[0m12:28:41.781598 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:28:46.631466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E882474980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E882F2CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E88356BD90>]}


============================== 12:28:46.638381 | ac79a14b-6f4c-4e4b-9c3d-479766383284 ==============================
[0m12:28:46.638381 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:28:46.639401 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt deps', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:28:46.839355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac79a14b-6f4c-4e4b-9c3d-479766383284', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8828D8770>]}
[0m12:28:46.878718 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:28:46.880622 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:28:46.882388 [debug] [MainThread]: Command `dbt deps` succeeded at 12:28:46.882239 after 0.44 seconds
[0m12:28:46.882783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E88340FF00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E88340F130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8833EBA50>]}
[0m12:28:46.883231 [debug] [MainThread]: Flushing usage events
[0m12:28:47.953216 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:28:53.811007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7394C4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A739F6CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73A5A7D90>]}


============================== 12:28:53.816491 | 66bf7b68-0b76-4869-ba0d-b62d167617bf ==============================
[0m12:28:53.816491 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:28:53.818059 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:28:53.847771 [info ] [MainThread]: dbt version: 1.10.15
[0m12:28:53.848690 [info ] [MainThread]: python version: 3.13.3
[0m12:28:53.849715 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m12:28:53.850531 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m12:28:53.964537 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m12:28:53.965436 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m12:28:53.966010 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m12:28:53.967664 [info ] [MainThread]: adapter type: postgres
[0m12:28:53.968164 [info ] [MainThread]: adapter version: 1.9.1
[0m12:28:54.093236 [info ] [MainThread]: Configuration:
[0m12:28:54.094398 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:28:54.094956 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:28:54.095560 [info ] [MainThread]: Required dependencies:
[0m12:28:54.096116 [debug] [MainThread]: Executing "git --help"
[0m12:28:54.365707 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:28:54.366230 [debug] [MainThread]: STDERR: "b''"
[0m12:28:54.366633 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:28:54.367156 [info ] [MainThread]: Connection:
[0m12:28:54.367711 [info ] [MainThread]:   host: localhost
[0m12:28:54.368142 [info ] [MainThread]:   port: 5433
[0m12:28:54.368645 [info ] [MainThread]:   user: postgres
[0m12:28:54.369172 [info ] [MainThread]:   database: delivery_analytics
[0m12:28:54.369774 [info ] [MainThread]:   schema: analytics
[0m12:28:54.370271 [info ] [MainThread]:   connect_timeout: 10
[0m12:28:54.370782 [info ] [MainThread]:   role: None
[0m12:28:54.371384 [info ] [MainThread]:   search_path: None
[0m12:28:54.371931 [info ] [MainThread]:   keepalives_idle: 0
[0m12:28:54.372447 [info ] [MainThread]:   sslmode: None
[0m12:28:54.372983 [info ] [MainThread]:   sslcert: None
[0m12:28:54.373493 [info ] [MainThread]:   sslkey: None
[0m12:28:54.374037 [info ] [MainThread]:   sslrootcert: None
[0m12:28:54.374492 [info ] [MainThread]:   application_name: dbt
[0m12:28:54.374898 [info ] [MainThread]:   retries: 1
[0m12:28:54.375649 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:28:54.983980 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m12:28:55.145396 [debug] [MainThread]: Using postgres connection "debug"
[0m12:28:55.145885 [debug] [MainThread]: On debug: select 1 as id
[0m12:28:55.146425 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:28:55.266956 [debug] [MainThread]: SQL status: SELECT 1 in 0.120 seconds
[0m12:28:55.268598 [debug] [MainThread]: On debug: Close
[0m12:28:55.269207 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:28:55.269968 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:28:55.271345 [debug] [MainThread]: Command `dbt debug` succeeded at 12:28:55.271219 after 1.66 seconds
[0m12:28:55.271710 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:28:55.272221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73BBC2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73BC996D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73B697CE0>]}
[0m12:28:55.272669 [debug] [MainThread]: Flushing usage events
[0m12:28:56.330253 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:01.173226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4014980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4ACCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A5107D90>]}


============================== 12:29:01.179714 | 510d9f84-dd19-4e84-91b1-7fb59660ef8e ==============================
[0m12:29:01.179714 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:29:01.180889 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt source freshness', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:29:01.507506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '510d9f84-dd19-4e84-91b1-7fb59660ef8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4478770>]}
[0m12:29:01.596227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '510d9f84-dd19-4e84-91b1-7fb59660ef8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4FAEE00>]}
[0m12:29:01.598300 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:29:02.119266 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:29:02.120522 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:29:02.121130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '510d9f84-dd19-4e84-91b1-7fb59660ef8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A61E9850>]}
[0m12:29:03.614967 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m12:29:03.616898 [debug] [MainThread]: Command `dbt source freshness` failed at 12:29:03.616730 after 2.63 seconds
[0m12:29:03.617573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A694E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A694C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A510CC90>]}
[0m12:29:03.618169 [debug] [MainThread]: Flushing usage events
[0m12:29:04.698742 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:43.436907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CDBA4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CE65CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CEC97D90>]}


============================== 12:29:43.443248 | c3b38175-532b-427a-b78a-048a8ca27261 ==============================
[0m12:29:43.443248 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:29:43.444218 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt source freshness', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:29:43.808394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c3b38175-532b-427a-b78a-048a8ca27261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CE008770>]}
[0m12:29:43.877786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c3b38175-532b-427a-b78a-048a8ca27261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CEB3EE00>]}
[0m12:29:43.879580 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:29:44.509449 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:29:44.511124 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:29:44.511827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c3b38175-532b-427a-b78a-048a8ca27261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CFD79850>]}
[0m12:29:45.904118 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:29:45.906140 [debug] [MainThread]: Command `dbt source freshness` failed at 12:29:45.905995 after 2.69 seconds
[0m12:29:45.906530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7D04EE7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7D04EC320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CEC9CC90>]}
[0m12:29:45.906914 [debug] [MainThread]: Flushing usage events
[0m12:29:47.057553 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:32:17.211920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FCE14980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FD8CCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FDF07D90>]}


============================== 12:32:17.218235 | 04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8 ==============================
[0m12:32:17.218235 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:32:17.219384 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt source freshness', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:32:17.578961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FD278770>]}
[0m12:32:17.684133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FDDAEE00>]}
[0m12:32:17.686041 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:32:18.498963 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:32:18.501007 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:32:18.501905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FF339850>]}
[0m12:32:19.815616 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:32:19.817689 [debug] [MainThread]: Command `dbt source freshness` failed at 12:32:19.817537 after 2.93 seconds
[0m12:32:19.818140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FF70E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FF70C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FDF0CC90>]}
[0m12:32:19.818705 [debug] [MainThread]: Flushing usage events
[0m12:32:20.802630 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:32:43.392183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CAFEC4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB096CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0FBBD90>]}


============================== 12:32:43.398902 | 3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35 ==============================
[0m12:32:43.398902 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:32:43.400377 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:32:43.692066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0328770>]}
[0m12:32:43.776225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0E5EE00>]}
[0m12:32:43.778111 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:32:44.312393 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:32:44.313928 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:32:44.314716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB10C9850>]}
[0m12:32:45.619926 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:32:45.621912 [debug] [MainThread]: Command `dbt run` failed at 12:32:45.621744 after 2.44 seconds
[0m12:32:45.622519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB28197C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB2819310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0FBFE70>]}
[0m12:32:45.623017 [debug] [MainThread]: Flushing usage events
[0m12:32:46.676640 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:33:47.779163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A775980980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A77643CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A776A77D90>]}


============================== 12:33:47.785470 | bbc386af-26db-4dc5-ba5c-870671bda6f2 ==============================
[0m12:33:47.785470 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:33:47.787000 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:33:48.109542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bbc386af-26db-4dc5-ba5c-870671bda6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A775DE8770>]}
[0m12:33:48.202185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bbc386af-26db-4dc5-ba5c-870671bda6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A77691EE00>]}
[0m12:33:48.215566 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:33:48.746932 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:33:48.748429 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:33:48.749206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bbc386af-26db-4dc5-ba5c-870671bda6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A777EA9850>]}
[0m12:33:49.953791 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:33:49.956007 [debug] [MainThread]: Command `dbt run` failed at 12:33:49.955811 after 2.42 seconds
[0m12:33:49.956552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A7782797C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A778279310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A776A7FE70>]}
[0m12:33:49.957027 [debug] [MainThread]: Flushing usage events
[0m12:33:51.023877 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:34:47.825257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D33FC4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D34A7CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D350B7D90>]}


============================== 12:34:47.831265 | 06ae78a2-7e82-47f5-b076-4414b39d6fda ==============================
[0m12:34:47.831265 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:34:47.832571 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:34:48.153118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06ae78a2-7e82-47f5-b076-4414b39d6fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D34428770>]}
[0m12:34:48.244423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06ae78a2-7e82-47f5-b076-4414b39d6fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D34F5EE00>]}
[0m12:34:48.246539 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:34:48.788128 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:34:48.790174 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:34:48.790863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '06ae78a2-7e82-47f5-b076-4414b39d6fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D364E9850>]}
[0m12:34:50.110402 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:34:50.112386 [debug] [MainThread]: Command `dbt run` failed at 12:34:50.112142 after 2.51 seconds
[0m12:34:50.112984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D368B97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D368B9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D350BFE70>]}
[0m12:34:50.113478 [debug] [MainThread]: Flushing usage events
[0m12:34:51.235923 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:15.057554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D30BF4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D3169CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D31CE7D90>]}


============================== 12:41:15.063480 | 6a9fc7d7-8416-4b99-9924-fe9ee1e7a41c ==============================
[0m12:41:15.063480 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:41:15.064657 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:41:15.104106 [info ] [MainThread]: dbt version: 1.10.15
[0m12:41:15.105184 [info ] [MainThread]: python version: 3.13.3
[0m12:41:15.105990 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m12:41:15.106800 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m12:41:15.212164 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m12:41:15.213274 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m12:41:15.214266 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m12:41:15.216017 [info ] [MainThread]: adapter type: postgres
[0m12:41:15.216840 [info ] [MainThread]: adapter version: 1.9.1
[0m12:41:15.360794 [info ] [MainThread]: Configuration:
[0m12:41:15.362047 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:41:15.362997 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:41:15.363828 [info ] [MainThread]: Required dependencies:
[0m12:41:15.364814 [debug] [MainThread]: Executing "git --help"
[0m12:41:15.641912 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:41:15.642926 [debug] [MainThread]: STDERR: "b''"
[0m12:41:15.643485 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:41:15.644309 [info ] [MainThread]: Connection:
[0m12:41:15.645184 [info ] [MainThread]:   host: localhost
[0m12:41:15.645957 [info ] [MainThread]:   port: 5433
[0m12:41:15.646725 [info ] [MainThread]:   user: postgres
[0m12:41:15.647547 [info ] [MainThread]:   database: delivery_analytics
[0m12:41:15.648341 [info ] [MainThread]:   schema: analytics
[0m12:41:15.649182 [info ] [MainThread]:   connect_timeout: 10
[0m12:41:15.649889 [info ] [MainThread]:   role: None
[0m12:41:15.650601 [info ] [MainThread]:   search_path: None
[0m12:41:15.651382 [info ] [MainThread]:   keepalives_idle: 0
[0m12:41:15.652059 [info ] [MainThread]:   sslmode: None
[0m12:41:15.652669 [info ] [MainThread]:   sslcert: None
[0m12:41:15.653355 [info ] [MainThread]:   sslkey: None
[0m12:41:15.653993 [info ] [MainThread]:   sslrootcert: None
[0m12:41:15.654650 [info ] [MainThread]:   application_name: dbt
[0m12:41:15.655305 [info ] [MainThread]:   retries: 1
[0m12:41:15.656534 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:41:16.212599 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m12:41:16.383368 [debug] [MainThread]: Using postgres connection "debug"
[0m12:41:16.383874 [debug] [MainThread]: On debug: select 1 as id
[0m12:41:16.384257 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:16.536812 [debug] [MainThread]: SQL status: SELECT 1 in 0.152 seconds
[0m12:41:16.538618 [debug] [MainThread]: On debug: Close
[0m12:41:16.539137 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:41:16.539973 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:41:16.542419 [debug] [MainThread]: Command `dbt debug` succeeded at 12:41:16.542263 after 1.80 seconds
[0m12:41:16.542847 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:41:16.543401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D33362B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D3343D6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D331C7CE0>]}
[0m12:41:16.544138 [debug] [MainThread]: Flushing usage events
[0m12:41:17.632073 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:23.461518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCBD94980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCC82CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCCE77D90>]}


============================== 12:41:23.466407 | d59166be-e54d-4ee4-b87e-a055730a2fea ==============================
[0m12:41:23.466407 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:41:23.467302 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:41:23.700430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd59166be-e54d-4ee4-b87e-a055730a2fea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCC1F8770>]}
[0m12:41:23.761943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd59166be-e54d-4ee4-b87e-a055730a2fea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCCD1EE00>]}
[0m12:41:23.763525 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:41:24.170871 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:41:24.172146 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:41:24.172901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd59166be-e54d-4ee4-b87e-a055730a2fea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCE329850>]}
[0m12:41:25.185511 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:41:25.187357 [debug] [MainThread]: Command `dbt run` failed at 12:41:25.187217 after 1.88 seconds
[0m12:41:25.187875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCE6F97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCE6F9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCCE7FE70>]}
[0m12:41:25.188377 [debug] [MainThread]: Flushing usage events
[0m12:41:26.177168 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:48:45.989927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E264880980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E26532CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E265977D90>]}


============================== 13:48:45.996954 | eab4d17c-c281-4435-9620-9b2f3506958a ==============================
[0m13:48:45.996954 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:48:45.998505 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt run --select staging', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:48:46.334626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eab4d17c-c281-4435-9620-9b2f3506958a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E264CE8770>]}
[0m13:48:46.427844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eab4d17c-c281-4435-9620-9b2f3506958a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E26581EE00>]}
[0m13:48:46.429863 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:48:46.918174 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:48:46.919439 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:48:46.920193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eab4d17c-c281-4435-9620-9b2f3506958a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E266DA9850>]}
[0m13:48:47.974368 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:48:47.976137 [debug] [MainThread]: Command `dbt run` failed at 13:48:47.975995 after 2.34 seconds
[0m13:48:47.976755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E2671797C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E267179310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E26597FE70>]}
[0m13:48:47.977263 [debug] [MainThread]: Flushing usage events
[0m13:48:49.115236 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:54.810474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE88AC4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8957CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE89BB7D90>]}


============================== 13:49:54.816816 | 82b47af0-44e4-4b74-9b8a-34ebcea07274 ==============================
[0m13:49:54.816816 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:49:54.818188 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:49:55.112730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '82b47af0-44e4-4b74-9b8a-34ebcea07274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE88F28770>]}
[0m13:49:55.195988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '82b47af0-44e4-4b74-9b8a-34ebcea07274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE89A5EE00>]}
[0m13:49:55.197738 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:49:55.716590 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:49:55.717940 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:49:55.718554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '82b47af0-44e4-4b74-9b8a-34ebcea07274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8B0C9850>]}
[0m13:49:56.720365 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:49:56.722062 [debug] [MainThread]: Command `dbt run` failed at 13:49:56.721897 after 2.13 seconds
[0m13:49:56.722526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8B4997C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8B499310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE89BBFE70>]}
[0m13:49:56.722981 [debug] [MainThread]: Flushing usage events
[0m13:49:57.676580 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:51:33.046019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF1894980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF233CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF2987D90>]}


============================== 13:51:33.055917 | f56b7041-1bf1-4990-bcee-a42b428e736c ==============================
[0m13:51:33.055917 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:51:33.057332 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt source snapshot-freshness', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:51:33.361417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f56b7041-1bf1-4990-bcee-a42b428e736c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF1CF8770>]}
[0m13:51:33.453758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f56b7041-1bf1-4990-bcee-a42b428e736c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF282EE00>]}
[0m13:51:33.455809 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:51:34.018295 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:51:34.020003 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:51:34.020737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f56b7041-1bf1-4990-bcee-a42b428e736c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF3DE9850>]}
[0m13:51:35.339146 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:51:35.341299 [debug] [MainThread]: Command `dbt source snapshot-freshness` failed at 13:51:35.341119 after 2.64 seconds
[0m13:51:35.341813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF41C27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF41C0320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF298CC90>]}
[0m13:51:35.342289 [debug] [MainThread]: Flushing usage events
[0m13:51:36.452829 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:52:36.733388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89B884980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C32CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C977D90>]}


============================== 13:52:36.739291 | 13bacde7-4be0-4c46-8239-2cef1b15bbf2 ==============================
[0m13:52:36.739291 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:52:36.740677 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt source snapshot-freshness', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:52:37.072612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13bacde7-4be0-4c46-8239-2cef1b15bbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89BCE8770>]}
[0m13:52:37.165681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13bacde7-4be0-4c46-8239-2cef1b15bbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C81EE00>]}
[0m13:52:37.169662 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:52:37.860194 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:52:37.862299 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:52:37.863557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '13bacde7-4be0-4c46-8239-2cef1b15bbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89CE89850>]}
[0m13:52:39.121764 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:52:39.124241 [debug] [MainThread]: Command `dbt source snapshot-freshness` failed at 13:52:39.124035 after 2.64 seconds
[0m13:52:39.124659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89E22E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89E22C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C97CC90>]}
[0m13:52:39.125097 [debug] [MainThread]: Flushing usage events
[0m13:52:40.117248 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:54:16.446804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231CFC70980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D072CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D0D6BD90>]}


============================== 13:54:16.453166 | a52d5d50-ef11-43c7-845d-4cc643cbd88b ==============================
[0m13:54:16.453166 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:54:16.454622 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt ls --resource-type source', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:54:16.777828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a52d5d50-ef11-43c7-845d-4cc643cbd88b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D00D8770>]}
[0m13:54:16.860476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a52d5d50-ef11-43c7-845d-4cc643cbd88b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D0C0EF10>]}
[0m13:54:16.862484 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:54:17.407856 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:54:17.409571 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:54:17.410570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a52d5d50-ef11-43c7-845d-4cc643cbd88b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D2199850>]}
[0m13:54:18.738653 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:54:18.740619 [debug] [MainThread]: Command `dbt ls` failed at 13:54:18.740448 after 2.59 seconds
[0m13:54:18.741137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D256A6C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D2568230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D0D6FE70>]}
[0m13:54:18.741614 [debug] [MainThread]: Flushing usage events
[0m13:54:19.817483 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:04.046895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A335714980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A3361ACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A3367F7D90>]}


============================== 13:57:04.051819 | 5b818468-9b15-4aac-b0a2-e216a692e801 ==============================
[0m13:57:04.051819 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:04.052819 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt clean', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:04.243329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b818468-9b15-4aac-b0a2-e216a692e801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A335B78770>]}
[0m13:57:04.276209 [debug] [MainThread]: Command `dbt clean` succeeded at 13:57:04.276056 after 0.47 seconds
[0m13:57:04.276813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A33669FCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A33669F680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A337D0E150>]}
[0m13:57:04.277326 [debug] [MainThread]: Flushing usage events
[0m13:57:05.455994 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:11.222256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAA9C0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB46CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FABABBD90>]}


============================== 13:57:11.227188 | 260b6779-cc26-4336-8a0f-1de9215a560f ==============================
[0m13:57:11.227188 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:11.228341 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt deps', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:11.437840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '260b6779-cc26-4336-8a0f-1de9215a560f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAAE28770>]}
[0m13:57:11.487684 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:57:11.492598 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:57:11.494860 [debug] [MainThread]: Command `dbt deps` succeeded at 13:57:11.494551 after 0.47 seconds
[0m13:57:11.495415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB95FF00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB95F130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB93BA50>]}
[0m13:57:11.495952 [debug] [MainThread]: Flushing usage events
[0m13:57:12.584064 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:20.222982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDD564980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDE00CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDE65BD90>]}


============================== 13:57:20.228038 | 40f9d7f2-ef3c-4999-8037-11105efa282a ==============================
[0m13:57:20.228038 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:20.228873 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:20.260163 [info ] [MainThread]: dbt version: 1.10.15
[0m13:57:20.260902 [info ] [MainThread]: python version: 3.13.3
[0m13:57:20.261427 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m13:57:20.261951 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m13:57:20.387320 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m13:57:20.387928 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m13:57:20.388480 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m13:57:20.390485 [info ] [MainThread]: adapter type: postgres
[0m13:57:20.391142 [info ] [MainThread]: adapter version: 1.9.1
[0m13:57:20.526169 [info ] [MainThread]: Configuration:
[0m13:57:20.527030 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:57:20.527678 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:57:20.528215 [info ] [MainThread]: Required dependencies:
[0m13:57:20.528831 [debug] [MainThread]: Executing "git --help"
[0m13:57:21.285089 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:57:21.285940 [debug] [MainThread]: STDERR: "b''"
[0m13:57:21.286649 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:57:21.287509 [info ] [MainThread]: Connection:
[0m13:57:21.288160 [info ] [MainThread]:   host: localhost
[0m13:57:21.289052 [info ] [MainThread]:   port: 5433
[0m13:57:21.289582 [info ] [MainThread]:   user: postgres
[0m13:57:21.290293 [info ] [MainThread]:   database: delivery_analytics
[0m13:57:21.290867 [info ] [MainThread]:   schema: analytics
[0m13:57:21.291478 [info ] [MainThread]:   connect_timeout: 10
[0m13:57:21.292082 [info ] [MainThread]:   role: None
[0m13:57:21.292634 [info ] [MainThread]:   search_path: None
[0m13:57:21.293177 [info ] [MainThread]:   keepalives_idle: 0
[0m13:57:21.293725 [info ] [MainThread]:   sslmode: None
[0m13:57:21.294257 [info ] [MainThread]:   sslcert: None
[0m13:57:21.294888 [info ] [MainThread]:   sslkey: None
[0m13:57:21.295435 [info ] [MainThread]:   sslrootcert: None
[0m13:57:21.295925 [info ] [MainThread]:   application_name: dbt
[0m13:57:21.296612 [info ] [MainThread]:   retries: 1
[0m13:57:21.297703 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:57:21.904178 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m13:57:22.097544 [debug] [MainThread]: Using postgres connection "debug"
[0m13:57:22.098152 [debug] [MainThread]: On debug: select 1 as id
[0m13:57:22.098640 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:57:22.211902 [debug] [MainThread]: SQL status: SELECT 1 in 0.113 seconds
[0m13:57:22.213001 [debug] [MainThread]: On debug: Close
[0m13:57:22.213468 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:57:22.214196 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:57:22.215877 [debug] [MainThread]: Command `dbt debug` succeeded at 13:57:22.215687 after 2.19 seconds
[0m13:57:22.216323 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:57:22.216799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDFC32B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDFD096D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDFA97CE0>]}
[0m13:57:22.217201 [debug] [MainThread]: Flushing usage events
[0m13:57:23.267990 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:28.672770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CB890980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC33CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC987D90>]}


============================== 13:57:28.679211 | 058f2b60-19b5-41da-90bc-1f25f9c87593 ==============================
[0m13:57:28.679211 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:28.680257 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt ls --resource-type source', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:28.960676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CBCF8770>]}
[0m13:57:29.039757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC82EF10>]}
[0m13:57:29.041232 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:57:29.575926 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:57:29.577064 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:57:29.577667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CDE09850>]}
[0m13:57:31.059273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC9E3D40>]}
[0m13:57:31.138140 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:57:31.163498 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:57:31.203161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CDF38E50>]}
[0m13:57:31.203679 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:57:31.204341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CDE91230>]}
[0m13:57:31.205643 [info ] [MainThread]: source:dbt_delivery_analytics.raw.courier_assignments
[0m13:57:31.206249 [info ] [MainThread]: source:dbt_delivery_analytics.raw.couriers
[0m13:57:31.206780 [info ] [MainThread]: source:dbt_delivery_analytics.raw.shipment_status
[0m13:57:31.207335 [info ] [MainThread]: source:dbt_delivery_analytics.raw.shipments
[0m13:57:31.207965 [info ] [MainThread]: source:dbt_delivery_analytics.raw.users
[0m13:57:31.209301 [debug] [MainThread]: Command `dbt ls` succeeded at 13:57:31.209178 after 2.72 seconds
[0m13:57:31.209683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC753590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CE4628E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CE462990>]}
[0m13:57:31.210031 [debug] [MainThread]: Flushing usage events
[0m13:57:32.283618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:58:18.188041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C965688980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96612CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96677BD90>]}


============================== 13:58:18.192993 | a785f218-1083-4e43-92cc-02925959720b ==============================
[0m13:58:18.192993 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:58:18.193995 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:58:18.526805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C965AE8770>]}
[0m13:58:18.610808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96661EE00>]}
[0m13:58:18.612517 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:58:19.061958 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:58:19.268221 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:58:19.268954 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:58:19.338857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9680A4150>]}
[0m13:58:19.449986 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:19.455687 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:19.500629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96660FD40>]}
[0m13:58:19.501449 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:58:19.502147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C966C77310>]}
[0m13:58:19.505503 [info ] [MainThread]: 
[0m13:58:19.506328 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:58:19.506986 [info ] [MainThread]: 
[0m13:58:19.507980 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:58:19.514989 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m13:58:19.706212 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m13:58:19.706814 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:58:19.707240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:19.868681 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.161 seconds
[0m13:58:19.870961 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m13:58:19.872409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_delivery_analytics, now create_delivery_analytics_analytics)
[0m13:58:19.873242 [debug] [ThreadPool]: Creating schema "database: "delivery_analytics"
schema: "analytics"
"
[0m13:58:19.880923 [debug] [ThreadPool]: Using postgres connection "create_delivery_analytics_analytics"
[0m13:58:19.881497 [debug] [ThreadPool]: On create_delivery_analytics_analytics: BEGIN
[0m13:58:19.881851 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:58:19.977932 [debug] [ThreadPool]: SQL status: BEGIN in 0.096 seconds
[0m13:58:19.978617 [debug] [ThreadPool]: Using postgres connection "create_delivery_analytics_analytics"
[0m13:58:19.979093 [debug] [ThreadPool]: On create_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "create_delivery_analytics_analytics"} */
create schema if not exists "analytics"
[0m13:58:19.980799 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m13:58:19.982415 [debug] [ThreadPool]: On create_delivery_analytics_analytics: COMMIT
[0m13:58:19.982956 [debug] [ThreadPool]: Using postgres connection "create_delivery_analytics_analytics"
[0m13:58:19.983443 [debug] [ThreadPool]: On create_delivery_analytics_analytics: COMMIT
[0m13:58:19.985185 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m13:58:19.985636 [debug] [ThreadPool]: On create_delivery_analytics_analytics: Close
[0m13:58:19.989765 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m13:58:19.999439 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:20.000227 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m13:58:20.000785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:20.086487 [debug] [ThreadPool]: SQL status: BEGIN in 0.086 seconds
[0m13:58:20.087327 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:20.087884 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:58:20.101234 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.013 seconds
[0m13:58:20.103145 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m13:58:20.104569 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m13:58:20.113412 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.114081 [debug] [MainThread]: On master: BEGIN
[0m13:58:20.114577 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:58:20.190380 [debug] [MainThread]: SQL status: BEGIN in 0.076 seconds
[0m13:58:20.191037 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.191642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m13:58:20.203827 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m13:58:20.205955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9684C8600>]}
[0m13:58:20.206617 [debug] [MainThread]: On master: ROLLBACK
[0m13:58:20.207416 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.207844 [debug] [MainThread]: On master: BEGIN
[0m13:58:20.208677 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:58:20.209077 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.209420 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.209744 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.210260 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:20.210570 [debug] [MainThread]: On master: Close
[0m13:58:20.217908 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.218644 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.219227 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.219755 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.220489 [info ] [Thread-2 (]: 2 of 8 START sql view model analytics.stg_couriers ............................. [RUN]
[0m13:58:20.221159 [info ] [Thread-1 (]: 1 of 8 START sql view model analytics.stg_courier_assigments ................... [RUN]
[0m13:58:20.223394 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_couriers'
[0m13:58:20.221971 [info ] [Thread-3 (]: 3 of 8 START sql view model analytics.stg_shipment_status ...................... [RUN]
[0m13:58:20.224342 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_courier_assigments'
[0m13:58:20.222723 [info ] [Thread-4 (]: 4 of 8 START sql view model analytics.stg_shipments ............................ [RUN]
[0m13:58:20.225009 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.225778 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipment_status'
[0m13:58:20.226494 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.227110 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipments'
[0m13:58:20.234478 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.235142 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.238652 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.239242 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.242517 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.245746 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.251972 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.252504 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.253308 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.288065 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.307292 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.310490 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.314519 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.317659 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.325295 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.326099 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.326747 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: BEGIN
[0m13:58:20.327332 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: BEGIN
[0m13:58:20.327927 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.328414 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.328988 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:58:20.329472 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:58:20.330002 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: BEGIN
[0m13:58:20.330564 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: BEGIN
[0m13:58:20.331498 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:58:20.332002 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:58:20.409807 [debug] [Thread-2 (]: SQL status: BEGIN in 0.080 seconds
[0m13:58:20.410637 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.411228 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */

  create view "delivery_analytics"."analytics"."stg_couriers__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."couriers"
)

select
    courier_id,
    user_id,
    vehicle_type,
    city
from source;
  );
[0m13:58:20.414126 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 17: from source;
                    ^

[0m13:58:20.414837 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: ROLLBACK
[0m13:58:20.415799 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: Close
[0m13:58:20.431106 [debug] [Thread-2 (]: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:20.431881 [debug] [Thread-1 (]: SQL status: BEGIN in 0.103 seconds
[0m13:58:20.433834 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.434546 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */

  create view "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    assignment_id,
    courier_id,
    shipment_id,
    assigned_at,
    delivered_at
from source;
  );
[0m13:58:20.435924 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:20.436630 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C968116A50>]}
[0m13:58:20.437214 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: ROLLBACK
[0m13:58:20.438179 [error] [Thread-2 (]: 2 of 8 ERROR creating sql view model analytics.stg_couriers .................... [[31mERROR[0m in 0.21s]
[0m13:58:20.439230 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.439851 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: Close
[0m13:58:20.440481 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_users
[0m13:58:20.441179 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_couriers' to be skipped because of status 'error'.  Reason: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql.
[0m13:58:20.441957 [info ] [Thread-2 (]: 5 of 8 START sql view model analytics.stg_users ................................ [RUN]
[0m13:58:20.444761 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.stg_couriers, now model.dbt_delivery_analytics.stg_users)
[0m13:58:20.445429 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_users
[0m13:58:20.449511 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.451287 [debug] [Thread-3 (]: SQL status: BEGIN in 0.120 seconds
[0m13:58:20.451832 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.452833 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */

  create view "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipment_status"
)

select
    shipment_status_id,
    shipment_id,
    status,
    status_timestamp,
    courier_id
from source;
  );
[0m13:58:20.456767 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:20.457559 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_users
[0m13:58:20.458651 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: ROLLBACK
[0m13:58:20.459886 [debug] [Thread-1 (]: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:20.471291 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.472394 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9681322B0>]}
[0m13:58:20.472979 [debug] [Thread-4 (]: SQL status: BEGIN in 0.141 seconds
[0m13:58:20.473567 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: Close
[0m13:58:20.474958 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.474475 [error] [Thread-1 (]: 1 of 8 ERROR creating sql view model analytics.stg_courier_assigments .......... [[31mERROR[0m in 0.25s]
[0m13:58:20.475906 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */

  create view "delivery_analytics"."analytics"."stg_shipments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipments"
)

select
    shipment_id,
    sender_id,
    receiver_id,
    shipment_date,
    expected_delivery_date,
    price
from source;
  );
[0m13:58:20.477992 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.478632 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.479753 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_courier_assigments' to be skipped because of status 'error'.  Reason: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql.
[0m13:58:20.480313 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: from source;
                    ^

[0m13:58:20.480802 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: BEGIN
[0m13:58:20.481594 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: ROLLBACK
[0m13:58:20.482164 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:58:20.483145 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: Close
[0m13:58:20.489565 [debug] [Thread-3 (]: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:20.490730 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9683DA990>]}
[0m13:58:20.491967 [error] [Thread-3 (]: 3 of 8 ERROR creating sql view model analytics.stg_shipment_status ............. [[31mERROR[0m in 0.26s]
[0m13:58:20.493099 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.493884 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipment_status' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql.
[0m13:58:20.498758 [debug] [Thread-4 (]: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:20.499648 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9683F5850>]}
[0m13:58:20.500751 [error] [Thread-4 (]: 4 of 8 ERROR creating sql view model analytics.stg_shipments ................... [[31mERROR[0m in 0.27s]
[0m13:58:20.502022 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.502726 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipments' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql.
[0m13:58:20.503562 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.dim_dates
[0m13:58:20.504172 [info ] [Thread-1 (]: 6 of 8 SKIP relation analytics.dim_dates ....................................... [[33mSKIP[0m]
[0m13:58:20.504961 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.dim_dates
[0m13:58:20.608113 [debug] [Thread-2 (]: SQL status: BEGIN in 0.126 seconds
[0m13:58:20.608735 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.609178 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */

  create view "delivery_analytics"."analytics"."stg_users__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from source;
  );
[0m13:58:20.610022 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:20.610529 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: ROLLBACK
[0m13:58:20.611283 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: Close
[0m13:58:20.618241 [debug] [Thread-2 (]: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:20.618905 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C968526B30>]}
[0m13:58:20.619616 [error] [Thread-2 (]: 5 of 8 ERROR creating sql view model analytics.stg_users ....................... [[31mERROR[0m in 0.17s]
[0m13:58:20.620388 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_users
[0m13:58:20.621050 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_users' to be skipped because of status 'error'.  Reason: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql.
[0m13:58:20.622009 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.dim_users
[0m13:58:20.623078 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.dim_couriers
[0m13:58:20.622515 [info ] [Thread-4 (]: 8 of 8 SKIP relation analytics.dim_users ....................................... [[33mSKIP[0m]
[0m13:58:20.624428 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.dim_users
[0m13:58:20.623812 [info ] [Thread-3 (]: 7 of 8 SKIP relation analytics.dim_couriers .................................... [[33mSKIP[0m]
[0m13:58:20.625340 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.dim_couriers
[0m13:58:20.627099 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.627561 [debug] [MainThread]: On master: BEGIN
[0m13:58:20.627847 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:58:20.735795 [debug] [MainThread]: SQL status: BEGIN in 0.108 seconds
[0m13:58:20.736264 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.736566 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.736834 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.737268 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:20.737573 [debug] [MainThread]: On master: Close
[0m13:58:20.738115 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:58:20.738532 [debug] [MainThread]: Connection 'create_delivery_analytics_analytics' was properly closed.
[0m13:58:20.738805 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m13:58:20.739277 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_users' was properly closed.
[0m13:58:20.739674 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_courier_assigments' was properly closed.
[0m13:58:20.740142 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipment_status' was properly closed.
[0m13:58:20.740505 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipments' was properly closed.
[0m13:58:20.741029 [info ] [MainThread]: 
[0m13:58:20.741813 [info ] [MainThread]: Finished running 3 table models, 5 view models in 0 hours 0 minutes and 1.23 seconds (1.23s).
[0m13:58:20.743408 [debug] [MainThread]: Command end result
[0m13:58:20.857690 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:20.862329 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:20.870576 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m13:58:20.871305 [info ] [MainThread]: 
[0m13:58:20.872049 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m13:58:20.872576 [info ] [MainThread]: 
[0m13:58:20.873127 [error] [MainThread]: [31mFailure in model stg_couriers (models\staging\stg_couriers.sql)[0m
[0m13:58:20.873622 [error] [MainThread]:   Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:20.874172 [info ] [MainThread]: 
[0m13:58:20.874737 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:20.875202 [info ] [MainThread]: 
[0m13:58:20.875761 [error] [MainThread]: [31mFailure in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)[0m
[0m13:58:20.876304 [error] [MainThread]:   Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:20.876808 [info ] [MainThread]: 
[0m13:58:20.877449 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:20.877918 [info ] [MainThread]: 
[0m13:58:20.878551 [error] [MainThread]: [31mFailure in model stg_shipment_status (models\staging\stg_shipment_status.sql)[0m
[0m13:58:20.879279 [error] [MainThread]:   Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:20.879817 [info ] [MainThread]: 
[0m13:58:20.880432 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:20.880951 [info ] [MainThread]: 
[0m13:58:20.881600 [error] [MainThread]: [31mFailure in model stg_shipments (models\staging\stg_shipments.sql)[0m
[0m13:58:20.882303 [error] [MainThread]:   Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:20.882897 [info ] [MainThread]: 
[0m13:58:20.883530 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:20.884091 [info ] [MainThread]: 
[0m13:58:20.884709 [error] [MainThread]: [31mFailure in model stg_users (models\staging\stg_users.sql)[0m
[0m13:58:20.885822 [error] [MainThread]:   Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:20.886567 [info ] [MainThread]: 
[0m13:58:20.887334 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:20.888447 [info ] [MainThread]: 
[0m13:58:20.889064 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=3 NO-OP=0 TOTAL=8
[0m13:58:20.892089 [debug] [MainThread]: Command `dbt run` failed at 13:58:20.891765 after 2.90 seconds
[0m13:58:20.892802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9652E4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C965967470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C967CD7D10>]}
[0m13:58:20.893195 [debug] [MainThread]: Flushing usage events
[0m13:58:22.120898 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:58:31.637041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D490FF0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491A9CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4920E7D90>]}


============================== 13:58:31.642708 | f87eca52-3f68-4181-ac3e-923b893f22a7 ==============================
[0m13:58:31.642708 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:58:31.643445 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:58:31.875676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491458770>]}
[0m13:58:31.943564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491F8AE00>]}
[0m13:58:31.945160 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:58:32.386923 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:58:32.556928 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:58:32.557373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:58:32.614898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493A60150>]}
[0m13:58:32.692542 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:32.696474 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:32.728944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491F7FD40>]}
[0m13:58:32.729575 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:58:32.730074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D492277310>]}
[0m13:58:32.732210 [info ] [MainThread]: 
[0m13:58:32.732790 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:58:32.733325 [info ] [MainThread]: 
[0m13:58:32.733979 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:58:32.738210 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m13:58:32.885732 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m13:58:32.886198 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:58:32.886497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:32.992348 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.106 seconds
[0m13:58:32.993839 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m13:58:32.996661 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m13:58:33.002950 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:33.003431 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m13:58:33.003703 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:33.071623 [debug] [ThreadPool]: SQL status: BEGIN in 0.068 seconds
[0m13:58:33.072152 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:33.072518 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:58:33.082056 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.009 seconds
[0m13:58:33.083385 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m13:58:33.083885 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m13:58:33.089943 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.090436 [debug] [MainThread]: On master: BEGIN
[0m13:58:33.090798 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:58:33.178999 [debug] [MainThread]: SQL status: BEGIN in 0.088 seconds
[0m13:58:33.179599 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.180210 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m13:58:33.189700 [debug] [MainThread]: SQL status: SELECT 0 in 0.009 seconds
[0m13:58:33.191613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493C7BBA0>]}
[0m13:58:33.192328 [debug] [MainThread]: On master: ROLLBACK
[0m13:58:33.193066 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.193520 [debug] [MainThread]: On master: BEGIN
[0m13:58:33.194343 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:58:33.194778 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.195191 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.195579 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.196155 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:33.196605 [debug] [MainThread]: On master: Close
[0m13:58:33.202937 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.203534 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.207380 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.208763 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.209607 [info ] [Thread-1 (]: 1 of 5 START sql view model analytics.stg_courier_assigments ................... [RUN]
[0m13:58:33.210126 [info ] [Thread-4 (]: 4 of 5 START sql view model analytics.stg_shipments ............................ [RUN]
[0m13:58:33.212659 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipments'
[0m13:58:33.213125 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.212000 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_courier_assigments'
[0m13:58:33.225352 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.210709 [info ] [Thread-2 (]: 2 of 5 START sql view model analytics.stg_couriers ............................. [RUN]
[0m13:58:33.231153 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.211246 [info ] [Thread-3 (]: 3 of 5 START sql view model analytics.stg_shipment_status ...................... [RUN]
[0m13:58:33.232455 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_couriers'
[0m13:58:33.236730 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.237586 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipment_status'
[0m13:58:33.238094 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.238739 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.239220 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.242524 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.244883 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.280397 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.286137 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.289881 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.291024 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.294387 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.295653 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.296132 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.296555 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.297005 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: BEGIN
[0m13:58:33.300223 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.300659 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: BEGIN
[0m13:58:33.301071 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.301464 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:58:33.302150 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:58:33.302625 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: BEGIN
[0m13:58:33.303500 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:58:33.304102 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.304656 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: BEGIN
[0m13:58:33.305254 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:58:33.371500 [debug] [Thread-4 (]: SQL status: BEGIN in 0.070 seconds
[0m13:58:33.372016 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.372600 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */

  create view "delivery_analytics"."analytics"."stg_shipments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipments"
)

select
    shipment_id,
    sender_id,
    receiver_id,
    shipment_date,
    expected_delivery_date,
    price
from source;
  );
[0m13:58:33.373710 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: from source;
                    ^

[0m13:58:33.374358 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: ROLLBACK
[0m13:58:33.375262 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: Close
[0m13:58:33.385533 [debug] [Thread-4 (]: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:33.388200 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493ADB410>]}
[0m13:58:33.388965 [error] [Thread-4 (]: 4 of 5 ERROR creating sql view model analytics.stg_shipments ................... [[31mERROR[0m in 0.17s]
[0m13:58:33.390013 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.390450 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_users
[0m13:58:33.391081 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipments' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql.
[0m13:58:33.391754 [info ] [Thread-4 (]: 5 of 5 START sql view model analytics.stg_users ................................ [RUN]
[0m13:58:33.393593 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.stg_shipments, now model.dbt_delivery_analytics.stg_users)
[0m13:58:33.394282 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_users
[0m13:58:33.398075 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.399939 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_users
[0m13:58:33.404065 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.405361 [debug] [Thread-1 (]: SQL status: BEGIN in 0.103 seconds
[0m13:58:33.405974 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.406611 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.407110 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: BEGIN
[0m13:58:33.407632 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */

  create view "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    assignment_id,
    courier_id,
    shipment_id,
    assigned_at,
    delivered_at
from source;
  );
[0m13:58:33.408143 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:58:33.409403 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:33.409844 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: ROLLBACK
[0m13:58:33.410602 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: Close
[0m13:58:33.421022 [debug] [Thread-1 (]: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:33.422010 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493AF9B20>]}
[0m13:58:33.422809 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model analytics.stg_courier_assigments .......... [[31mERROR[0m in 0.21s]
[0m13:58:33.424002 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.424714 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_courier_assigments' to be skipped because of status 'error'.  Reason: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql.
[0m13:58:33.427621 [debug] [Thread-2 (]: SQL status: BEGIN in 0.124 seconds
[0m13:58:33.428133 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.428495 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */

  create view "delivery_analytics"."analytics"."stg_couriers__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."couriers"
)

select
    courier_id,
    user_id,
    vehicle_type,
    city
from source;
  );
[0m13:58:33.429484 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 17: from source;
                    ^

[0m13:58:33.430022 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: ROLLBACK
[0m13:58:33.430861 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: Close
[0m13:58:33.437815 [debug] [Thread-2 (]: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:33.438429 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4913D4C30>]}
[0m13:58:33.439061 [error] [Thread-2 (]: 2 of 5 ERROR creating sql view model analytics.stg_couriers .................... [[31mERROR[0m in 0.21s]
[0m13:58:33.440002 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.440672 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_couriers' to be skipped because of status 'error'.  Reason: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql.
[0m13:58:33.444255 [debug] [Thread-3 (]: SQL status: BEGIN in 0.139 seconds
[0m13:58:33.444732 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.445087 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */

  create view "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipment_status"
)

select
    shipment_status_id,
    shipment_id,
    status,
    status_timestamp,
    courier_id
from source;
  );
[0m13:58:33.445914 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:33.446363 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: ROLLBACK
[0m13:58:33.447152 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: Close
[0m13:58:33.453772 [debug] [Thread-3 (]: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:33.454426 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D48EFA4450>]}
[0m13:58:33.455144 [error] [Thread-3 (]: 3 of 5 ERROR creating sql view model analytics.stg_shipment_status ............. [[31mERROR[0m in 0.22s]
[0m13:58:33.455950 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.456654 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipment_status' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql.
[0m13:58:33.483896 [debug] [Thread-4 (]: SQL status: BEGIN in 0.076 seconds
[0m13:58:33.484429 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.484772 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */

  create view "delivery_analytics"."analytics"."stg_users__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from source;
  );
[0m13:58:33.485670 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:33.486112 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: ROLLBACK
[0m13:58:33.486799 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: Close
[0m13:58:33.492128 [debug] [Thread-4 (]: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:33.492718 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493F5FD90>]}
[0m13:58:33.493329 [error] [Thread-4 (]: 5 of 5 ERROR creating sql view model analytics.stg_users ....................... [[31mERROR[0m in 0.10s]
[0m13:58:33.494224 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_users
[0m13:58:33.494836 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_users' to be skipped because of status 'error'.  Reason: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql.
[0m13:58:33.496650 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.497204 [debug] [MainThread]: On master: BEGIN
[0m13:58:33.497543 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:58:33.563632 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m13:58:33.564116 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.564419 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.564700 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.565133 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:33.565432 [debug] [MainThread]: On master: Close
[0m13:58:33.565930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:58:33.566195 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m13:58:33.566449 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m13:58:33.566691 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_courier_assigments' was properly closed.
[0m13:58:33.566974 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_users' was properly closed.
[0m13:58:33.567215 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_couriers' was properly closed.
[0m13:58:33.567457 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipment_status' was properly closed.
[0m13:58:33.567857 [info ] [MainThread]: 
[0m13:58:33.568439 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.83 seconds (0.83s).
[0m13:58:33.570254 [debug] [MainThread]: Command end result
[0m13:58:33.664708 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:33.668318 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:33.675246 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m13:58:33.675670 [info ] [MainThread]: 
[0m13:58:33.676272 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m13:58:33.676813 [info ] [MainThread]: 
[0m13:58:33.677429 [error] [MainThread]: [31mFailure in model stg_shipments (models\staging\stg_shipments.sql)[0m
[0m13:58:33.678038 [error] [MainThread]:   Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:33.678636 [info ] [MainThread]: 
[0m13:58:33.679202 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:33.679779 [info ] [MainThread]: 
[0m13:58:33.680327 [error] [MainThread]: [31mFailure in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)[0m
[0m13:58:33.680942 [error] [MainThread]:   Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:33.681516 [info ] [MainThread]: 
[0m13:58:33.682123 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:33.682614 [info ] [MainThread]: 
[0m13:58:33.683228 [error] [MainThread]: [31mFailure in model stg_couriers (models\staging\stg_couriers.sql)[0m
[0m13:58:33.683949 [error] [MainThread]:   Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:33.684472 [info ] [MainThread]: 
[0m13:58:33.685094 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:33.685673 [info ] [MainThread]: 
[0m13:58:33.686371 [error] [MainThread]: [31mFailure in model stg_shipment_status (models\staging\stg_shipment_status.sql)[0m
[0m13:58:33.687132 [error] [MainThread]:   Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:33.687841 [info ] [MainThread]: 
[0m13:58:33.688382 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:33.688857 [info ] [MainThread]: 
[0m13:58:33.689445 [error] [MainThread]: [31mFailure in model stg_users (models\staging\stg_users.sql)[0m
[0m13:58:33.690027 [error] [MainThread]:   Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:33.690478 [info ] [MainThread]: 
[0m13:58:33.690996 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:33.691488 [info ] [MainThread]: 
[0m13:58:33.692067 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 NO-OP=0 TOTAL=5
[0m13:58:33.693732 [debug] [MainThread]: Command `dbt run` failed at 13:58:33.693588 after 2.22 seconds
[0m13:58:33.694145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491A95FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491333AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4936F08F0>]}
[0m13:58:33.694516 [debug] [MainThread]: Flushing usage events
[0m13:58:34.721407 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:59:34.512828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD268D4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD2737CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD279CBD90>]}


============================== 13:59:34.518025 | e216441e-60d6-468b-88cc-51556d6cf323 ==============================
[0m13:59:34.518025 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:59:34.519017 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:59:34.775508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD26D38770>]}
[0m13:59:34.843360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD2786EE00>]}
[0m13:59:34.845399 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:59:35.284785 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:59:35.434338 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m13:59:35.435306 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_shipments.sql
[0m13:59:35.435732 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_couriers.sql
[0m13:59:35.436103 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_shipment_status.sql
[0m13:59:35.436460 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_users.sql
[0m13:59:35.436816 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_courier_assigments.sql
[0m13:59:35.737085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD28E59850>]}
[0m13:59:35.819247 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:59:35.823534 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:59:35.865021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD2785FD40>]}
[0m13:59:35.865975 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:59:35.866683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD29475EF0>]}
[0m13:59:35.869126 [info ] [MainThread]: 
[0m13:59:35.869746 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:59:35.870249 [info ] [MainThread]: 
[0m13:59:35.871015 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:59:35.876165 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m13:59:36.099825 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m13:59:36.100249 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:59:36.100541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:36.223725 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.123 seconds
[0m13:59:36.225263 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m13:59:36.228101 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m13:59:36.234081 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:59:36.234490 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m13:59:36.234779 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:36.305804 [debug] [ThreadPool]: SQL status: BEGIN in 0.071 seconds
[0m13:59:36.306325 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:59:36.306706 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:59:36.315587 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m13:59:36.316848 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m13:59:36.317329 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m13:59:36.322984 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.323578 [debug] [MainThread]: On master: BEGIN
[0m13:59:36.323870 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:59:36.398967 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m13:59:36.399508 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.399956 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m13:59:36.409154 [debug] [MainThread]: SQL status: SELECT 0 in 0.009 seconds
[0m13:59:36.410559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD294EADD0>]}
[0m13:59:36.411115 [debug] [MainThread]: On master: ROLLBACK
[0m13:59:36.411685 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.412058 [debug] [MainThread]: On master: BEGIN
[0m13:59:36.412769 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:59:36.413150 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.413495 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.413816 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.414298 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:59:36.414596 [debug] [MainThread]: On master: Close
[0m13:59:36.420046 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.420611 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.420997 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.421361 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.422127 [info ] [Thread-4 (]: 4 of 5 START sql view model analytics.stg_shipments ............................ [RUN]
[0m13:59:36.422836 [info ] [Thread-2 (]: 2 of 5 START sql view model analytics.stg_couriers ............................. [RUN]
[0m13:59:36.425111 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipments'
[0m13:59:36.423623 [info ] [Thread-1 (]: 1 of 5 START sql view model analytics.stg_courier_assigments ................... [RUN]
[0m13:59:36.425963 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_couriers'
[0m13:59:36.426592 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.424257 [info ] [Thread-3 (]: 3 of 5 START sql view model analytics.stg_shipment_status ...................... [RUN]
[0m13:59:36.427456 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_courier_assigments'
[0m13:59:36.427955 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.434847 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.435525 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipment_status'
[0m13:59:36.436047 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.439359 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.440199 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.443373 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.446145 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.447208 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.485351 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.486503 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.490208 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.491025 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.494612 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.495243 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.495773 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.496331 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: BEGIN
[0m13:59:36.499618 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.500118 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:59:36.501043 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.501635 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.502183 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: BEGIN
[0m13:59:36.502757 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: BEGIN
[0m13:59:36.503143 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:59:36.503661 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:59:36.504303 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.505242 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: BEGIN
[0m13:59:36.505819 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:59:36.568610 [debug] [Thread-4 (]: SQL status: BEGIN in 0.068 seconds
[0m13:59:36.569341 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.569921 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */

  create view "delivery_analytics"."analytics"."stg_shipments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipments"
)

select
    shipment_id,
    sender_id,
    receiver_id,
    shipment_date,
    expected_delivery_date,
    price
from source
  );
[0m13:59:36.580395 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m13:59:36.586709 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.587276 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */
alter table "delivery_analytics"."analytics"."stg_shipments__dbt_tmp" rename to "stg_shipments"
[0m13:59:36.588037 [debug] [Thread-3 (]: SQL status: BEGIN in 0.085 seconds
[0m13:59:36.588606 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.589227 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */

  create view "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipment_status"
)

select
    shipment_status_id,
    shipment_id,
    status,
    status_timestamp,
    courier_id
from source
  );
[0m13:59:36.591325 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m13:59:36.605525 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: COMMIT
[0m13:59:36.606054 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.016 seconds
[0m13:59:36.606496 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.609958 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.610486 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: COMMIT
[0m13:59:36.611062 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */
alter table "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp" rename to "stg_shipment_status"
[0m13:59:36.611832 [debug] [Thread-2 (]: SQL status: BEGIN in 0.108 seconds
[0m13:59:36.612271 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:59:36.612707 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.613083 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m13:59:36.614491 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: COMMIT
[0m13:59:36.614963 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */

  create view "delivery_analytics"."analytics"."stg_couriers__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."couriers"
)

select
    courier_id,
    user_id,
    vehicle_type,
    city
from source
  );
[0m13:59:36.620979 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_shipments__dbt_backup"
[0m13:59:36.621491 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.626636 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.627131 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: COMMIT
[0m13:59:36.627640 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */
drop view if exists "delivery_analytics"."analytics"."stg_shipments__dbt_backup" cascade
[0m13:59:36.628250 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m13:59:36.631479 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.631991 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.003 seconds
[0m13:59:36.632443 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m13:59:36.632867 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */
alter table "delivery_analytics"."analytics"."stg_couriers__dbt_tmp" rename to "stg_couriers"
[0m13:59:36.635217 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: Close
[0m13:59:36.637266 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_shipment_status__dbt_backup"
[0m13:59:36.638292 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.638858 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:59:36.639305 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */
drop view if exists "delivery_analytics"."analytics"."stg_shipment_status__dbt_backup" cascade
[0m13:59:36.642518 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: COMMIT
[0m13:59:36.643010 [debug] [Thread-1 (]: SQL status: BEGIN in 0.137 seconds
[0m13:59:36.643595 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.644090 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.001 seconds
[0m13:59:36.644516 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.644930 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: COMMIT
[0m13:59:36.646341 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: Close
[0m13:59:36.646797 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */

  create view "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    assignment_id,
    courier_id,
    shipment_id,
    assigned_at,
    delivered_at
from source
  );
[0m13:59:36.647258 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD298DC350>]}
[0m13:59:36.648206 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD29542D00>]}
[0m13:59:36.649582 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m13:59:36.649081 [info ] [Thread-4 (]: 4 of 5 OK created sql view model analytics.stg_shipments ....................... [[32mCREATE VIEW[0m in 0.22s]
[0m13:59:36.653792 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_couriers__dbt_backup"
[0m13:59:36.650474 [info ] [Thread-3 (]: 3 of 5 OK created sql view model analytics.stg_shipment_status ................. [[32mCREATE VIEW[0m in 0.21s]
[0m13:59:36.654844 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.655274 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m13:59:36.656075 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.656699 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.657198 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_users
[0m13:59:36.660325 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.660801 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */
drop view if exists "delivery_analytics"."analytics"."stg_couriers__dbt_backup" cascade
[0m13:59:36.662112 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */
alter table "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp" rename to "stg_courier_assigments"
[0m13:59:36.661700 [info ] [Thread-4 (]: 5 of 5 START sql view model analytics.stg_users ................................ [RUN]
[0m13:59:36.662974 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.stg_shipments, now model.dbt_delivery_analytics.stg_users)
[0m13:59:36.663494 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_users
[0m13:59:36.664003 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:59:36.664418 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.002 seconds
[0m13:59:36.667718 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.669451 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: COMMIT
[0m13:59:36.670999 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: Close
[0m13:59:36.671594 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.672117 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: COMMIT
[0m13:59:36.672651 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD298ECEB0>]}
[0m13:59:36.674211 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m13:59:36.674850 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_users
[0m13:59:36.673633 [info ] [Thread-2 (]: 2 of 5 OK created sql view model analytics.stg_couriers ........................ [[32mCREATE VIEW[0m in 0.25s]
[0m13:59:36.678087 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_courier_assigments__dbt_backup"
[0m13:59:36.681748 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.682503 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.683286 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.684064 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */
drop view if exists "delivery_analytics"."analytics"."stg_courier_assigments__dbt_backup" cascade
[0m13:59:36.684947 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m13:59:36.686428 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: Close
[0m13:59:36.686873 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.687387 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: BEGIN
[0m13:59:36.688055 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD294385D0>]}
[0m13:59:36.688590 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:59:36.689443 [info ] [Thread-1 (]: 1 of 5 OK created sql view model analytics.stg_courier_assigments .............. [[32mCREATE VIEW[0m in 0.26s]
[0m13:59:36.690512 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.761152 [debug] [Thread-4 (]: SQL status: BEGIN in 0.072 seconds
[0m13:59:36.761709 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.762113 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */

  create view "delivery_analytics"."analytics"."stg_users__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from source
  );
[0m13:59:36.768100 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m13:59:36.771127 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.771525 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */
alter table "delivery_analytics"."analytics"."stg_users__dbt_tmp" rename to "stg_users"
[0m13:59:36.772381 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:59:36.773750 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: COMMIT
[0m13:59:36.774116 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.774450 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: COMMIT
[0m13:59:36.775806 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m13:59:36.778343 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_users__dbt_backup"
[0m13:59:36.778975 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.779312 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */
drop view if exists "delivery_analytics"."analytics"."stg_users__dbt_backup" cascade
[0m13:59:36.779931 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.000 seconds
[0m13:59:36.781400 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: Close
[0m13:59:36.782136 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD298F6120>]}
[0m13:59:36.782732 [info ] [Thread-4 (]: 5 of 5 OK created sql view model analytics.stg_users ........................... [[32mCREATE VIEW[0m in 0.12s]
[0m13:59:36.783529 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_users
[0m13:59:36.785245 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.785603 [debug] [MainThread]: On master: BEGIN
[0m13:59:36.785916 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:59:36.857565 [debug] [MainThread]: SQL status: BEGIN in 0.072 seconds
[0m13:59:36.858101 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.858524 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.858818 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.859256 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:59:36.859575 [debug] [MainThread]: On master: Close
[0m13:59:36.860066 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:59:36.860376 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m13:59:36.860736 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m13:59:36.861090 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_users' was properly closed.
[0m13:59:36.861425 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_couriers' was properly closed.
[0m13:59:36.861785 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_courier_assigments' was properly closed.
[0m13:59:36.862151 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipment_status' was properly closed.
[0m13:59:36.862666 [info ] [MainThread]: 
[0m13:59:36.863280 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m13:59:36.865137 [debug] [MainThread]: Command end result
[0m13:59:36.901986 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:59:36.906009 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:59:36.913925 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m13:59:36.914326 [info ] [MainThread]: 
[0m13:59:36.914892 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:59:36.915370 [info ] [MainThread]: 
[0m13:59:36.915894 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m13:59:36.917244 [debug] [MainThread]: Command `dbt run` succeeded at 13:59:36.917126 after 2.61 seconds
[0m13:59:36.917604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD26CCEB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD28FCB590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD28FC9BB0>]}
[0m13:59:36.917971 [debug] [MainThread]: Flushing usage events
[0m13:59:38.083843 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:14:09.307235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023591C60980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002359271CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592D57D90>]}


============================== 14:14:09.313804 | c2798855-b4cc-4265-9773-0ff7141fbe74 ==============================
[0m14:14:09.313804 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:14:09.314779 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.core', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:14:09.614750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235920C8770>]}
[0m14:14:09.697181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592BFEE00>]}
[0m14:14:09.699030 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:14:10.312062 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:14:10.515198 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m14:14:10.516146 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\core\dim_dates.sql
[0m14:14:10.516708 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\core\dim_couriers.sql
[0m14:14:10.517203 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\core\dim_users.sql
[0m14:14:10.867816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235946D1650>]}
[0m14:14:10.965364 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:14:10.969719 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:14:11.011366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592BEFD40>]}
[0m14:14:11.012039 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:14:11.012703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594816270>]}
[0m14:14:11.014859 [info ] [MainThread]: 
[0m14:14:11.015509 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:14:11.016165 [info ] [MainThread]: 
[0m14:14:11.017223 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:14:11.021750 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:14:11.259468 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:14:11.259920 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:14:11.260304 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:14:11.378067 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.118 seconds
[0m14:14:11.379427 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:14:11.382501 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:14:11.391921 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:14:11.392693 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:14:11.393082 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:14:11.453570 [debug] [ThreadPool]: SQL status: BEGIN in 0.060 seconds
[0m14:14:11.454023 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:14:11.454330 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:14:11.461917 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.007 seconds
[0m14:14:11.463362 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:14:11.463938 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:14:11.470888 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.471356 [debug] [MainThread]: On master: BEGIN
[0m14:14:11.471628 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:14:11.532114 [debug] [MainThread]: SQL status: BEGIN in 0.060 seconds
[0m14:14:11.532566 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.532930 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:14:11.540167 [debug] [MainThread]: SQL status: SELECT 5 in 0.007 seconds
[0m14:14:11.541492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594886EA0>]}
[0m14:14:11.541952 [debug] [MainThread]: On master: ROLLBACK
[0m14:14:11.542637 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.542950 [debug] [MainThread]: On master: BEGIN
[0m14:14:11.543689 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:14:11.544001 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.544284 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.544627 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.545104 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:14:11.545405 [debug] [MainThread]: On master: Close
[0m14:14:11.550961 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.551427 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.dim_users
[0m14:14:11.551849 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.552374 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.dim_couriers ............................ [RUN]
[0m14:14:11.554050 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.dim_couriers'
[0m14:14:11.552884 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.dim_users ............................... [RUN]
[0m14:14:11.554612 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.555246 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.dim_users'
[0m14:14:11.553452 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.dim_dates ............................... [RUN]
[0m14:14:11.563832 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.564336 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.dim_users
[0m14:14:11.565000 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.dim_dates'
[0m14:14:11.567766 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.568247 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.570959 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.574338 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.574933 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.dim_users
[0m14:14:11.575393 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.621201 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.626156 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.629543 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.633578 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.634083 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.634450 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.634870 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: BEGIN
[0m14:14:11.635400 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: BEGIN
[0m14:14:11.635875 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: BEGIN
[0m14:14:11.636317 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:14:11.636834 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:14:11.637313 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:14:11.705029 [debug] [Thread-3 (]: SQL status: BEGIN in 0.068 seconds
[0m14:14:11.705664 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.706187 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_users"} */

  
    

  create  table "delivery_analytics"."analytics"."dim_users__dbt_tmp"
  
  
    as
  
  (
    with users as (
    select *
    from "delivery_analytics"."analytics"."stg_users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from users
  );
  
[0m14:14:11.713794 [debug] [Thread-3 (]: SQL status: SELECT 8 in 0.007 seconds
[0m14:14:11.723440 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.723933 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_users"} */
alter table "delivery_analytics"."analytics"."dim_users__dbt_tmp" rename to "dim_users"
[0m14:14:11.724605 [debug] [Thread-1 (]: SQL status: BEGIN in 0.088 seconds
[0m14:14:11.725021 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.725416 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:14:11.725863 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_couriers"} */

  
    

  create  table "delivery_analytics"."analytics"."dim_couriers__dbt_tmp"
  
  
    as
  
  (
    with couriers as (
    select *
    from "delivery_analytics"."analytics"."stg_couriers"
),

users as (
    select user_id, username
    from "delivery_analytics"."analytics"."stg_users"
)

select
    c.courier_id,
    c.user_id,
    u.username,
    c.vehicle_type,
    c.city
from couriers c
left join users u
    on c.user_id = u.user_id
  );
  
[0m14:14:11.740057 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: COMMIT
[0m14:14:11.740794 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.741354 [debug] [Thread-2 (]: SQL status: BEGIN in 0.104 seconds
[0m14:14:11.741771 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: COMMIT
[0m14:14:11.742211 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.742706 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_dates"} */

  
    

  create  table "delivery_analytics"."analytics"."dim_dates__dbt_tmp"
  
  
    as
  
  (
    with users as (
    select *
    from "delivery_analytics"."analytics"."stg_users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from users
  );
  
[0m14:14:11.743507 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:14:11.749404 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."dim_users__dbt_backup"
[0m14:14:11.749937 [debug] [Thread-2 (]: SQL status: SELECT 8 in 0.007 seconds
[0m14:14:11.750372 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.010 seconds
[0m14:14:11.755249 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.758398 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.761641 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.762140 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_users"} */
drop table if exists "delivery_analytics"."analytics"."dim_users__dbt_backup" cascade
[0m14:14:11.762639 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_dates"} */
alter table "delivery_analytics"."analytics"."dim_dates__dbt_tmp" rename to "dim_dates"
[0m14:14:11.763080 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_couriers"} */
alter table "delivery_analytics"."analytics"."dim_couriers__dbt_tmp" rename to "dim_couriers"
[0m14:14:11.764309 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m14:14:11.764724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:14:11.765100 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m14:14:11.767411 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: Close
[0m14:14:11.768712 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: COMMIT
[0m14:14:11.769917 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: COMMIT
[0m14:14:11.770408 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.772016 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.772468 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: COMMIT
[0m14:14:11.772956 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: COMMIT
[0m14:14:11.773662 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594847F50>]}
[0m14:14:11.774780 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:14:11.775179 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m14:14:11.774426 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.dim_users .......................... [[32mSELECT 8[0m in 0.22s]
[0m14:14:11.777834 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."dim_couriers__dbt_backup"
[0m14:14:11.780205 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."dim_dates__dbt_backup"
[0m14:14:11.781486 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.dim_users
[0m14:14:11.782373 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.783167 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.783877 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_couriers"} */
drop table if exists "delivery_analytics"."analytics"."dim_couriers__dbt_backup" cascade
[0m14:14:11.784356 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_dates"} */
drop table if exists "delivery_analytics"."analytics"."dim_dates__dbt_backup" cascade
[0m14:14:11.785308 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:14:11.785696 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m14:14:11.787056 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: Close
[0m14:14:11.788279 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: Close
[0m14:14:11.789024 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235948D7330>]}
[0m14:14:11.789541 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594315DB0>]}
[0m14:14:11.790189 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.dim_couriers ....................... [[32mSELECT 3[0m in 0.24s]
[0m14:14:11.791740 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.790768 [info ] [Thread-2 (]: 2 of 3 OK created sql table model analytics.dim_dates .......................... [[32mSELECT 8[0m in 0.22s]
[0m14:14:11.792909 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.794790 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.795245 [debug] [MainThread]: On master: BEGIN
[0m14:14:11.795558 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:14:11.865350 [debug] [MainThread]: SQL status: BEGIN in 0.070 seconds
[0m14:14:11.865804 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.866100 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.866400 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.866899 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:14:11.867228 [debug] [MainThread]: On master: Close
[0m14:14:11.867739 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:14:11.868028 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:14:11.868274 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:14:11.868606 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.dim_couriers' was properly closed.
[0m14:14:11.868849 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.dim_users' was properly closed.
[0m14:14:11.869082 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.dim_dates' was properly closed.
[0m14:14:11.869455 [info ] [MainThread]: 
[0m14:14:11.870020 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.85 seconds (0.85s).
[0m14:14:11.871470 [debug] [MainThread]: Command end result
[0m14:14:11.897867 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:14:11.901409 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:14:11.908560 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:14:11.908988 [info ] [MainThread]: 
[0m14:14:11.909573 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:14:11.910111 [info ] [MainThread]: 
[0m14:14:11.910677 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m14:14:11.912071 [debug] [MainThread]: Command `dbt run` succeeded at 14:14:11.911955 after 2.83 seconds
[0m14:14:11.912558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002359488CBD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594BFD150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592C6FA80>]}
[0m14:14:11.913016 [debug] [MainThread]: Flushing usage events
[0m14:14:12.956616 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:12.889210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99E0F0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99EB9CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F1E7D90>]}


============================== 14:17:12.895295 | 4ec62e9b-f819-443c-9d87-0993581562d3 ==============================
[0m14:17:12.895295 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:17:12.896598 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:17:13.188851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99E558770>]}
[0m14:17:13.271859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F08EE00>]}
[0m14:17:13.273900 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:17:13.769554 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:17:13.933824 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m14:17:13.934670 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\daily_shipments_status.sql
[0m14:17:13.935199 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments.sql
[0m14:17:13.935697 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:17:14.220058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0B05950>]}
[0m14:17:14.299455 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:17:14.303712 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:17:14.341638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F07FD40>]}
[0m14:17:14.342777 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:17:14.343482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0C465F0>]}
[0m14:17:14.345658 [info ] [MainThread]: 
[0m14:17:14.346463 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:17:14.347008 [info ] [MainThread]: 
[0m14:17:14.347735 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:17:14.351828 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:17:14.562179 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:17:14.562607 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:17:14.562928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:14.702454 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.139 seconds
[0m14:17:14.703918 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:17:14.706192 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:17:14.712382 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:17:14.712857 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:17:14.713192 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:14.777134 [debug] [ThreadPool]: SQL status: BEGIN in 0.064 seconds
[0m14:17:14.777594 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:17:14.777909 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:17:14.784271 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m14:17:14.786262 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:17:14.786953 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:17:14.794207 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.794624 [debug] [MainThread]: On master: BEGIN
[0m14:17:14.794919 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:14.853105 [debug] [MainThread]: SQL status: BEGIN in 0.058 seconds
[0m14:17:14.853603 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.853949 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:17:14.860567 [debug] [MainThread]: SQL status: SELECT 5 in 0.006 seconds
[0m14:17:14.862482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0EB2F70>]}
[0m14:17:14.862924 [debug] [MainThread]: On master: ROLLBACK
[0m14:17:14.863482 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.863853 [debug] [MainThread]: On master: BEGIN
[0m14:17:14.864641 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:17:14.864954 [debug] [MainThread]: On master: COMMIT
[0m14:17:14.865239 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.865510 [debug] [MainThread]: On master: COMMIT
[0m14:17:14.866000 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:17:14.866321 [debug] [MainThread]: On master: Close
[0m14:17:14.870822 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:17:14.871644 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:17:14.872548 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:17:14.872919 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:17:14.880775 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.883409 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:17:14.923658 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.926318 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.927207 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:17:14.927795 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:17:14.987217 [debug] [Thread-1 (]: SQL status: BEGIN in 0.059 seconds
[0m14:17:14.987779 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.988166 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:17:15.105015 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.116 seconds
[0m14:17:15.115845 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:15.116494 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:17:15.117636 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:17:15.131712 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:17:15.132233 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:15.132663 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:17:15.133959 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:17:15.139547 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:17:15.144180 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:15.144553 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:17:15.145296 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:17:15.147827 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:17:15.150436 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0A73590>]}
[0m14:17:15.151252 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.28s]
[0m14:17:15.152387 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:17:15.153376 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.154398 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.154006 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:17:15.155808 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:17:15.155168 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:17:15.156458 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.157009 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:17:15.160048 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.160511 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.163087 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.169494 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.173799 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.174690 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.181448 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.183529 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.184250 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:17:15.184780 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:17:15.187244 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.187782 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:17:15.188269 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:17:15.252587 [debug] [Thread-3 (]: SQL status: BEGIN in 0.068 seconds
[0m14:17:15.253150 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.253519 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:17:15.263105 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.009 seconds
[0m14:17:15.266466 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.267063 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:17:15.267719 [debug] [Thread-2 (]: SQL status: BEGIN in 0.079 seconds
[0m14:17:15.268266 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.268716 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:17:15.269203 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    avg(s.expected_delivery_date - s.shipment_date) as avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:17:15.270604 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:17:15.271245 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.271752 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:17:15.273287 [debug] [Thread-2 (]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                 ^

[0m14:17:15.273838 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:17:15.274426 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:17:15.278144 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:17:15.279020 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:17:15.279998 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.280550 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:17:15.282702 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:17:15.284347 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:17:15.285293 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0D176A0>]}
[0m14:17:15.286194 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.13s]
[0m14:17:15.287497 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.296618 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:17:15.297352 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0777110>]}
[0m14:17:15.298069 [error] [Thread-2 (]: 2 of 3 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.14s]
[0m14:17:15.298988 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.299848 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:17:15.302537 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:15.303133 [debug] [MainThread]: On master: BEGIN
[0m14:17:15.303520 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:17:15.369396 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m14:17:15.369844 [debug] [MainThread]: On master: COMMIT
[0m14:17:15.370139 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:15.370420 [debug] [MainThread]: On master: COMMIT
[0m14:17:15.370841 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:17:15.371219 [debug] [MainThread]: On master: Close
[0m14:17:15.371718 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:17:15.371989 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:17:15.372235 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:17:15.372539 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m14:17:15.372785 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:17:15.373022 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:17:15.373374 [info ] [MainThread]: 
[0m14:17:15.373918 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m14:17:15.375602 [debug] [MainThread]: Command end result
[0m14:17:15.404005 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:17:15.408154 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:17:15.416903 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:17:15.417392 [info ] [MainThread]: 
[0m14:17:15.418075 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:17:15.418580 [info ] [MainThread]: 
[0m14:17:15.419344 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:17:15.420020 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:17:15.420577 [info ] [MainThread]: 
[0m14:17:15.421168 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:17:15.421679 [info ] [MainThread]: 
[0m14:17:15.422217 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m14:17:15.423981 [debug] [MainThread]: Command `dbt run` failed at 14:17:15.423830 after 2.84 seconds
[0m14:17:15.424463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0CC09D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0FBB2D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F0FFA80>]}
[0m14:17:15.424919 [debug] [MainThread]: Flushing usage events
[0m14:17:16.505531 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:18:41.446939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC4210980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC4CCCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC530BD90>]}


============================== 14:18:41.452995 | 1962fec5-49a5-4d57-8198-7de58a63d7f8 ==============================
[0m14:18:41.452995 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:18:41.454223 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:18:41.734997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC4678770>]}
[0m14:18:41.817168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC51AEE00>]}
[0m14:18:41.818966 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:18:42.412622 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:18:42.599636 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:18:42.600849 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:18:42.962123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6C79850>]}
[0m14:18:43.051674 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:18:43.056154 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:18:43.097409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC519FD40>]}
[0m14:18:43.098430 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:18:43.099331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E7E5F0>]}
[0m14:18:43.101713 [info ] [MainThread]: 
[0m14:18:43.102455 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:18:43.103164 [info ] [MainThread]: 
[0m14:18:43.104248 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:18:43.111587 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:18:43.379119 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:18:43.379660 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:18:43.380137 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:18:43.534321 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.154 seconds
[0m14:18:43.536143 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:18:43.539529 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:18:43.547534 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:18:43.548077 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:18:43.548444 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:18:43.621391 [debug] [ThreadPool]: SQL status: BEGIN in 0.073 seconds
[0m14:18:43.621950 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:18:43.622373 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:18:43.629895 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m14:18:43.632126 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:18:43.632858 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:18:43.642255 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.642764 [debug] [MainThread]: On master: BEGIN
[0m14:18:43.643125 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:18:43.716593 [debug] [MainThread]: SQL status: BEGIN in 0.073 seconds
[0m14:18:43.717151 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.717623 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:18:43.727649 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m14:18:43.730364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC7013040>]}
[0m14:18:43.730975 [debug] [MainThread]: On master: ROLLBACK
[0m14:18:43.731760 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.732296 [debug] [MainThread]: On master: BEGIN
[0m14:18:43.733277 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m14:18:43.733692 [debug] [MainThread]: On master: COMMIT
[0m14:18:43.734108 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.734466 [debug] [MainThread]: On master: COMMIT
[0m14:18:43.735117 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:18:43.735538 [debug] [MainThread]: On master: Close
[0m14:18:43.742116 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.743198 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:18:43.744193 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:18:43.744685 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.754159 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.756503 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.808203 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.810544 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.811185 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:18:43.811993 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:18:43.887796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.076 seconds
[0m14:18:43.888452 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.888934 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:18:43.899734 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.010 seconds
[0m14:18:43.912996 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.913518 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:18:43.915088 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:43.918899 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.919398 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:18:43.920949 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:43.941487 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:18:43.942035 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.942486 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:18:43.944414 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:18:43.953776 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:18:43.961215 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.962600 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:18:43.969932 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m14:18:43.973817 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:18:43.976723 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6BD3890>]}
[0m14:18:43.977590 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.23s]
[0m14:18:43.979216 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.980493 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:18:43.981128 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:43.981857 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:18:43.983463 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:18:43.984008 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:18:43.982600 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:18:43.987726 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:18:43.988593 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:18:43.989523 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:43.994677 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:43.995882 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:18:44.000752 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:18:44.002280 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:44.006367 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.008110 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:18:44.008953 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:18:44.009810 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:18:44.011079 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.011615 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:18:44.012121 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:18:44.093192 [debug] [Thread-2 (]: SQL status: BEGIN in 0.083 seconds
[0m14:18:44.094110 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:18:44.094872 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shipment_date)) / 86400) AS avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:18:44.098050 [debug] [Thread-2 (]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                     ^

[0m14:18:44.098687 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:18:44.099662 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:18:44.114925 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                       ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:18:44.116047 [debug] [Thread-3 (]: SQL status: BEGIN in 0.104 seconds
[0m14:18:44.116973 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E6BD80>]}
[0m14:18:44.117629 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.119463 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:18:44.118744 [error] [Thread-2 (]: 2 of 3 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.13s]
[0m14:18:44.120533 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:18:44.121288 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                       ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:18:44.129853 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.010 seconds
[0m14:18:44.134870 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.135450 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:18:44.136766 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:44.140203 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.140739 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:18:44.142329 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:44.144336 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:18:44.144846 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.145287 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:18:44.147198 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:18:44.150561 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:18:44.151477 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.151943 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:18:44.157011 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.005 seconds
[0m14:18:44.159119 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:18:44.159914 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC68A02D0>]}
[0m14:18:44.160874 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.17s]
[0m14:18:44.162279 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:44.164523 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:44.165017 [debug] [MainThread]: On master: BEGIN
[0m14:18:44.165418 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:18:44.240058 [debug] [MainThread]: SQL status: BEGIN in 0.074 seconds
[0m14:18:44.240739 [debug] [MainThread]: On master: COMMIT
[0m14:18:44.241217 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:44.241603 [debug] [MainThread]: On master: COMMIT
[0m14:18:44.242274 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:18:44.242688 [debug] [MainThread]: On master: Close
[0m14:18:44.243326 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:18:44.243692 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:18:44.244041 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:18:44.244494 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m14:18:44.244838 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:18:44.245183 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:18:44.245653 [info ] [MainThread]: 
[0m14:18:44.246405 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.14 seconds (1.14s).
[0m14:18:44.248064 [debug] [MainThread]: Command end result
[0m14:18:44.279736 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:18:44.284443 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:18:44.293033 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:18:44.293574 [info ] [MainThread]: 
[0m14:18:44.294331 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:18:44.295181 [info ] [MainThread]: 
[0m14:18:44.295917 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:18:44.296705 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                       ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:18:44.297390 [info ] [MainThread]: 
[0m14:18:44.298109 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:18:44.298799 [info ] [MainThread]: 
[0m14:18:44.299669 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m14:18:44.301634 [debug] [MainThread]: Command `dbt run` failed at 14:18:44.301479 after 3.09 seconds
[0m14:18:44.302206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E28950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E30AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC521FA80>]}
[0m14:18:44.302660 [debug] [MainThread]: Flushing usage events
[0m14:18:45.344282 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:19:19.612296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215443F0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021544E9CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215454EBD90>]}


============================== 14:19:19.618293 | bc10e861-d968-4a1c-801a-5442778b6c22 ==============================
[0m14:19:19.618293 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:19:19.620032 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:19:19.920560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021544858770>]}
[0m14:19:20.006230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002154538EE00>]}
[0m14:19:20.008020 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:19:20.633002 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:19:20.832521 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:19:20.833333 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:19:21.191065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546E31850>]}
[0m14:19:21.284569 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:19:21.289722 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:19:21.332228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002154537FD40>]}
[0m14:19:21.332945 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:19:21.333746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546FA25F0>]}
[0m14:19:21.336740 [info ] [MainThread]: 
[0m14:19:21.337495 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:19:21.338134 [info ] [MainThread]: 
[0m14:19:21.339054 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:19:21.344666 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:19:21.657382 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:19:21.657947 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:19:21.658401 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:21.797991 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.139 seconds
[0m14:19:21.799567 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:19:21.802100 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:19:21.811648 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:19:21.812313 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:19:21.812762 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:21.882773 [debug] [ThreadPool]: SQL status: BEGIN in 0.070 seconds
[0m14:19:21.883437 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:19:21.883959 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:19:21.891913 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m14:19:21.894206 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:19:21.894929 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:19:21.904327 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:21.904930 [debug] [MainThread]: On master: BEGIN
[0m14:19:21.905329 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:19:21.996629 [debug] [MainThread]: SQL status: BEGIN in 0.091 seconds
[0m14:19:21.997275 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:21.997845 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:19:22.006473 [debug] [MainThread]: SQL status: SELECT 5 in 0.008 seconds
[0m14:19:22.008681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215471D3040>]}
[0m14:19:22.009301 [debug] [MainThread]: On master: ROLLBACK
[0m14:19:22.009879 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.010225 [debug] [MainThread]: On master: BEGIN
[0m14:19:22.010873 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:19:22.011198 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.011496 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.011786 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.012257 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:19:22.012670 [debug] [MainThread]: On master: Close
[0m14:19:22.018531 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.019384 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:19:22.020266 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:19:22.020897 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.032212 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.034475 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.087502 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.089895 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.090581 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:19:22.091181 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:19:22.162508 [debug] [Thread-1 (]: SQL status: BEGIN in 0.071 seconds
[0m14:19:22.163118 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.163595 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:19:22.174832 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.011 seconds
[0m14:19:22.187022 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.187616 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:19:22.188615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.192067 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.192579 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:19:22.193966 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.212073 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:19:22.212523 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.212857 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:19:22.214158 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:19:22.220018 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:19:22.224671 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.225347 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:19:22.229800 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m14:19:22.232268 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:19:22.234876 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546CEB890>]}
[0m14:19:22.235678 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.21s]
[0m14:19:22.237036 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.238323 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.238869 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.239413 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:19:22.240195 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:19:22.241132 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:19:22.241775 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:19:22.242408 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.242886 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.246657 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.250279 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.253721 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.254576 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.260139 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.264468 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.267114 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.267723 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:19:22.268371 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.268991 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:19:22.269484 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:19:22.270220 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:19:22.343675 [debug] [Thread-3 (]: SQL status: BEGIN in 0.075 seconds
[0m14:19:22.344171 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.344556 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:19:22.352986 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.008 seconds
[0m14:19:22.356981 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.357520 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:19:22.358310 [debug] [Thread-2 (]: SQL status: BEGIN in 0.088 seconds
[0m14:19:22.358740 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.359097 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.361580 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.362007 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipment_date)) / 86400) AS avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:19:22.362412 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:19:22.363434 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.364899 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:19:22.365264 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.365941 [debug] [Thread-2 (]: Postgres adapter: Postgres error: function pg_catalog.extract(unknown, integer) does not exist
LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                 ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m14:19:22.366489 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:19:22.367095 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:19:22.367854 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:19:22.369534 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:19:22.372634 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:19:22.373464 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.373882 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:19:22.381463 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:19:22.382313 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021547033AC0>]}
[0m14:19:22.383831 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.009 seconds
[0m14:19:22.383397 [error] [Thread-2 (]: 2 of 3 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.14s]
[0m14:19:22.385463 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:19:22.386050 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.387002 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:19:22.387729 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546A651D0>]}
[0m14:19:22.389225 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.15s]
[0m14:19:22.390280 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.392107 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.392552 [debug] [MainThread]: On master: BEGIN
[0m14:19:22.392919 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:19:22.458555 [debug] [MainThread]: SQL status: BEGIN in 0.065 seconds
[0m14:19:22.459280 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.459870 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.460368 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.461050 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:19:22.461451 [debug] [MainThread]: On master: Close
[0m14:19:22.462150 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:19:22.462515 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:19:22.462787 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:19:22.463122 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m14:19:22.463369 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:19:22.463617 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:19:22.464004 [info ] [MainThread]: 
[0m14:19:22.464644 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.13 seconds (1.13s).
[0m14:19:22.466520 [debug] [MainThread]: Command end result
[0m14:19:22.495829 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:19:22.500111 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:19:22.508571 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:19:22.509188 [info ] [MainThread]: 
[0m14:19:22.510000 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:19:22.510608 [info ] [MainThread]: 
[0m14:19:22.511290 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:19:22.511893 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:19:22.512425 [info ] [MainThread]: 
[0m14:19:22.513014 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:19:22.513518 [info ] [MainThread]: 
[0m14:19:22.514061 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m14:19:22.515489 [debug] [MainThread]: Command `dbt run` failed at 14:19:22.515359 after 3.11 seconds
[0m14:19:22.515881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215472C43D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546FE8950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215453FFA80>]}
[0m14:19:22.516251 [debug] [MainThread]: Flushing usage events
[0m14:19:23.673259 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:32:42.672973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A174AA0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A17553CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A175B8BD90>]}


============================== 14:32:42.680307 | 8544f83d-13f1-4b8d-b599-7afb5ac89319 ==============================
[0m14:32:42.680307 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:32:42.681673 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:32:42.984524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A174F08770>]}
[0m14:32:43.069379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A175A2EE00>]}
[0m14:32:43.071208 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:32:43.720208 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:32:43.959853 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m14:32:43.960634 [debug] [MainThread]: Partial parsing: added file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_slq.sql
[0m14:32:43.961358 [debug] [MainThread]: Partial parsing: added file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_revenue.sql
[0m14:32:44.338473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A177539950>]}
[0m14:32:44.442560 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:32:44.451146 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:32:44.509387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A175A1FD40>]}
[0m14:32:44.510424 [info ] [MainThread]: Found 13 models, 5 sources, 459 macros
[0m14:32:44.511355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A1776BA6D0>]}
[0m14:32:44.514790 [info ] [MainThread]: 
[0m14:32:44.515487 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:32:44.516443 [info ] [MainThread]: 
[0m14:32:44.517417 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:32:44.525419 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:32:44.801655 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:32:44.802223 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:32:44.802651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:32:44.968843 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.166 seconds
[0m14:32:44.971147 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:32:44.975197 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:32:44.987276 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:32:44.988021 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:32:44.988558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:32:45.062144 [debug] [ThreadPool]: SQL status: BEGIN in 0.073 seconds
[0m14:32:45.062700 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:32:45.063128 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:32:45.072027 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m14:32:45.074003 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:32:45.074796 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:32:45.086285 [debug] [MainThread]: Using postgres connection "master"
[0m14:32:45.086830 [debug] [MainThread]: On master: BEGIN
[0m14:32:45.087186 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:32:45.161850 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m14:32:45.162387 [debug] [MainThread]: Using postgres connection "master"
[0m14:32:45.162949 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:32:45.171977 [debug] [MainThread]: SQL status: SELECT 5 in 0.008 seconds
[0m14:32:45.174924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A1778D2F70>]}
[0m14:32:45.175558 [debug] [MainThread]: On master: ROLLBACK
[0m14:32:45.176271 [debug] [MainThread]: Using postgres connection "master"
[0m14:32:45.176931 [debug] [MainThread]: On master: BEGIN
[0m14:32:45.178460 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m14:32:45.178963 [debug] [MainThread]: On master: COMMIT
[0m14:32:45.179368 [debug] [MainThread]: Using postgres connection "master"
[0m14:32:45.179721 [debug] [MainThread]: On master: COMMIT
[0m14:32:45.180381 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:32:45.180789 [debug] [MainThread]: On master: Close
[0m14:32:45.187037 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:32:45.187978 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:32:45.189109 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:32:45.189723 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:32:45.200201 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.202642 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:32:45.253666 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.255997 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.256624 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:32:45.257188 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:32:45.327557 [debug] [Thread-1 (]: SQL status: BEGIN in 0.070 seconds
[0m14:32:45.328121 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.328591 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:32:45.340457 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.011 seconds
[0m14:32:45.351627 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.352100 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:32:45.353243 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:32:45.356884 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.357523 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:32:45.358988 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:32:45.378733 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:32:45.379296 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.379709 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:32:45.381345 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:32:45.388330 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:32:45.394470 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:32:45.394925 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:32:45.400763 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m14:32:45.404481 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:32:45.407693 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A1773EBF50>]}
[0m14:32:45.408625 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.22s]
[0m14:32:45.410167 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:32:45.411306 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:32:45.411892 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:32:45.412411 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:32:45.413045 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:32:45.413807 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_slq ....................... [RUN]
[0m14:32:45.414560 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:32:45.415652 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:32:45.417540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_slq)
[0m14:32:45.416558 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:32:45.418272 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:32:45.418969 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:32:45.419576 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:32:45.420352 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:32:45.421014 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:32:45.421779 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:32:45.426828 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:32:45.427605 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:32:45.431476 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.435830 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:32:45.438980 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:32:45.441107 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:32:45.447051 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:32:45.448397 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:32:45.449031 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:32:45.449596 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:32:45.454853 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.459767 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:32:45.464609 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:32:45.465307 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:32:45.466386 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: BEGIN
[0m14:32:45.467001 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:32:45.468270 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.468948 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:32:45.469508 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:32:45.469927 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:32:45.470366 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:32:45.470813 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:32:45.471292 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:32:45.471902 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:32:45.472429 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:32:45.541058 [debug] [Thread-1 (]: SQL status: BEGIN in 0.074 seconds
[0m14:32:45.541903 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:32:45.542596 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_slq"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_slq__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
),

sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        -- trajanje isporuke u danima
        extract(epoch from (delivered_at - shipment_date))/86400 as delivery_duration_days,
        -- kasnjenje
        case 
            when delivered_at > expected_delivery_date then true
            else false
        end as late_delivery
    from base
)

select * from sla;
  );
  
[0m14:32:45.543861 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 44: select * from sla;
                          ^

[0m14:32:45.544491 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: ROLLBACK
[0m14:32:45.545347 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: Close
[0m14:32:45.555789 [debug] [Thread-1 (]: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:32:45.556540 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A17772FB70>]}
[0m14:32:45.557758 [debug] [Thread-4 (]: SQL status: BEGIN in 0.086 seconds
[0m14:32:45.557269 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_slq .............. [[31mERROR[0m in 0.14s]
[0m14:32:45.558507 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:32:45.559443 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:32:45.560200 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date::date as date,
    courier_id,
    sum(price) as total_revenue,
    count(shipment_id) as total_shipments
from base
group by 1, 2
order by 1, 2;
  );
  
[0m14:32:45.561054 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_slq' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql.
[0m14:32:45.562408 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 26: order by 1, 2;
                      ^

[0m14:32:45.562814 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: ROLLBACK
[0m14:32:45.563479 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:32:45.570702 [debug] [Thread-4 (]: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 26: order by 1, 2;
                        ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:32:45.571362 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A17775F890>]}
[0m14:32:45.572057 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.fct_shipments_revenue .......... [[31mERROR[0m in 0.15s]
[0m14:32:45.573132 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:32:45.573803 [debug] [Thread-3 (]: SQL status: BEGIN in 0.102 seconds
[0m14:32:45.574663 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_revenue' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 26: order by 1, 2;
                        ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql.
[0m14:32:45.575400 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.576259 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:32:45.585056 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.008 seconds
[0m14:32:45.588822 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.589252 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:32:45.590150 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m14:32:45.590614 [debug] [Thread-2 (]: SQL status: BEGIN in 0.118 seconds
[0m14:32:45.593963 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.594474 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:32:45.594925 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:32:45.595385 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipment_date)) / 86400) AS avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:32:45.596731 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:32:45.598350 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:32:45.598877 [debug] [Thread-2 (]: Postgres adapter: Postgres error: function pg_catalog.extract(unknown, integer) does not exist
LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                 ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m14:32:45.599325 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.599784 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:32:45.600243 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:32:45.601025 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:32:45.602410 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:32:45.604881 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:32:45.605659 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:32:45.606064 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:32:45.610070 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:32:45.610748 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A177B3DA50>]}
[0m14:32:45.611524 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.19s]
[0m14:32:45.612443 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:32:45.613042 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:32:45.617483 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.011 seconds
[0m14:32:45.619064 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:32:45.619749 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8544f83d-13f1-4b8d-b599-7afb5ac89319', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A177AB4130>]}
[0m14:32:45.620385 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.20s]
[0m14:32:45.621266 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:32:45.623262 [debug] [MainThread]: Using postgres connection "master"
[0m14:32:45.623655 [debug] [MainThread]: On master: BEGIN
[0m14:32:45.623959 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:32:45.696571 [debug] [MainThread]: SQL status: BEGIN in 0.073 seconds
[0m14:32:45.697098 [debug] [MainThread]: On master: COMMIT
[0m14:32:45.697411 [debug] [MainThread]: Using postgres connection "master"
[0m14:32:45.697705 [debug] [MainThread]: On master: COMMIT
[0m14:32:45.698211 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:32:45.698555 [debug] [MainThread]: On master: Close
[0m14:32:45.699093 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:32:45.699403 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:32:45.699668 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:32:45.699999 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_slq' was properly closed.
[0m14:32:45.700294 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:32:45.700638 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:32:45.700998 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:32:45.701482 [info ] [MainThread]: 
[0m14:32:45.702096 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.18 seconds (1.18s).
[0m14:32:45.703764 [debug] [MainThread]: Command end result
[0m14:32:45.730770 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:32:45.735363 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:32:45.743618 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:32:45.744290 [info ] [MainThread]: 
[0m14:32:45.745056 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m14:32:45.745720 [info ] [MainThread]: 
[0m14:32:45.746412 [error] [MainThread]: [31mFailure in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)[0m
[0m14:32:45.747096 [error] [MainThread]:   Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:32:45.747607 [info ] [MainThread]: 
[0m14:32:45.748243 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:32:45.748744 [info ] [MainThread]: 
[0m14:32:45.749382 [error] [MainThread]: [31mFailure in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)[0m
[0m14:32:45.749967 [error] [MainThread]:   Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 26: order by 1, 2;
                        ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:32:45.750491 [info ] [MainThread]: 
[0m14:32:45.750948 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:32:45.751385 [info ] [MainThread]: 
[0m14:32:45.752087 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:32:45.752861 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:32:45.753406 [info ] [MainThread]: 
[0m14:32:45.753918 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:32:45.754366 [info ] [MainThread]: 
[0m14:32:45.754898 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=5
[0m14:32:45.756639 [debug] [MainThread]: Command `dbt run` failed at 14:32:45.756508 after 3.40 seconds
[0m14:32:45.757082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A16F36D490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A177AF0EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A177B3BC50>]}
[0m14:32:45.757484 [debug] [MainThread]: Flushing usage events
[0m14:32:46.801814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:45:28.332397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130D070980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130DB1CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130E16BD90>]}


============================== 14:45:28.339019 | 502b1357-9fda-4efc-b783-3bc6e6169e06 ==============================
[0m14:45:28.339019 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:45:28.340779 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:45:28.654343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130D4D8770>]}
[0m14:45:28.745234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130E00EE00>]}
[0m14:45:28.747564 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:45:29.343316 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:45:29.559669 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m14:45:29.560783 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_revenue.sql
[0m14:45:29.561521 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:45:29.920024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130FB05850>]}
[0m14:45:30.013565 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:45:30.017831 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:45:30.057444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130DFFFD40>]}
[0m14:45:30.058286 [info ] [MainThread]: Found 13 models, 5 sources, 459 macros
[0m14:45:30.059287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130FC9E7B0>]}
[0m14:45:30.061824 [info ] [MainThread]: 
[0m14:45:30.062629 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:45:30.063409 [info ] [MainThread]: 
[0m14:45:30.064712 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:45:30.070942 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:45:30.350634 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:45:30.351120 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:45:30.351425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:30.480823 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.129 seconds
[0m14:45:30.482290 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:45:30.485471 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:45:30.492817 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:45:30.493239 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:45:30.493532 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:30.554270 [debug] [ThreadPool]: SQL status: BEGIN in 0.061 seconds
[0m14:45:30.554739 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:45:30.555047 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:45:30.561166 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m14:45:30.562767 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:45:30.563371 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:45:30.572476 [debug] [MainThread]: Using postgres connection "master"
[0m14:45:30.573117 [debug] [MainThread]: On master: BEGIN
[0m14:45:30.573572 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:45:30.630710 [debug] [MainThread]: SQL status: BEGIN in 0.057 seconds
[0m14:45:30.631230 [debug] [MainThread]: Using postgres connection "master"
[0m14:45:30.631682 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:45:30.639131 [debug] [MainThread]: SQL status: SELECT 5 in 0.007 seconds
[0m14:45:30.641198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130FEBF040>]}
[0m14:45:30.641694 [debug] [MainThread]: On master: ROLLBACK
[0m14:45:30.642285 [debug] [MainThread]: Using postgres connection "master"
[0m14:45:30.642657 [debug] [MainThread]: On master: BEGIN
[0m14:45:30.643398 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:45:30.643734 [debug] [MainThread]: On master: COMMIT
[0m14:45:30.644034 [debug] [MainThread]: Using postgres connection "master"
[0m14:45:30.644294 [debug] [MainThread]: On master: COMMIT
[0m14:45:30.644708 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:45:30.645014 [debug] [MainThread]: On master: Close
[0m14:45:30.650576 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:45:30.651179 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:45:30.652035 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:45:30.652416 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:45:30.660175 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.662024 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:45:30.704569 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.706510 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.706916 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:45:30.707277 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:45:30.768409 [debug] [Thread-1 (]: SQL status: BEGIN in 0.061 seconds
[0m14:45:30.769036 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.769498 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:45:30.778291 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.008 seconds
[0m14:45:30.788327 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.788791 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:45:30.789719 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:45:30.792582 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.793049 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:45:30.794311 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:45:30.809833 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:45:30.810345 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.810708 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:45:30.812761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m14:45:30.819043 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:45:30.823947 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:45:30.824329 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:45:30.828297 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m14:45:30.830809 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:45:30.833121 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130F9DFF50>]}
[0m14:45:30.833789 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.18s]
[0m14:45:30.834892 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:45:30.835844 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:45:30.836251 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:45:30.836812 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:45:30.837892 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:45:30.837422 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_slq ....................... [RUN]
[0m14:45:30.838871 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:45:30.840576 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_slq)
[0m14:45:30.839433 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:45:30.841309 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:45:30.841829 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:45:30.840073 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:45:30.842497 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:45:30.842983 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:45:30.845916 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:45:30.846718 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:45:30.847264 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:45:30.850158 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.850854 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:45:30.854824 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:45:30.857506 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:45:30.858724 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:45:30.862959 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:45:30.864165 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:45:30.864724 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:45:30.865349 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:45:30.869536 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:45:30.872829 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:45:30.876329 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.877310 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:45:30.877995 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: BEGIN
[0m14:45:30.878646 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:30.879655 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:45:30.880210 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:45:30.880649 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.881015 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:45:30.881619 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:45:30.882191 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:45:30.883870 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:45:30.883337 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:45:30.882741 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:45:30.950118 [debug] [Thread-1 (]: SQL status: BEGIN in 0.071 seconds
[0m14:45:30.950804 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:45:30.951198 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_slq"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_slq__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
),

sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        -- trajanje isporuke u danima
        extract(epoch from (delivered_at - shipment_date))/86400 as delivery_duration_days,
        -- kasnjenje
        case 
            when delivered_at > expected_delivery_date then true
            else false
        end as late_delivery
    from base
)

select * from sla;
  );
  
[0m14:45:30.952206 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 44: select * from sla;
                          ^

[0m14:45:30.952686 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: ROLLBACK
[0m14:45:30.953402 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: Close
[0m14:45:30.964316 [debug] [Thread-1 (]: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:45:30.965065 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130FD1BCD0>]}
[0m14:45:30.965738 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_slq .............. [[31mERROR[0m in 0.12s]
[0m14:45:30.966877 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:45:30.967613 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_slq' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql.
[0m14:45:30.968952 [debug] [Thread-3 (]: SQL status: BEGIN in 0.085 seconds
[0m14:45:30.969406 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.969838 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:45:30.978502 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.008 seconds
[0m14:45:30.983632 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.984339 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:45:30.984990 [debug] [Thread-2 (]: SQL status: BEGIN in 0.102 seconds
[0m14:45:30.985387 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:45:30.985802 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:45:30.988716 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.989245 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    avg(expected_delivery_date - shipment_date) as avg_delivery_days
from fct
group by courier_id;
  );
  
[0m14:45:30.989805 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:45:30.990809 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 23: group by courier_id;
                            ^

[0m14:45:30.991273 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:45:30.991724 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:45:30.993349 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:45:30.994060 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:30.994557 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:45:30.994959 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:45:30.995362 [debug] [Thread-4 (]: SQL status: BEGIN in 0.113 seconds
[0m14:45:30.995969 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:45:30.997632 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date::date as date,
    courier_id,
    sum(price) as total_revenue,
    count(shipment_id) as total_shipments
from base
group by shipment_date::date, courier_id;
  );
  
[0m14:45:30.998151 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:45:31.000676 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:45:31.001179 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 25: group by shipment_date::date, courier_id;
                                                 ^

[0m14:45:31.001905 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:45:31.002346 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: ROLLBACK
[0m14:45:31.002862 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:45:31.003746 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:45:31.008279 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 23: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:45:31.008907 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131013F7F0>]}
[0m14:45:31.009621 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.16s]
[0m14:45:31.010564 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:45:31.011142 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 23: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:45:31.013878 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.010 seconds
[0m14:45:31.015804 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:45:31.016585 [debug] [Thread-4 (]: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 25: group by shipment_date::date, courier_id;
                                                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:45:31.017161 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130FC1DF50>]}
[0m14:45:31.017710 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '502b1357-9fda-4efc-b783-3bc6e6169e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131012E450>]}
[0m14:45:31.018523 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.fct_shipments_revenue .......... [[31mERROR[0m in 0.17s]
[0m14:45:31.020133 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:45:31.019138 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.18s]
[0m14:45:31.021186 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_revenue' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 25: group by shipment_date::date, courier_id;
                                                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql.
[0m14:45:31.021976 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:45:31.024145 [debug] [MainThread]: Using postgres connection "master"
[0m14:45:31.024701 [debug] [MainThread]: On master: BEGIN
[0m14:45:31.025033 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:45:31.087102 [debug] [MainThread]: SQL status: BEGIN in 0.062 seconds
[0m14:45:31.087646 [debug] [MainThread]: On master: COMMIT
[0m14:45:31.088002 [debug] [MainThread]: Using postgres connection "master"
[0m14:45:31.088333 [debug] [MainThread]: On master: COMMIT
[0m14:45:31.089105 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:45:31.089536 [debug] [MainThread]: On master: Close
[0m14:45:31.090106 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:45:31.090413 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:45:31.090660 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:45:31.090963 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_slq' was properly closed.
[0m14:45:31.091209 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:45:31.091445 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:45:31.091691 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:45:31.092060 [info ] [MainThread]: 
[0m14:45:31.092716 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m14:45:31.094604 [debug] [MainThread]: Command end result
[0m14:45:31.122058 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:45:31.125547 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:45:31.133842 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:45:31.134398 [info ] [MainThread]: 
[0m14:45:31.135103 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m14:45:31.135736 [info ] [MainThread]: 
[0m14:45:31.136362 [error] [MainThread]: [31mFailure in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)[0m
[0m14:45:31.136958 [error] [MainThread]:   Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:45:31.137529 [info ] [MainThread]: 
[0m14:45:31.138083 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:45:31.138707 [info ] [MainThread]: 
[0m14:45:31.139332 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:45:31.140014 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 23: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:45:31.140563 [info ] [MainThread]: 
[0m14:45:31.141154 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:45:31.141665 [info ] [MainThread]: 
[0m14:45:31.142212 [error] [MainThread]: [31mFailure in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)[0m
[0m14:45:31.142786 [error] [MainThread]:   Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 25: group by shipment_date::date, courier_id;
                                                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:45:31.143303 [info ] [MainThread]: 
[0m14:45:31.143837 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:45:31.144325 [info ] [MainThread]: 
[0m14:45:31.144976 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=5
[0m14:45:31.146715 [debug] [MainThread]: Command `dbt run` failed at 14:45:31.146570 after 3.13 seconds
[0m14:45:31.147145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130B973410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002130DAE6C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000213100DF7D0>]}
[0m14:45:31.147559 [debug] [MainThread]: Flushing usage events
[0m14:45:32.247789 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:08.362173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2A200980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2ACACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2B2E7D90>]}


============================== 14:47:08.370940 | 7bb128af-578b-4928-9a25-d3a428293717 ==============================
[0m14:47:08.370940 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:47:08.372336 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:47:08.744653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2A668770>]}
[0m14:47:08.844282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2B18EE00>]}
[0m14:47:08.846799 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:47:09.516210 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:47:09.742065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:47:09.743130 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:47:10.103354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2CCD5950>]}
[0m14:47:10.194084 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:47:10.199115 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:47:10.241207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2B17FD40>]}
[0m14:47:10.242050 [info ] [MainThread]: Found 13 models, 5 sources, 459 macros
[0m14:47:10.242920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2CE6E6D0>]}
[0m14:47:10.245714 [info ] [MainThread]: 
[0m14:47:10.246376 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:47:10.246980 [info ] [MainThread]: 
[0m14:47:10.248097 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:47:10.253714 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:47:10.509460 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:47:10.509903 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:47:10.510281 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:10.651384 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.141 seconds
[0m14:47:10.654083 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:47:10.657208 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:47:10.664653 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:47:10.665196 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:47:10.665548 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:10.729200 [debug] [ThreadPool]: SQL status: BEGIN in 0.064 seconds
[0m14:47:10.729689 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:47:10.730008 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:47:10.736798 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m14:47:10.738382 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:47:10.739067 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:47:10.746152 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:10.746555 [debug] [MainThread]: On master: BEGIN
[0m14:47:10.746848 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:10.809602 [debug] [MainThread]: SQL status: BEGIN in 0.063 seconds
[0m14:47:10.810107 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:10.810492 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:47:10.817590 [debug] [MainThread]: SQL status: SELECT 5 in 0.007 seconds
[0m14:47:10.819608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D09B040>]}
[0m14:47:10.820184 [debug] [MainThread]: On master: ROLLBACK
[0m14:47:10.820891 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:10.821246 [debug] [MainThread]: On master: BEGIN
[0m14:47:10.822031 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:47:10.822417 [debug] [MainThread]: On master: COMMIT
[0m14:47:10.822759 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:10.823034 [debug] [MainThread]: On master: COMMIT
[0m14:47:10.823547 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:10.823869 [debug] [MainThread]: On master: Close
[0m14:47:10.828146 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:47:10.828789 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:47:10.829537 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:47:10.829912 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:47:10.838560 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.840550 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:47:10.880785 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.883145 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.883961 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:47:10.884636 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:47:10.948780 [debug] [Thread-1 (]: SQL status: BEGIN in 0.064 seconds
[0m14:47:10.949572 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.950153 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:47:10.960602 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.010 seconds
[0m14:47:10.970816 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.971251 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:47:10.972350 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:47:10.975268 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.975631 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:47:10.976640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:47:10.993798 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:47:10.994377 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:10.994738 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:47:10.996093 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:47:11.004017 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:47:11.009085 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:11.009536 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:47:11.014006 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m14:47:11.017531 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:47:11.020367 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2CC53590>]}
[0m14:47:11.021398 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.19s]
[0m14:47:11.022535 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:47:11.023540 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:11.023988 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:47:11.025006 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:11.025616 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:11.024587 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_slq ....................... [RUN]
[0m14:47:11.026237 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:47:11.028103 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_slq)
[0m14:47:11.026760 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:47:11.028990 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:47:11.029505 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:11.027383 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:47:11.030208 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:47:11.030638 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:47:11.033548 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:11.034218 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:47:11.034682 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:11.037627 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:47:11.038410 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:11.042494 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.045241 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:11.046530 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:11.050351 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:11.051791 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:11.056230 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.056840 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:47:11.061106 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:47:11.061565 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:11.062282 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:11.065908 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:11.066493 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: BEGIN
[0m14:47:11.067373 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:47:11.068245 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:47:11.068709 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:47:11.069253 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:47:11.070029 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.070633 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:47:11.071354 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:47:11.073373 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:11.074075 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:47:11.074751 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:47:11.138533 [debug] [Thread-1 (]: SQL status: BEGIN in 0.071 seconds
[0m14:47:11.139094 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:11.139485 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_slq"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_slq__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
),

sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        -- trajanje isporuke u danima
        extract(epoch from (delivered_at - shipment_date))/86400 as delivery_duration_days,
        -- kasnjenje
        case 
            when delivered_at > expected_delivery_date then true
            else false
        end as late_delivery
    from base
)

select * from sla;
  );
  
[0m14:47:11.140369 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 44: select * from sla;
                          ^

[0m14:47:11.140839 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: ROLLBACK
[0m14:47:11.141531 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: Close
[0m14:47:11.153074 [debug] [Thread-1 (]: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:47:11.154049 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D2909F0>]}
[0m14:47:11.155018 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_slq .............. [[31mERROR[0m in 0.13s]
[0m14:47:11.156093 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:11.156789 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_slq' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql.
[0m14:47:11.159759 [debug] [Thread-2 (]: SQL status: BEGIN in 0.090 seconds
[0m14:47:11.160205 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:47:11.160588 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(shipment_id) as total_shipments,
    sum(case when not late_delivery then 1 else 0 end) as on_time_deliveries,
    sum(case when late_delivery then 1 else 0 end) as late_deliveries,
    avg(delivery_duration_days) as avg_delivery_days
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id;
  );
  
[0m14:47:11.161416 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: group by courier_id;
                            ^

[0m14:47:11.161878 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:47:11.162604 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:47:11.168899 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:47:11.169688 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2CF1BF70>]}
[0m14:47:11.170681 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.14s]
[0m14:47:11.171601 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:47:11.172274 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:47:11.175401 [debug] [Thread-3 (]: SQL status: BEGIN in 0.104 seconds
[0m14:47:11.175986 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.176416 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:47:11.183179 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.006 seconds
[0m14:47:11.188029 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.188646 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:47:11.189364 [debug] [Thread-4 (]: SQL status: BEGIN in 0.115 seconds
[0m14:47:11.189773 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:47:11.190157 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:11.193037 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.193531 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date::date as date,
    courier_id,
    sum(price) as total_revenue,
    count(shipment_id) as total_shipments
from base
group by shipment_date::date, courier_id;
  );
  
[0m14:47:11.194053 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:47:11.195076 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 25: group by shipment_date::date, courier_id;
                                                 ^

[0m14:47:11.195465 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:47:11.195889 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: ROLLBACK
[0m14:47:11.197687 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:47:11.198157 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.198654 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:47:11.199139 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:47:11.201006 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:47:11.204156 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:47:11.205447 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:11.206102 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:47:11.209950 [debug] [Thread-4 (]: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 25: group by shipment_date::date, courier_id;
                                                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:11.210525 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D301A50>]}
[0m14:47:11.211144 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.fct_shipments_revenue .......... [[31mERROR[0m in 0.18s]
[0m14:47:11.212100 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:11.212770 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_revenue' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 25: group by shipment_date::date, courier_id;
                                                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql.
[0m14:47:11.216134 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.009 seconds
[0m14:47:11.217943 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:47:11.218679 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bb128af-578b-4928-9a25-d3a428293717', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D22C9F0>]}
[0m14:47:11.219429 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.19s]
[0m14:47:11.220488 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:11.222379 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:11.222758 [debug] [MainThread]: On master: BEGIN
[0m14:47:11.223048 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:47:11.288683 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m14:47:11.289148 [debug] [MainThread]: On master: COMMIT
[0m14:47:11.289453 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:11.289740 [debug] [MainThread]: On master: COMMIT
[0m14:47:11.290235 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:11.290557 [debug] [MainThread]: On master: Close
[0m14:47:11.291060 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:47:11.291345 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:47:11.291612 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:47:11.291986 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_slq' was properly closed.
[0m14:47:11.292321 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:47:11.292611 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:47:11.292870 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:47:11.293222 [info ] [MainThread]: 
[0m14:47:11.293838 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m14:47:11.295661 [debug] [MainThread]: Command end result
[0m14:47:11.322627 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:47:11.326147 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:47:11.334035 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:47:11.334676 [info ] [MainThread]: 
[0m14:47:11.335361 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m14:47:11.336061 [info ] [MainThread]: 
[0m14:47:11.336721 [error] [MainThread]: [31mFailure in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)[0m
[0m14:47:11.337364 [error] [MainThread]:   Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:47:11.337873 [info ] [MainThread]: 
[0m14:47:11.338469 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:47:11.339058 [info ] [MainThread]: 
[0m14:47:11.339636 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:47:11.340258 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:47:11.340813 [info ] [MainThread]: 
[0m14:47:11.341479 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:47:11.342070 [info ] [MainThread]: 
[0m14:47:11.342731 [error] [MainThread]: [31mFailure in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)[0m
[0m14:47:11.343342 [error] [MainThread]:   Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 25: group by shipment_date::date, courier_id;
                                                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:11.343947 [info ] [MainThread]: 
[0m14:47:11.344616 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:11.345122 [info ] [MainThread]: 
[0m14:47:11.345573 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=5
[0m14:47:11.347069 [debug] [MainThread]: Command `dbt run` failed at 14:47:11.346944 after 3.32 seconds
[0m14:47:11.347507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D2CB950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D2FFA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E2D2FF9B0>]}
[0m14:47:11.347906 [debug] [MainThread]: Flushing usage events
[0m14:47:12.459467 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:30.495456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544D630980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544E0ECB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544E727D90>]}


============================== 14:47:30.501600 | f9230324-1487-48e3-8994-224429bee8d2 ==============================
[0m14:47:30.501600 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:47:30.503162 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:47:30.821337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544DA98770>]}
[0m14:47:30.914357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544E5CEE00>]}
[0m14:47:30.916434 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:47:31.481770 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:47:31.681843 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:47:31.682710 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:31.987664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015450029950>]}
[0m14:47:32.079083 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:47:32.084575 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:47:32.130930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544E5BFD40>]}
[0m14:47:32.131650 [info ] [MainThread]: Found 13 models, 5 sources, 459 macros
[0m14:47:32.132318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154501B2970>]}
[0m14:47:32.134647 [info ] [MainThread]: 
[0m14:47:32.135380 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:47:32.136229 [info ] [MainThread]: 
[0m14:47:32.137230 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:47:32.142317 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:47:32.389226 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:47:32.389670 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:47:32.389963 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:32.526652 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.137 seconds
[0m14:47:32.528515 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:47:32.531394 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:47:32.538460 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:47:32.538890 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:47:32.539184 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:32.602121 [debug] [ThreadPool]: SQL status: BEGIN in 0.063 seconds
[0m14:47:32.602592 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:47:32.602910 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:47:32.609034 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m14:47:32.610661 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:47:32.611371 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:47:32.619695 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:32.620226 [debug] [MainThread]: On master: BEGIN
[0m14:47:32.620581 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:32.682876 [debug] [MainThread]: SQL status: BEGIN in 0.062 seconds
[0m14:47:32.683312 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:32.683673 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:47:32.691934 [debug] [MainThread]: SQL status: SELECT 5 in 0.008 seconds
[0m14:47:32.693960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154503FB040>]}
[0m14:47:32.694456 [debug] [MainThread]: On master: ROLLBACK
[0m14:47:32.695243 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:32.695554 [debug] [MainThread]: On master: BEGIN
[0m14:47:32.696297 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:47:32.696612 [debug] [MainThread]: On master: COMMIT
[0m14:47:32.696932 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:32.697223 [debug] [MainThread]: On master: COMMIT
[0m14:47:32.697707 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:32.698074 [debug] [MainThread]: On master: Close
[0m14:47:32.703397 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:47:32.704244 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:47:32.705360 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:47:32.706118 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:47:32.713615 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.716706 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:47:32.755813 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.757756 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.758206 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:47:32.758545 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:47:32.819327 [debug] [Thread-1 (]: SQL status: BEGIN in 0.061 seconds
[0m14:47:32.819830 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.820430 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:47:32.827821 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.007 seconds
[0m14:47:32.838750 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.839398 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:47:32.840359 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m14:47:32.843503 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.843864 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:47:32.845002 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:47:32.863177 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:47:32.863808 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.864301 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:47:32.865808 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:47:32.874074 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:47:32.878830 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:47:32.879274 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:47:32.884413 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m14:47:32.886820 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:47:32.889276 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544FFA3590>]}
[0m14:47:32.890070 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.18s]
[0m14:47:32.891313 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:47:32.892209 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:32.892615 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:32.892986 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:32.893372 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:47:32.893840 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_slq ....................... [RUN]
[0m14:47:32.896546 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_slq)
[0m14:47:32.894426 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:47:32.897230 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:32.895176 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:47:32.898067 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:47:32.902620 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:32.900810 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:32.902015 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:47:32.895962 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:47:32.907427 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:32.908218 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:32.908997 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:47:32.910115 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:32.914089 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:32.914549 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:47:32.917574 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:32.924553 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:32.927175 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:47:32.931214 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:32.931990 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:32.936842 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:32.939963 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:32.940646 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: BEGIN
[0m14:47:32.941176 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:47:32.942110 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:47:32.947083 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:32.947762 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:32.948440 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:47:32.949078 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:47:32.949638 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:47:32.950386 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:47:32.950924 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:47:32.953064 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:47:32.953795 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:47:32.954270 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:47:33.027131 [debug] [Thread-1 (]: SQL status: BEGIN in 0.086 seconds
[0m14:47:33.027765 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:47:33.028324 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_slq"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_slq__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
),

sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        -- trajanje isporuke u danima
        extract(epoch from (delivered_at - shipment_date))/86400 as delivery_duration_days,
        -- kasnjenje
        case 
            when delivered_at > expected_delivery_date then true
            else false
        end as late_delivery
    from base
)

select * from sla;
  );
  
[0m14:47:33.029365 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 44: select * from sla;
                          ^

[0m14:47:33.029877 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: ROLLBACK
[0m14:47:33.030589 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: Close
[0m14:47:33.041438 [debug] [Thread-1 (]: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:47:33.042301 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154505F8AA0>]}
[0m14:47:33.042964 [debug] [Thread-3 (]: SQL status: BEGIN in 0.092 seconds
[0m14:47:33.044420 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:33.043802 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_slq .............. [[31mERROR[0m in 0.15s]
[0m14:47:33.045067 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:47:33.045990 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:47:33.046967 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_slq' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql.
[0m14:47:33.053626 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.007 seconds
[0m14:47:33.057020 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:33.057466 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:47:33.058289 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m14:47:33.058667 [debug] [Thread-4 (]: SQL status: BEGIN in 0.108 seconds
[0m14:47:33.061559 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:33.062266 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:47:33.062857 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:47:33.063467 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    shipment_date,
    courier_id,
    sum(price) as total_revenue,
    count(shipment_id) as total_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by shipment_date, courier_id;
  );
  
[0m14:47:33.064730 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 20: group by shipment_date, courier_id;
                                           ^

[0m14:47:33.065152 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: ROLLBACK
[0m14:47:33.065595 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:47:33.068079 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:47:33.068780 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:47:33.069329 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:33.069982 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:47:33.073498 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:47:33.076448 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:47:33.080186 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:47:33.081133 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:47:33.081725 [debug] [Thread-2 (]: SQL status: BEGIN in 0.127 seconds
[0m14:47:33.083405 [debug] [Thread-4 (]: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:33.084108 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:47:33.084790 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544FC73110>]}
[0m14:47:33.085383 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(shipment_id) as total_shipments,
    sum(case when not late_delivery then 1 else 0 end) as on_time_deliveries,
    sum(case when late_delivery then 1 else 0 end) as late_deliveries,
    avg(delivery_duration_days) as avg_delivery_days
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id;
  );
  
[0m14:47:33.086622 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.fct_shipments_revenue .......... [[31mERROR[0m in 0.18s]
[0m14:47:33.087720 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:47:33.088230 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: group by courier_id;
                            ^

[0m14:47:33.088856 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_revenue' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql.
[0m14:47:33.089259 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:47:33.089702 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m14:47:33.091441 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:47:33.091908 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:47:33.092694 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154504FB650>]}
[0m14:47:33.094860 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.19s]
[0m14:47:33.096247 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:47:33.101405 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:47:33.102262 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9230324-1487-48e3-8994-224429bee8d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154505C7310>]}
[0m14:47:33.103437 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.19s]
[0m14:47:33.104722 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:47:33.105590 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:47:33.107341 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:33.107788 [debug] [MainThread]: On master: BEGIN
[0m14:47:33.108223 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:47:33.180745 [debug] [MainThread]: SQL status: BEGIN in 0.072 seconds
[0m14:47:33.181264 [debug] [MainThread]: On master: COMMIT
[0m14:47:33.181625 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:33.181909 [debug] [MainThread]: On master: COMMIT
[0m14:47:33.182399 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:33.182921 [debug] [MainThread]: On master: Close
[0m14:47:33.183904 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:47:33.184195 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:47:33.184465 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:47:33.184813 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_slq' was properly closed.
[0m14:47:33.185077 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:47:33.185323 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:47:33.185587 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:47:33.186012 [info ] [MainThread]: 
[0m14:47:33.186546 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m14:47:33.188240 [debug] [MainThread]: Command end result
[0m14:47:33.221154 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:47:33.224606 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:47:33.231585 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:47:33.231958 [info ] [MainThread]: 
[0m14:47:33.232596 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m14:47:33.233338 [info ] [MainThread]: 
[0m14:47:33.234011 [error] [MainThread]: [31mFailure in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)[0m
[0m14:47:33.234668 [error] [MainThread]:   Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:47:33.235202 [info ] [MainThread]: 
[0m14:47:33.235944 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:47:33.236504 [info ] [MainThread]: 
[0m14:47:33.237179 [error] [MainThread]: [31mFailure in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)[0m
[0m14:47:33.237826 [error] [MainThread]:   Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:33.238383 [info ] [MainThread]: 
[0m14:47:33.238979 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:47:33.239610 [info ] [MainThread]: 
[0m14:47:33.240240 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:47:33.240824 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:47:33.241373 [info ] [MainThread]: 
[0m14:47:33.241961 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:47:33.242490 [info ] [MainThread]: 
[0m14:47:33.243038 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=5
[0m14:47:33.244646 [debug] [MainThread]: Command `dbt run` failed at 14:47:33.244512 after 2.97 seconds
[0m14:47:33.245075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001544E056B70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154506D3E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000154506D38F0>]}
[0m14:47:33.245483 [debug] [MainThread]: Flushing usage events
[0m14:47:34.340578 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:48:03.843079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018076B14980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000180775BCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018077C0BD90>]}


============================== 14:48:03.849372 | da51ae77-19b5-4e16-8580-b8ff0d7fd567 ==============================
[0m14:48:03.849372 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:48:03.850919 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:48:04.163952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018076F78770>]}
[0m14:48:04.250426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018077AAEE00>]}
[0m14:48:04.252266 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:48:04.859190 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:48:05.071290 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:48:05.071822 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:48:05.125016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018079508250>]}
[0m14:48:05.229621 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:48:05.238284 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:48:05.316708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018077A9FD40>]}
[0m14:48:05.317581 [info ] [MainThread]: Found 13 models, 5 sources, 459 macros
[0m14:48:05.318467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000180790B58D0>]}
[0m14:48:05.321316 [info ] [MainThread]: 
[0m14:48:05.322086 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:48:05.322750 [info ] [MainThread]: 
[0m14:48:05.323673 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:48:05.328984 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:48:05.532760 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:48:05.533331 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:48:05.533839 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:48:05.716618 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.183 seconds
[0m14:48:05.718380 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:48:05.721588 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:48:05.729584 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:48:05.730128 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:48:05.730493 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:48:05.812552 [debug] [ThreadPool]: SQL status: BEGIN in 0.082 seconds
[0m14:48:05.813180 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:48:05.813593 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:48:05.821842 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m14:48:05.823649 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:48:05.824444 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:48:05.833314 [debug] [MainThread]: Using postgres connection "master"
[0m14:48:05.833842 [debug] [MainThread]: On master: BEGIN
[0m14:48:05.834330 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:48:05.907632 [debug] [MainThread]: SQL status: BEGIN in 0.073 seconds
[0m14:48:05.908172 [debug] [MainThread]: Using postgres connection "master"
[0m14:48:05.908613 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:48:05.918391 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m14:48:05.920080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018079950120>]}
[0m14:48:05.920650 [debug] [MainThread]: On master: ROLLBACK
[0m14:48:05.921389 [debug] [MainThread]: Using postgres connection "master"
[0m14:48:05.921873 [debug] [MainThread]: On master: BEGIN
[0m14:48:05.922870 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m14:48:05.923268 [debug] [MainThread]: On master: COMMIT
[0m14:48:05.923643 [debug] [MainThread]: Using postgres connection "master"
[0m14:48:05.923988 [debug] [MainThread]: On master: COMMIT
[0m14:48:05.924508 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:48:05.924895 [debug] [MainThread]: On master: Close
[0m14:48:05.931711 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:48:05.932750 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:48:05.934009 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:48:05.934523 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:48:05.944182 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:05.947019 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:48:05.994807 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:05.997103 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:05.997655 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:48:05.998215 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:48:06.173810 [debug] [Thread-1 (]: SQL status: BEGIN in 0.175 seconds
[0m14:48:06.174444 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:06.174891 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:48:06.184018 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.009 seconds
[0m14:48:06.195634 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:06.196098 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:48:06.197219 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:48:06.200417 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:06.200845 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:48:06.202168 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:48:06.220868 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:48:06.221387 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:06.221795 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:48:06.254401 [debug] [Thread-1 (]: SQL status: COMMIT in 0.032 seconds
[0m14:48:06.261875 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:48:06.267761 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:48:06.268209 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:48:06.272944 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m14:48:06.275664 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:48:06.278726 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001807958F350>]}
[0m14:48:06.279598 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.34s]
[0m14:48:06.280789 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:48:06.281846 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:48:06.282332 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:48:06.282817 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:48:06.283308 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:48:06.283961 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_slq ....................... [RUN]
[0m14:48:06.284750 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:48:06.287227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_slq)
[0m14:48:06.285552 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:48:06.288239 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:48:06.288855 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:48:06.286365 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:48:06.289762 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:48:06.290362 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:48:06.294511 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:48:06.295456 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:48:06.296090 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:48:06.300250 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:48:06.301553 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:48:06.306075 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:48:06.310055 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.311404 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:48:06.316073 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:48:06.317795 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:48:06.327071 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.327638 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:48:06.399685 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:48:06.400929 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:48:06.401768 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:48:06.405750 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:48:06.406835 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: BEGIN
[0m14:48:06.407678 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:48:06.408243 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.408950 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:48:06.409601 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:48:06.410176 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:48:06.411022 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:48:06.411730 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:48:06.412447 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:48:06.413626 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:48:06.414327 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:48:06.495557 [debug] [Thread-1 (]: SQL status: BEGIN in 0.086 seconds
[0m14:48:06.496138 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:48:06.496682 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_slq"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_slq__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
),

sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        -- trajanje isporuke u danima
        extract(epoch from (delivered_at - shipment_date))/86400 as delivery_duration_days,
        -- kasnjenje
        case 
            when delivered_at > expected_delivery_date then true
            else false
        end as late_delivery
    from base
)

select * from sla;
  );
  
[0m14:48:06.497916 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 44: select * from sla;
                          ^

[0m14:48:06.498459 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: ROLLBACK
[0m14:48:06.499313 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: Close
[0m14:48:06.513685 [debug] [Thread-1 (]: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:48:06.514504 [debug] [Thread-2 (]: SQL status: BEGIN in 0.104 seconds
[0m14:48:06.515210 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001807959F3E0>]}
[0m14:48:06.515889 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:48:06.517576 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(shipment_id) as total_shipments,
    sum(case when not late_delivery then 1 else 0 end) as on_time_deliveries,
    sum(case when late_delivery then 1 else 0 end) as late_deliveries,
    avg(delivery_duration_days) as avg_delivery_days
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id;
  );
  
[0m14:48:06.516864 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_slq .............. [[31mERROR[0m in 0.23s]
[0m14:48:06.518719 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:48:06.519259 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: group by courier_id;
                            ^

[0m14:48:06.520280 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_slq' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql.
[0m14:48:06.520995 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:48:06.522991 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:48:06.532158 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:48:06.533072 [debug] [Thread-3 (]: SQL status: BEGIN in 0.121 seconds
[0m14:48:06.533844 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000180791B9EF0>]}
[0m14:48:06.534664 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.536509 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:48:06.535787 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.25s]
[0m14:48:06.537651 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:48:06.538457 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:48:06.544875 [debug] [Thread-4 (]: SQL status: BEGIN in 0.131 seconds
[0m14:48:06.545566 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.008 seconds
[0m14:48:06.546162 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:48:06.551494 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.552154 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    shipment_date,
    courier_id,
    sum(price) as total_revenue,
    count(shipment_id) as total_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by shipment_date, courier_id;
  );
  
[0m14:48:06.552687 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:48:06.553904 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 20: group by shipment_date, courier_id;
                                           ^

[0m14:48:06.554371 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:48:06.554809 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: ROLLBACK
[0m14:48:06.558274 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.558932 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:48:06.559602 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:48:06.561247 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:48:06.563397 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:48:06.564213 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.564797 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:48:06.567221 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:48:06.570487 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:48:06.571439 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:48:06.574076 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:48:06.575178 [debug] [Thread-4 (]: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:48:06.575764 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018079A24550>]}
[0m14:48:06.576481 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.fct_shipments_revenue .......... [[31mERROR[0m in 0.29s]
[0m14:48:06.577425 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:48:06.578065 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_revenue' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql.
[0m14:48:06.579521 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.005 seconds
[0m14:48:06.581179 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:48:06.582173 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da51ae77-19b5-4e16-8580-b8ff0d7fd567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000180799AE7B0>]}
[0m14:48:06.583395 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.29s]
[0m14:48:06.584400 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:48:06.586400 [debug] [MainThread]: Using postgres connection "master"
[0m14:48:06.586810 [debug] [MainThread]: On master: BEGIN
[0m14:48:06.587168 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:48:06.661379 [debug] [MainThread]: SQL status: BEGIN in 0.074 seconds
[0m14:48:06.661991 [debug] [MainThread]: On master: COMMIT
[0m14:48:06.662427 [debug] [MainThread]: Using postgres connection "master"
[0m14:48:06.662835 [debug] [MainThread]: On master: COMMIT
[0m14:48:06.663730 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:48:06.664336 [debug] [MainThread]: On master: Close
[0m14:48:06.665180 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:48:06.665620 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:48:06.665973 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:48:06.666305 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_slq' was properly closed.
[0m14:48:06.666600 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:48:06.666922 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:48:06.667246 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:48:06.667700 [info ] [MainThread]: 
[0m14:48:06.668393 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.34 seconds (1.34s).
[0m14:48:06.670397 [debug] [MainThread]: Command end result
[0m14:48:06.699776 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:48:06.704432 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:48:06.713009 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:48:06.713590 [info ] [MainThread]: 
[0m14:48:06.714429 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m14:48:06.715292 [info ] [MainThread]: 
[0m14:48:06.716011 [error] [MainThread]: [31mFailure in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)[0m
[0m14:48:06.716725 [error] [MainThread]:   Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:48:06.717331 [info ] [MainThread]: 
[0m14:48:06.718013 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:48:06.718633 [info ] [MainThread]: 
[0m14:48:06.719425 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:48:06.720682 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:48:06.721547 [info ] [MainThread]: 
[0m14:48:06.722274 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:48:06.723201 [info ] [MainThread]: 
[0m14:48:06.724077 [error] [MainThread]: [31mFailure in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)[0m
[0m14:48:06.724975 [error] [MainThread]:   Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:48:06.726186 [info ] [MainThread]: 
[0m14:48:06.727161 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:48:06.727918 [info ] [MainThread]: 
[0m14:48:06.728651 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=5
[0m14:48:06.731532 [debug] [MainThread]: Command `dbt run` failed at 14:48:06.731362 after 3.09 seconds
[0m14:48:06.732066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018077B03590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000180799CB5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000180799F3CB0>]}
[0m14:48:06.732582 [debug] [MainThread]: Flushing usage events
[0m14:48:07.890207 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:46.854349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FC6B0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FD16CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FD7ABD90>]}


============================== 14:50:46.861608 | 962452bc-04ab-4bcf-bc5d-d0f894629020 ==============================
[0m14:50:46.861608 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:50:46.863499 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:50:47.211757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FCB18770>]}
[0m14:50:47.325331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FD64EE00>]}
[0m14:50:47.328142 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:50:47.968899 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:50:48.194737 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:50:48.195503 [debug] [MainThread]: Partial parsing: added file: dbt_delivery_analytics://models\schema.yml
[0m14:50:48.437845 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m14:50:48.438750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF194B50>]}
[0m14:50:48.543986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF0BF6B0>]}
[0m14:50:48.637925 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:50:48.641615 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:50:48.761857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FEEDC050>]}
[0m14:50:48.762458 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m14:50:48.763158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF3C6680>]}
[0m14:50:48.765611 [info ] [MainThread]: 
[0m14:50:48.766089 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:50:48.766559 [info ] [MainThread]: 
[0m14:50:48.767389 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:50:48.771463 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:50:48.927406 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:50:48.928256 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:50:48.928882 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:49.071807 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.143 seconds
[0m14:50:49.073390 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:50:49.075968 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:50:49.081833 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:50:49.082312 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:50:49.082635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:49.155979 [debug] [ThreadPool]: SQL status: BEGIN in 0.073 seconds
[0m14:50:49.156461 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:50:49.156784 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:50:49.165874 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.009 seconds
[0m14:50:49.167538 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:50:49.168071 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:50:49.174826 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:49.175322 [debug] [MainThread]: On master: BEGIN
[0m14:50:49.175614 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:49.248512 [debug] [MainThread]: SQL status: BEGIN in 0.073 seconds
[0m14:50:49.249025 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:49.249470 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:50:49.258082 [debug] [MainThread]: SQL status: SELECT 5 in 0.008 seconds
[0m14:50:49.260044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF698290>]}
[0m14:50:49.260514 [debug] [MainThread]: On master: ROLLBACK
[0m14:50:49.261082 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:49.261397 [debug] [MainThread]: On master: BEGIN
[0m14:50:49.262113 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:50:49.262533 [debug] [MainThread]: On master: COMMIT
[0m14:50:49.262905 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:49.263253 [debug] [MainThread]: On master: COMMIT
[0m14:50:49.263774 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:50:49.264166 [debug] [MainThread]: On master: Close
[0m14:50:49.268840 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:50:49.269457 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:50:49.270324 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:50:49.270858 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:50:49.279364 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.281382 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:50:49.322048 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.324120 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.324700 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:50:49.325039 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:50:49.391935 [debug] [Thread-1 (]: SQL status: BEGIN in 0.067 seconds
[0m14:50:49.392505 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.392969 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:50:49.403849 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.010 seconds
[0m14:50:49.415232 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.415810 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:50:49.416760 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:50:49.420028 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.420535 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:50:49.421806 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:50:49.437294 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:50:49.437744 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.438073 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:50:49.439613 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:50:49.446076 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:50:49.451180 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:50:49.451671 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:50:49.456848 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m14:50:49.459300 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:50:49.461607 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF68D180>]}
[0m14:50:49.462422 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.19s]
[0m14:50:49.463519 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:50:49.464495 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:50:49.465003 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:50:49.465433 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:50:49.466392 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:50:49.465974 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_slq ....................... [RUN]
[0m14:50:49.467123 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:50:49.467783 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:50:49.469000 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_slq)
[0m14:50:49.468281 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:50:49.469832 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:50:49.470446 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:50:49.470988 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:50:49.471705 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:50:49.472252 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:50:49.472676 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:50:49.476104 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:50:49.476672 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:50:49.479264 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.482032 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:50:49.484958 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:50:49.486968 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:50:49.491429 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:50:49.492439 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:50:49.493035 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:50:49.493554 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:50:49.497099 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:50:49.500871 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:50:49.504979 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.505512 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:50:49.506277 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: BEGIN
[0m14:50:49.506763 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:49.507964 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:50:49.508595 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:50:49.509083 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:50:49.509504 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:50:49.509982 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:50:49.510511 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.510960 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:50:49.511818 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:50:49.512656 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:50:49.577292 [debug] [Thread-1 (]: SQL status: BEGIN in 0.070 seconds
[0m14:50:49.577868 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_slq"
[0m14:50:49.578328 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_slq"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_slq__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with base as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
),

sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        -- trajanje isporuke u danima
        extract(epoch from (delivered_at - shipment_date))/86400 as delivery_duration_days,
        -- kasnjenje
        case 
            when delivered_at > expected_delivery_date then true
            else false
        end as late_delivery
    from base
)

select * from sla;
  );
  
[0m14:50:49.579321 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 44: select * from sla;
                          ^

[0m14:50:49.579776 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: ROLLBACK
[0m14:50:49.580473 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_slq: Close
[0m14:50:49.589853 [debug] [Thread-1 (]: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:50:49.590531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF7C1450>]}
[0m14:50:49.591209 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_slq .............. [[31mERROR[0m in 0.12s]
[0m14:50:49.592214 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_slq
[0m14:50:49.592947 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_slq' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql.
[0m14:50:49.594028 [debug] [Thread-2 (]: SQL status: BEGIN in 0.084 seconds
[0m14:50:49.594400 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:50:49.594757 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(shipment_id) as total_shipments,
    sum(case when not late_delivery then 1 else 0 end) as on_time_deliveries,
    sum(case when late_delivery then 1 else 0 end) as late_deliveries,
    avg(delivery_duration_days) as avg_delivery_days
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id;
  );
  
[0m14:50:49.595638 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: group by courier_id;
                            ^

[0m14:50:49.596103 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:50:49.596825 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:50:49.604050 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:50:49.604775 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FEE1D550>]}
[0m14:50:49.605534 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.13s]
[0m14:50:49.606422 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:50:49.607087 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:50:49.651594 [debug] [Thread-4 (]: SQL status: BEGIN in 0.141 seconds
[0m14:50:49.652222 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:50:49.652735 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    shipment_date,
    courier_id,
    sum(price) as total_revenue,
    count(shipment_id) as total_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by shipment_date, courier_id;
  );
  
[0m14:50:49.653715 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 20: group by shipment_date, courier_id;
                                           ^

[0m14:50:49.654125 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: ROLLBACK
[0m14:50:49.654827 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:50:49.660816 [debug] [Thread-4 (]: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:50:49.661446 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF739FD0>]}
[0m14:50:49.662080 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.fct_shipments_revenue .......... [[31mERROR[0m in 0.19s]
[0m14:50:49.663024 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:50:49.663699 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_revenue' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql.
[0m14:50:49.719793 [debug] [Thread-3 (]: SQL status: BEGIN in 0.207 seconds
[0m14:50:49.720439 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.720843 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:50:49.726579 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.005 seconds
[0m14:50:49.730223 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.730760 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:50:49.731862 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:50:49.734610 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.735021 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:50:49.736361 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:50:49.738198 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:50:49.738589 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.738921 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:50:49.740436 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:50:49.742761 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:50:49.743493 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:50:49.743947 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:50:49.754777 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.010 seconds
[0m14:50:49.756474 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:50:49.757193 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '962452bc-04ab-4bcf-bc5d-d0f894629020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF795010>]}
[0m14:50:49.757820 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.29s]
[0m14:50:49.758651 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:50:49.760133 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:49.760567 [debug] [MainThread]: On master: BEGIN
[0m14:50:49.761006 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:50:49.878939 [debug] [MainThread]: SQL status: BEGIN in 0.118 seconds
[0m14:50:49.879473 [debug] [MainThread]: On master: COMMIT
[0m14:50:49.879814 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:49.880105 [debug] [MainThread]: On master: COMMIT
[0m14:50:49.880666 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:50:49.881074 [debug] [MainThread]: On master: Close
[0m14:50:49.881699 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:50:49.882002 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:50:49.882265 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:50:49.882635 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_slq' was properly closed.
[0m14:50:49.883083 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:50:49.883501 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:50:49.883917 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:50:49.884472 [info ] [MainThread]: 
[0m14:50:49.885095 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.12 seconds (1.12s).
[0m14:50:49.886754 [debug] [MainThread]: Command end result
[0m14:50:49.922196 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:50:49.927706 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:50:49.938316 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:50:49.939026 [info ] [MainThread]: 
[0m14:50:49.939674 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m14:50:49.940249 [info ] [MainThread]: 
[0m14:50:49.940855 [error] [MainThread]: [31mFailure in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)[0m
[0m14:50:49.941605 [error] [MainThread]:   Database Error in model fct_shipments_slq (models\marts\analytics\fct_shipments_slq.sql)
  syntax error at or near ";"
  LINE 44: select * from sla;
                            ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:50:49.942170 [info ] [MainThread]: 
[0m14:50:49.942804 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_slq.sql
[0m14:50:49.943320 [info ] [MainThread]: 
[0m14:50:49.944030 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:50:49.944849 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  syntax error at or near ";"
  LINE 19: group by courier_id;
                              ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:50:49.945700 [info ] [MainThread]: 
[0m14:50:49.946819 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:50:49.951290 [info ] [MainThread]: 
[0m14:50:49.952782 [error] [MainThread]: [31mFailure in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)[0m
[0m14:50:49.954363 [error] [MainThread]:   Database Error in model fct_shipments_revenue (models\marts\analytics\fct_shipments_revenue.sql)
  syntax error at or near ";"
  LINE 20: group by shipment_date, courier_id;
                                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:50:49.954994 [info ] [MainThread]: 
[0m14:50:49.955666 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_revenue.sql
[0m14:50:49.956302 [info ] [MainThread]: 
[0m14:50:49.956933 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=5
[0m14:50:49.957837 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:50:49.959735 [debug] [MainThread]: Command `dbt run` failed at 14:50:49.959538 after 3.45 seconds
[0m14:50:49.960277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF29C770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FC2CFA70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000133FF113F50>]}
[0m14:50:49.960776 [debug] [MainThread]: Flushing usage events
[0m14:50:50.999070 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:53:58.633388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AE9D0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AF47CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AFACBD90>]}


============================== 14:53:58.639130 | 4be5890d-a9dc-4f0a-b4cb-04a66524913e ==============================
[0m14:53:58.639130 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:53:58.640236 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:53:58.908345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AEE38770>]}
[0m14:53:58.986815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AF96EE00>]}
[0m14:53:58.988548 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:53:59.475376 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:53:59.681191 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 2 files changed.
[0m14:53:59.682203 [debug] [MainThread]: Partial parsing: added file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_sla.sql
[0m14:53:59.683564 [debug] [MainThread]: Partial parsing: deleted file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_slq.sql
[0m14:53:59.684742 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_revenue.sql
[0m14:53:59.685448 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:54:00.009852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B149DA50>]}
[0m14:54:00.121406 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:54:00.125351 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:54:00.230820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AF95FD40>]}
[0m14:54:00.231408 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m14:54:00.232306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B118ADD0>]}
[0m14:54:00.235519 [info ] [MainThread]: 
[0m14:54:00.236112 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:54:00.236732 [info ] [MainThread]: 
[0m14:54:00.237520 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:54:00.241728 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:54:00.399198 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:54:00.399665 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:54:00.400005 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:00.547146 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.147 seconds
[0m14:54:00.549442 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:54:00.552422 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:54:00.567412 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:54:00.568173 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:54:00.568811 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:00.643806 [debug] [ThreadPool]: SQL status: BEGIN in 0.075 seconds
[0m14:54:00.644307 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:54:00.644769 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:54:00.653560 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m14:54:00.655182 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:54:00.655730 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:54:00.663489 [debug] [MainThread]: Using postgres connection "master"
[0m14:54:00.663932 [debug] [MainThread]: On master: BEGIN
[0m14:54:00.664203 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:54:00.739707 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m14:54:00.740293 [debug] [MainThread]: Using postgres connection "master"
[0m14:54:00.740643 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:54:00.750311 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m14:54:00.752281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B1793EE0>]}
[0m14:54:00.752735 [debug] [MainThread]: On master: ROLLBACK
[0m14:54:00.753358 [debug] [MainThread]: Using postgres connection "master"
[0m14:54:00.753737 [debug] [MainThread]: On master: BEGIN
[0m14:54:00.754494 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:54:00.754873 [debug] [MainThread]: On master: COMMIT
[0m14:54:00.755275 [debug] [MainThread]: Using postgres connection "master"
[0m14:54:00.755729 [debug] [MainThread]: On master: COMMIT
[0m14:54:00.756280 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:54:00.756667 [debug] [MainThread]: On master: Close
[0m14:54:00.761386 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:54:00.762023 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:54:00.762979 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:54:00.763475 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:54:00.771470 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.774380 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:54:00.814546 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.816684 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.817103 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:54:00.817445 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:54:00.881620 [debug] [Thread-1 (]: SQL status: BEGIN in 0.064 seconds
[0m14:54:00.882120 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.882513 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:54:00.893862 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.011 seconds
[0m14:54:00.905083 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.905528 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:54:00.906465 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:54:00.908873 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.909231 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:54:00.910593 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:54:00.926503 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:54:00.927167 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.927619 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:54:00.929549 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m14:54:00.936124 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:54:00.940754 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:54:00.941135 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:54:00.945897 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m14:54:00.948415 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:54:00.950751 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B19B8950>]}
[0m14:54:00.951639 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.19s]
[0m14:54:00.952761 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:54:00.953651 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:54:00.954122 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:54:00.954543 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m14:54:00.954983 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:54:00.955519 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:54:00.956087 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:54:00.958068 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:54:00.956709 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m14:54:00.958795 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:54:00.959658 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:54:00.957280 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m14:54:00.960491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m14:54:00.960980 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:54:00.963950 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:54:00.965041 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m14:54:00.965774 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m14:54:00.969269 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:00.970071 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:54:00.972962 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m14:54:00.975225 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:00.976103 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:54:00.981950 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:54:00.983257 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:54:00.988106 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:00.988739 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:54:00.989384 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m14:54:00.993725 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:00.996789 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m14:54:00.997844 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:54:00.998521 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:00.999117 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:54:00.999668 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:54:01.000207 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:54:01.000670 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:54:01.002131 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m14:54:01.002934 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m14:54:01.003771 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:01.004287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:01.004935 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m14:54:01.005668 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:54:01.082426 [debug] [Thread-2 (]: SQL status: BEGIN in 0.082 seconds
[0m14:54:01.083156 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:54:01.083712 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    avg(delivered_at::date - shipment_date::date) as avg_delivery_days
from fct
group by courier_id
  );
  
[0m14:54:01.085765 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m14:54:01.086509 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:54:01.087490 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:54:01.100185 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:54:01.100783 [debug] [Thread-3 (]: SQL status: BEGIN in 0.100 seconds
[0m14:54:01.101364 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B1901F40>]}
[0m14:54:01.101986 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:01.103469 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:54:01.102959 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.14s]
[0m14:54:01.104528 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:54:01.105417 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:54:01.112873 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.009 seconds
[0m14:54:01.117973 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:01.118816 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:54:01.119452 [debug] [Thread-1 (]: SQL status: BEGIN in 0.115 seconds
[0m14:54:01.119874 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:54:01.120250 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m14:54:01.123320 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:01.123876 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        (delivered_at::date - expected_delivery_date::date) as delivery_delay_days,
        case
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery
    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m14:54:01.124461 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:54:01.125676 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "delivered_at" does not exist
LINE 28:         delivered_at,
                 ^

[0m14:54:01.126124 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:54:01.126490 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: ROLLBACK
[0m14:54:01.128003 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:54:01.128489 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:01.128966 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m14:54:01.129301 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:54:01.130996 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:54:01.134178 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:54:01.135114 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:54:01.135528 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:54:01.139828 [debug] [Thread-1 (]: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m14:54:01.140789 [debug] [Thread-4 (]: SQL status: BEGIN in 0.135 seconds
[0m14:54:01.141455 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B1A58550>]}
[0m14:54:01.141977 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:01.143153 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    courier_id,
    sum(price) as total_revenue
from fct
group by shipment_date, courier_id
  );
  
[0m14:54:01.142759 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_sla .............. [[31mERROR[0m in 0.18s]
[0m14:54:01.143949 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m14:54:01.144504 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_sla' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql.
[0m14:54:01.147134 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.011 seconds
[0m14:54:01.149201 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:54:01.150442 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B134A1D0>]}
[0m14:54:01.151593 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.19s]
[0m14:54:01.152784 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:54:01.159159 [debug] [Thread-4 (]: SQL status: SELECT 6 in 0.015 seconds
[0m14:54:01.163530 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:01.163979 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m14:54:01.167359 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m14:54:01.169001 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m14:54:01.169415 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:01.169849 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m14:54:01.171375 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m14:54:01.173618 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m14:54:01.174382 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m14:54:01.174783 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m14:54:01.175502 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:54:01.176773 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m14:54:01.177379 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4be5890d-a9dc-4f0a-b4cb-04a66524913e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B1A0C590>]}
[0m14:54:01.177974 [info ] [Thread-4 (]: 4 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.21s]
[0m14:54:01.178907 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m14:54:01.180574 [debug] [MainThread]: Using postgres connection "master"
[0m14:54:01.181112 [debug] [MainThread]: On master: BEGIN
[0m14:54:01.181466 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:54:01.262264 [debug] [MainThread]: SQL status: BEGIN in 0.081 seconds
[0m14:54:01.262725 [debug] [MainThread]: On master: COMMIT
[0m14:54:01.263039 [debug] [MainThread]: Using postgres connection "master"
[0m14:54:01.263319 [debug] [MainThread]: On master: COMMIT
[0m14:54:01.263807 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:54:01.264222 [debug] [MainThread]: On master: Close
[0m14:54:01.264818 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:54:01.265129 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:54:01.265475 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:54:01.265853 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m14:54:01.266232 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:54:01.266543 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:54:01.266801 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m14:54:01.267200 [info ] [MainThread]: 
[0m14:54:01.267768 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m14:54:01.269588 [debug] [MainThread]: Command end result
[0m14:54:01.302013 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:54:01.306231 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:54:01.313439 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:54:01.313894 [info ] [MainThread]: 
[0m14:54:01.314624 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m14:54:01.315397 [info ] [MainThread]: 
[0m14:54:01.316007 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:54:01.316769 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:54:01.317511 [info ] [MainThread]: 
[0m14:54:01.318240 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:54:01.318919 [info ] [MainThread]: 
[0m14:54:01.319524 [error] [MainThread]: [31mFailure in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)[0m
[0m14:54:01.320076 [error] [MainThread]:   Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m14:54:01.320769 [info ] [MainThread]: 
[0m14:54:01.321397 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m14:54:01.321914 [info ] [MainThread]: 
[0m14:54:01.322459 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=5
[0m14:54:01.323847 [debug] [MainThread]: Command `dbt run` failed at 14:54:01.323722 after 2.97 seconds
[0m14:54:01.324241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267AEC7BD70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B1A96510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267B13A4A70>]}
[0m14:54:01.324644 [debug] [MainThread]: Flushing usage events
[0m14:54:02.387225 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:25:27.833326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016781314980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016781DACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167823FBD90>]}


============================== 10:25:27.868507 | 1a1f3fe9-6a0e-4296-93bd-f40bf575030a ==============================
[0m10:25:27.868507 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:25:27.869886 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:25:28.253558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016781778770>]}
[0m10:25:28.371174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001678229EE00>]}
[0m10:25:28.385498 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:25:28.971060 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:25:29.266703 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:25:29.267220 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:25:29.325406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016783D05650>]}
[0m10:25:29.448551 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:25:29.453787 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:25:29.506765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001678228FD40>]}
[0m10:25:29.507715 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:25:29.508573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167838C7D90>]}
[0m10:25:29.511291 [info ] [MainThread]: 
[0m10:25:29.512002 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:25:29.512748 [info ] [MainThread]: 
[0m10:25:29.513498 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:25:29.518848 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:25:29.773921 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:25:29.774465 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:25:29.774872 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:25:30.257182 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.482 seconds
[0m10:25:30.258923 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:25:30.262987 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:25:30.272741 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:25:30.273248 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:25:30.273725 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:25:30.345160 [debug] [ThreadPool]: SQL status: BEGIN in 0.071 seconds
[0m10:25:30.346140 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:25:30.346683 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:25:30.392855 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.046 seconds
[0m10:25:30.395007 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:25:30.396597 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:25:30.407710 [debug] [MainThread]: Using postgres connection "master"
[0m10:25:30.408477 [debug] [MainThread]: On master: BEGIN
[0m10:25:30.408997 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:25:30.474792 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m10:25:30.475423 [debug] [MainThread]: Using postgres connection "master"
[0m10:25:30.475985 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:25:30.513710 [debug] [MainThread]: SQL status: SELECT 5 in 0.037 seconds
[0m10:25:30.515858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001678400CFC0>]}
[0m10:25:30.516760 [debug] [MainThread]: On master: ROLLBACK
[0m10:25:30.517797 [debug] [MainThread]: Using postgres connection "master"
[0m10:25:30.518429 [debug] [MainThread]: On master: BEGIN
[0m10:25:30.519408 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:25:30.520062 [debug] [MainThread]: On master: COMMIT
[0m10:25:30.520721 [debug] [MainThread]: Using postgres connection "master"
[0m10:25:30.521281 [debug] [MainThread]: On master: COMMIT
[0m10:25:30.522422 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m10:25:30.522937 [debug] [MainThread]: On master: Close
[0m10:25:30.530679 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:25:30.531416 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:25:30.532589 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:25:30.533387 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:25:30.548920 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.552773 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:25:30.620009 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.622951 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.623792 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:25:30.624518 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:25:30.730368 [debug] [Thread-1 (]: SQL status: BEGIN in 0.106 seconds
[0m10:25:30.730990 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.731508 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m10:25:30.819406 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.087 seconds
[0m10:25:30.834310 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.835153 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:25:30.837465 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:25:30.841310 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.841829 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:25:30.843481 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:25:30.874538 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:25:30.875178 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.875627 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:25:30.877515 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m10:25:30.886249 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:25:30.898392 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:25:30.899136 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:25:30.914711 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.015 seconds
[0m10:25:30.918711 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:25:30.922756 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016783DD71D0>]}
[0m10:25:30.924000 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.39s]
[0m10:25:30.925444 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:25:30.926589 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:25:30.927447 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:25:30.927989 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:25:30.928524 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:25:30.929198 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:25:30.930079 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:25:30.935234 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:25:30.931353 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:25:30.936246 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:25:30.933024 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:25:30.937126 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:25:30.937941 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:25:30.938556 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:25:30.939294 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:25:30.943245 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:30.944142 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:25:30.947439 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:30.948012 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:25:31.032160 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:25:31.036657 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:25:31.038411 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:25:31.042867 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.045507 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.046332 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:25:31.047111 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:25:31.061217 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:25:31.062153 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:25:31.068697 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:25:31.070538 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:25:31.075209 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:25:31.078836 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.082420 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:25:31.083339 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:25:31.084309 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.085131 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:25:31.085891 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:25:31.086829 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:25:31.087869 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:25:31.088623 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:25:31.089327 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:25:31.134741 [debug] [Thread-3 (]: SQL status: BEGIN in 0.088 seconds
[0m10:25:31.135507 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.136263 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m10:25:31.152304 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.015 seconds
[0m10:25:31.157954 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.158726 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m10:25:31.160149 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:25:31.164838 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.165608 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m10:25:31.167178 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:25:31.169838 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:25:31.170351 [debug] [Thread-1 (]: SQL status: BEGIN in 0.085 seconds
[0m10:25:31.170840 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.171345 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:25:31.171853 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:25:31.172408 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        (delivered_at::date - expected_delivery_date::date) as delivery_delay_days,
        case
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery
    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:25:31.174107 [debug] [Thread-4 (]: SQL status: BEGIN in 0.087 seconds
[0m10:25:31.174728 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m10:25:31.175288 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.179102 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m10:25:31.180080 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "delivered_at" does not exist
LINE 28:         delivered_at,
                 ^

[0m10:25:31.180680 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    courier_id,
    sum(price) as total_revenue
from fct
group by shipment_date, courier_id
  );
  
[0m10:25:31.181961 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:25:31.182499 [debug] [Thread-2 (]: SQL status: BEGIN in 0.093 seconds
[0m10:25:31.182964 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: ROLLBACK
[0m10:25:31.183633 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m10:25:31.184338 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:25:31.185346 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    avg(delivered_at::date - shipment_date::date) as avg_delivery_days
from fct
group by courier_id
  );
  
[0m10:25:31.186019 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:25:31.188326 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:25:31.189053 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:25:31.190106 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:25:31.296107 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.111 seconds
[0m10:25:31.299821 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:25:31.301602 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167840F8AA0>]}
[0m10:25:31.303297 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.37s]
[0m10:25:31.304748 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:25:31.310600 [debug] [Thread-4 (]: SQL status: SELECT 6 in 0.127 seconds
[0m10:25:31.315473 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.316074 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:25:31.317730 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:25:31.322951 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.323537 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:25:31.325925 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:25:31.327894 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:25:31.328401 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.328853 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:25:31.421810 [debug] [Thread-4 (]: SQL status: COMMIT in 0.092 seconds
[0m10:25:31.428190 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:25:31.429832 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:25:31.430676 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:25:31.447150 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:25:31.447896 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.016 seconds
[0m10:25:31.448798 [debug] [Thread-1 (]: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:25:31.449462 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167FFCB4730>]}
[0m10:25:31.451436 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:25:31.452005 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167841C69F0>]}
[0m10:25:31.454763 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a1f3fe9-6a0e-4296-93bd-f40bf575030a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167841FFF50>]}
[0m10:25:31.452870 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.51s]
[0m10:25:31.457012 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:25:31.453939 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_sla .............. [[31mERROR[0m in 0.51s]
[0m10:25:31.458276 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:25:31.459456 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:25:31.455875 [info ] [Thread-4 (]: 4 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.52s]
[0m10:25:31.461763 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_sla' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql.
[0m10:25:31.462639 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:25:31.465913 [debug] [MainThread]: Using postgres connection "master"
[0m10:25:31.466368 [debug] [MainThread]: On master: BEGIN
[0m10:25:31.466732 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:25:31.552445 [debug] [MainThread]: SQL status: BEGIN in 0.086 seconds
[0m10:25:31.553128 [debug] [MainThread]: On master: COMMIT
[0m10:25:31.553534 [debug] [MainThread]: Using postgres connection "master"
[0m10:25:31.554063 [debug] [MainThread]: On master: COMMIT
[0m10:25:31.554776 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:25:31.555185 [debug] [MainThread]: On master: Close
[0m10:25:31.556032 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:25:31.556561 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:25:31.557088 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:25:31.557578 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:25:31.558028 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:25:31.558473 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m10:25:31.558916 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:25:31.559583 [info ] [MainThread]: 
[0m10:25:31.560680 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 2.05 seconds (2.05s).
[0m10:25:31.563612 [debug] [MainThread]: Command end result
[0m10:25:31.612256 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:25:31.619061 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:25:31.629945 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:25:31.630741 [info ] [MainThread]: 
[0m10:25:31.631518 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m10:25:31.632640 [info ] [MainThread]: 
[0m10:25:31.633598 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:25:31.634549 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:25:31.635261 [info ] [MainThread]: 
[0m10:25:31.636088 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:25:31.636807 [info ] [MainThread]: 
[0m10:25:31.637858 [error] [MainThread]: [31mFailure in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)[0m
[0m10:25:31.638732 [error] [MainThread]:   Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:25:31.639561 [info ] [MainThread]: 
[0m10:25:31.640399 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:25:31.641058 [info ] [MainThread]: 
[0m10:25:31.641888 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=5
[0m10:25:31.643826 [debug] [MainThread]: Command `dbt run` failed at 10:25:31.643556 after 4.04 seconds
[0m10:25:31.644687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016781653E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016781D713D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167842CBDD0>]}
[0m10:25:31.645521 [debug] [MainThread]: Flushing usage events
[0m10:25:33.042436 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:31:55.120495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A04F8980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A0FACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A15E7D90>]}


============================== 10:31:55.126700 | 0eec2cae-5096-481d-8bbe-f1e2caf71925 ==============================
[0m10:31:55.126700 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:31:55.128156 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select marts.analytics', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:31:55.419053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A0958770>]}
[0m10:31:55.500774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A148EE00>]}
[0m10:31:55.502083 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:31:55.918667 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:31:56.115927 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:31:56.116878 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_revenue.sql
[0m10:31:56.517913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A2FA5B50>]}
[0m10:31:56.646578 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:31:56.650722 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:31:56.755144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A147FD40>]}
[0m10:31:56.756155 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:31:56.757255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A2FB6F90>]}
[0m10:31:56.761614 [info ] [MainThread]: 
[0m10:31:56.762527 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:31:56.764635 [info ] [MainThread]: 
[0m10:31:56.765761 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:31:56.772349 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:31:56.911883 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:31:56.912527 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:31:56.912904 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:31:57.050257 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.137 seconds
[0m10:31:57.052466 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:31:57.056224 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:31:57.064218 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:31:57.064762 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:31:57.065137 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:31:57.129824 [debug] [ThreadPool]: SQL status: BEGIN in 0.065 seconds
[0m10:31:57.130441 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:31:57.130872 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:31:57.139065 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.008 seconds
[0m10:31:57.140884 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:31:57.141980 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:31:57.151326 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:57.151821 [debug] [MainThread]: On master: BEGIN
[0m10:31:57.152169 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:31:57.214543 [debug] [MainThread]: SQL status: BEGIN in 0.062 seconds
[0m10:31:57.215276 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:57.216105 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:31:57.225976 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m10:31:57.228275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A32BB6C0>]}
[0m10:31:57.228845 [debug] [MainThread]: On master: ROLLBACK
[0m10:31:57.229608 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:57.230016 [debug] [MainThread]: On master: BEGIN
[0m10:31:57.231300 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:31:57.231946 [debug] [MainThread]: On master: COMMIT
[0m10:31:57.232323 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:57.232693 [debug] [MainThread]: On master: COMMIT
[0m10:31:57.233323 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:31:57.233758 [debug] [MainThread]: On master: Close
[0m10:31:57.239481 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:31:57.240072 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:31:57.240886 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:31:57.242446 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:31:57.243019 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:31:57.241604 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:31:57.252571 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.253677 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:31:57.254894 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:31:57.258925 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.260159 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:31:57.312250 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.313887 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:31:57.318131 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.319503 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.320192 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:31:57.320841 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:31:57.321683 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.322195 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:31:57.322687 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:31:57.387889 [debug] [Thread-1 (]: SQL status: BEGIN in 0.067 seconds
[0m10:31:57.388633 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.389196 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m10:31:57.395198 [debug] [Thread-2 (]: SQL status: BEGIN in 0.072 seconds
[0m10:31:57.395703 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.396196 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    s.shipment_id,
    ca.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    ca.delivered_at,
    s.price,

    case
        when ca.delivered_at is null then null
        when ca.delivered_at::date > s.expected_delivery_date then true
        else false
    end as late_delivery

from "delivery_analytics"."raw"."shipments" s
left join "delivery_analytics"."raw"."courier_assignments" ca
    on s.shipment_id = ca.shipment_id
  );
  
[0m10:31:57.404527 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.015 seconds
[0m10:31:57.417386 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.417928 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.021 seconds
[0m10:31:57.418410 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:31:57.421814 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.422444 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:31:57.423018 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:31:57.423552 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:31:57.426804 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.430366 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.430992 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:31:57.431706 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:31:57.433396 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:31:57.433930 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:31:57.454135 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:31:57.456213 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:31:57.456853 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.457447 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.458003 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:31:57.458603 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:31:57.460550 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m10:31:57.468208 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:31:57.468884 [debug] [Thread-2 (]: SQL status: COMMIT in 0.009 seconds
[0m10:31:57.477844 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:31:57.480837 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:31:57.481472 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:31:57.482528 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:31:57.483227 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:31:57.489151 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m10:31:57.492397 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:31:57.492935 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.009 seconds
[0m10:31:57.494701 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:31:57.497413 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A34FCA10>]}
[0m10:31:57.498045 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A33B8470>]}
[0m10:31:57.499130 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.25s]
[0m10:31:57.501539 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:31:57.500127 [info ] [Thread-2 (]: 2 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.24s]
[0m10:31:57.503038 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:31:57.503732 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:31:57.504315 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:31:57.505048 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:31:57.505813 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:31:57.508576 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:31:57.506547 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:31:57.509571 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:31:57.507437 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:31:57.510638 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:31:57.514967 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:31:57.515914 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:31:57.516665 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:31:57.517514 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:31:57.522845 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.526232 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:31:57.528038 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:31:57.532786 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:31:57.534118 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:31:57.534664 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:31:57.539080 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.544095 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:31:57.545575 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:31:57.546165 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:31:57.546905 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:31:57.548376 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:31:57.549301 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.550343 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:31:57.551154 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:31:57.551924 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:31:57.552486 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:31:57.664664 [debug] [Thread-4 (]: SQL status: BEGIN in 0.112 seconds
[0m10:31:57.665500 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.666235 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m10:31:57.682946 [debug] [Thread-4 (]: SQL status: SELECT 9 in 0.016 seconds
[0m10:31:57.688712 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.689454 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m10:31:57.690452 [debug] [Thread-3 (]: SQL status: BEGIN in 0.144 seconds
[0m10:31:57.691043 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:31:57.691616 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:31:57.696374 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.697064 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    avg(delivered_at::date - shipment_date::date) as avg_delivery_days
from fct
group by courier_id
  );
  
[0m10:31:57.697822 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m10:31:57.699158 [debug] [Thread-1 (]: SQL status: BEGIN in 0.147 seconds
[0m10:31:57.699822 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:31:57.700563 [debug] [Thread-3 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:31:57.701283 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m10:31:57.701997 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        (delivered_at::date - expected_delivery_date::date) as delivery_delay_days,
        case
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery
    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:31:57.702911 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:31:57.705390 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:31:57.706223 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.706866 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:31:57.707376 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:31:57.707940 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "delivered_at" does not exist
LINE 28:         delivered_at,
                 ^

[0m10:31:57.710230 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: ROLLBACK
[0m10:31:57.710859 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m10:31:57.720855 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m10:31:57.721711 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:31:57.722911 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:31:57.723944 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m10:31:57.734548 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.009 seconds
[0m10:31:57.736936 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:31:57.738030 [debug] [Thread-1 (]: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:31:57.738837 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A35A9090>]}
[0m10:31:57.742154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A34EBAD0>]}
[0m10:31:57.744344 [debug] [Thread-3 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:31:57.743350 [info ] [Thread-4 (]: 4 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.23s]
[0m10:31:57.746079 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eec2cae-5096-481d-8bbe-f1e2caf71925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A354D630>]}
[0m10:31:57.745454 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_sla .............. [[31mERROR[0m in 0.23s]
[0m10:31:57.747206 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:31:57.748852 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:31:57.748044 [error] [Thread-3 (]: 3 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.24s]
[0m10:31:57.750172 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_sla' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql.
[0m10:31:57.751058 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:31:57.753101 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:31:57.755643 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:57.756066 [debug] [MainThread]: On master: BEGIN
[0m10:31:57.756433 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:31:57.822586 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m10:31:57.823386 [debug] [MainThread]: On master: COMMIT
[0m10:31:57.823966 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:57.824359 [debug] [MainThread]: On master: COMMIT
[0m10:31:57.825030 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:31:57.825654 [debug] [MainThread]: On master: Close
[0m10:31:57.826384 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:31:57.826833 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:31:57.827225 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:31:57.827658 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:31:57.827988 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m10:31:57.828369 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:31:57.828684 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:31:57.829165 [info ] [MainThread]: 
[0m10:31:57.829982 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.06 seconds (1.06s).
[0m10:31:57.832052 [debug] [MainThread]: Command end result
[0m10:31:57.865411 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:31:57.869029 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:31:57.877949 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:31:57.878526 [info ] [MainThread]: 
[0m10:31:57.879380 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m10:31:57.880186 [info ] [MainThread]: 
[0m10:31:57.881011 [error] [MainThread]: [31mFailure in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)[0m
[0m10:31:57.881856 [error] [MainThread]:   Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:31:57.882585 [info ] [MainThread]: 
[0m10:31:57.883458 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:31:57.884197 [info ] [MainThread]: 
[0m10:31:57.885064 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:31:57.885946 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 20:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:31:57.886647 [info ] [MainThread]: 
[0m10:31:57.887370 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:31:57.888074 [info ] [MainThread]: 
[0m10:31:57.888835 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=5
[0m10:31:57.890265 [debug] [MainThread]: Command `dbt run` failed at 10:31:57.890104 after 3.07 seconds
[0m10:31:57.890794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A01915B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A304FB30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A14E2150>]}
[0m10:31:57.891263 [debug] [MainThread]: Flushing usage events
[0m10:31:59.090454 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:32:14.824642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF664980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B801FCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B8084BD90>]}


============================== 10:32:14.830602 | b288fe23-ddc9-466a-a6bd-8c69dd2604a1 ==============================
[0m10:32:14.830602 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:32:14.831806 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select fct_shipments', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:32:15.070641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFFAC8770>]}
[0m10:32:15.153488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B806EEE00>]}
[0m10:32:15.155044 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:32:15.562296 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:32:15.751470 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:32:15.752184 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:32:15.811006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B821F5650>]}
[0m10:32:15.915505 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:32:15.920476 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:32:15.953643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B806DFD40>]}
[0m10:32:15.954308 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:32:15.955046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B81DB7D90>]}
[0m10:32:15.957364 [info ] [MainThread]: 
[0m10:32:15.958087 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:32:15.958807 [info ] [MainThread]: 
[0m10:32:15.959773 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:32:15.961016 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:32:16.097535 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:32:16.098084 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:32:16.098460 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:32:16.227538 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.129 seconds
[0m10:32:16.229456 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:32:16.236697 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:32:16.243922 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:32:16.244492 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:32:16.244893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:32:16.338400 [debug] [ThreadPool]: SQL status: BEGIN in 0.093 seconds
[0m10:32:16.339171 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:32:16.339683 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:32:16.347367 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.007 seconds
[0m10:32:16.349628 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:32:16.350366 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:32:16.360488 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:16.361037 [debug] [MainThread]: On master: BEGIN
[0m10:32:16.361645 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:32:16.423652 [debug] [MainThread]: SQL status: BEGIN in 0.062 seconds
[0m10:32:16.424218 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:16.424733 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:32:16.435967 [debug] [MainThread]: SQL status: SELECT 5 in 0.011 seconds
[0m10:32:16.438077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B824FCFC0>]}
[0m10:32:16.438643 [debug] [MainThread]: On master: ROLLBACK
[0m10:32:16.439398 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:16.439802 [debug] [MainThread]: On master: BEGIN
[0m10:32:16.440780 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:32:16.441196 [debug] [MainThread]: On master: COMMIT
[0m10:32:16.441575 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:16.441969 [debug] [MainThread]: On master: COMMIT
[0m10:32:16.442599 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:32:16.443026 [debug] [MainThread]: On master: Close
[0m10:32:16.449450 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:32:16.450326 [info ] [Thread-1 (]: 1 of 1 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:32:16.451451 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:32:16.451945 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:32:16.462135 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.464580 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:32:16.516989 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.519340 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.519901 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:32:16.520403 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:32:16.588779 [debug] [Thread-1 (]: SQL status: BEGIN in 0.068 seconds
[0m10:32:16.589607 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.590306 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m10:32:16.600446 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.009 seconds
[0m10:32:16.613027 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.613586 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:32:16.614965 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:32:16.618703 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.619174 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:32:16.620622 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:32:16.639990 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:32:16.640500 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.640929 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:32:16.642667 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m10:32:16.650101 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:32:16.659665 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:32:16.660180 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:32:16.667642 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m10:32:16.671130 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:32:16.673621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b288fe23-ddc9-466a-a6bd-8c69dd2604a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B822C34D0>]}
[0m10:32:16.674448 [info ] [Thread-1 (]: 1 of 1 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.22s]
[0m10:32:16.675683 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:32:16.677813 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:16.678265 [debug] [MainThread]: On master: BEGIN
[0m10:32:16.678700 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:32:16.743132 [debug] [MainThread]: SQL status: BEGIN in 0.064 seconds
[0m10:32:16.743832 [debug] [MainThread]: On master: COMMIT
[0m10:32:16.744693 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:16.745181 [debug] [MainThread]: On master: COMMIT
[0m10:32:16.745874 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:32:16.746342 [debug] [MainThread]: On master: Close
[0m10:32:16.746985 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:32:16.747383 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:32:16.747703 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:32:16.748219 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m10:32:16.748709 [info ] [MainThread]: 
[0m10:32:16.749441 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m10:32:16.750966 [debug] [MainThread]: Command end result
[0m10:32:16.855988 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:32:16.860283 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:32:16.869321 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:32:16.869835 [info ] [MainThread]: 
[0m10:32:16.870697 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:32:16.871492 [info ] [MainThread]: 
[0m10:32:16.872183 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m10:32:16.873583 [debug] [MainThread]: Command `dbt run` succeeded at 10:32:16.873419 after 2.26 seconds
[0m10:32:16.874074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B8230E830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFD279270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B81DBF1B0>]}
[0m10:32:16.874552 [debug] [MainThread]: Flushing usage events
[0m10:32:17.928051 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:32:51.809153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C639A68980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63A4FCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63AB4BD90>]}


============================== 10:32:51.846471 | 16f997c0-627c-4ab6-8389-f9794b20aca5 ==============================
[0m10:32:51.846471 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:32:51.847859 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select courier_performance', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:32:52.098475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C639EC8770>]}
[0m10:32:52.180867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63A9EEE00>]}
[0m10:32:52.182340 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:32:52.607086 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:32:52.828893 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:32:52.829927 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m10:32:53.208646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63C4C5B50>]}
[0m10:32:53.328844 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:32:53.332670 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:32:53.441704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63A9DFD40>]}
[0m10:32:53.442431 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:32:53.443267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63C4D6F90>]}
[0m10:32:53.445805 [info ] [MainThread]: 
[0m10:32:53.446719 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:32:53.447510 [info ] [MainThread]: 
[0m10:32:53.448492 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:32:53.449915 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:32:53.578585 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:32:53.579125 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:32:53.579514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:32:53.722318 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.143 seconds
[0m10:32:53.724413 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:32:53.732132 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:32:53.742107 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:32:53.742781 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:32:53.743195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:32:53.842555 [debug] [ThreadPool]: SQL status: BEGIN in 0.099 seconds
[0m10:32:53.843222 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:32:53.843627 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:32:53.853148 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.009 seconds
[0m10:32:53.855498 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:32:53.856512 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:32:53.866290 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:53.866780 [debug] [MainThread]: On master: BEGIN
[0m10:32:53.867128 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:32:53.932114 [debug] [MainThread]: SQL status: BEGIN in 0.065 seconds
[0m10:32:53.932757 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:53.933337 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:32:53.945801 [debug] [MainThread]: SQL status: SELECT 5 in 0.012 seconds
[0m10:32:53.948210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63C7DBEE0>]}
[0m10:32:53.948789 [debug] [MainThread]: On master: ROLLBACK
[0m10:32:53.949549 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:53.949960 [debug] [MainThread]: On master: BEGIN
[0m10:32:53.950921 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:32:53.951329 [debug] [MainThread]: On master: COMMIT
[0m10:32:53.951695 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:53.952219 [debug] [MainThread]: On master: COMMIT
[0m10:32:53.953008 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:32:53.953440 [debug] [MainThread]: On master: Close
[0m10:32:53.959192 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:32:53.960026 [info ] [Thread-1 (]: 1 of 1 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:32:53.961395 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:32:53.962117 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:32:53.972328 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:32:53.974695 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:32:54.029649 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:32:54.031827 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:32:54.032889 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:32:54.033693 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:32:54.116906 [debug] [Thread-1 (]: SQL status: BEGIN in 0.083 seconds
[0m10:32:54.117677 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:32:54.118150 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:32:54.120677 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:32:54.121170 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:32:54.121977 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:32:54.131440 [debug] [Thread-1 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:32:54.134089 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16f997c0-627c-4ab6-8389-f9794b20aca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63CA10590>]}
[0m10:32:54.134947 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.17s]
[0m10:32:54.136262 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:32:54.137049 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:32:54.139814 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:54.140257 [debug] [MainThread]: On master: BEGIN
[0m10:32:54.140612 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:32:54.219889 [debug] [MainThread]: SQL status: BEGIN in 0.079 seconds
[0m10:32:54.220578 [debug] [MainThread]: On master: COMMIT
[0m10:32:54.220979 [debug] [MainThread]: Using postgres connection "master"
[0m10:32:54.221323 [debug] [MainThread]: On master: COMMIT
[0m10:32:54.221958 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:32:54.222471 [debug] [MainThread]: On master: Close
[0m10:32:54.223145 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:32:54.223733 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:32:54.224298 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:32:54.224769 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:32:54.225367 [info ] [MainThread]: 
[0m10:32:54.226229 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.78 seconds (0.78s).
[0m10:32:54.227638 [debug] [MainThread]: Command end result
[0m10:32:54.260066 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:32:54.263857 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:32:54.305153 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:32:54.305713 [info ] [MainThread]: 
[0m10:32:54.306507 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:32:54.307286 [info ] [MainThread]: 
[0m10:32:54.308192 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:32:54.309154 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:32:54.309840 [info ] [MainThread]: 
[0m10:32:54.310766 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:32:54.311416 [info ] [MainThread]: 
[0m10:32:54.312191 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m10:32:54.313707 [debug] [MainThread]: Command `dbt run` failed at 10:32:54.313547 after 2.71 seconds
[0m10:32:54.314209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C63C453330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C639E576B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C639E54AF0>]}
[0m10:32:54.314715 [debug] [MainThread]: Flushing usage events
[0m10:32:55.437627 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:32:59.130819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED71E98980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED7293CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED72F8BD90>]}


============================== 10:32:59.166925 | 1e4e1214-8dd3-493c-87ea-a10882b8ae6f ==============================
[0m10:32:59.166925 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:32:59.167815 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt run --select courier_performance', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:32:59.359403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED722F8770>]}
[0m10:32:59.441078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED72E2EE00>]}
[0m10:32:59.442546 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:32:59.808575 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:32:59.994082 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:32:59.994698 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:33:00.051720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED748D5650>]}
[0m10:33:00.146243 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:33:00.149502 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:33:00.175648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED72E1FD40>]}
[0m10:33:00.176288 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:33:00.176862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED740E7D90>]}
[0m10:33:00.178789 [info ] [MainThread]: 
[0m10:33:00.179342 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:33:00.179733 [info ] [MainThread]: 
[0m10:33:00.180330 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:33:00.181403 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:33:00.277147 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:33:00.277596 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:33:00.277910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:33:00.410578 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.133 seconds
[0m10:33:00.412019 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:33:00.419110 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:33:00.424895 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:33:00.425337 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:33:00.425765 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:33:00.485691 [debug] [ThreadPool]: SQL status: BEGIN in 0.060 seconds
[0m10:33:00.486204 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:33:00.486544 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:33:00.496234 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.009 seconds
[0m10:33:00.498046 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:33:00.498803 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:33:00.506919 [debug] [MainThread]: Using postgres connection "master"
[0m10:33:00.507365 [debug] [MainThread]: On master: BEGIN
[0m10:33:00.507682 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:33:00.568490 [debug] [MainThread]: SQL status: BEGIN in 0.061 seconds
[0m10:33:00.568995 [debug] [MainThread]: Using postgres connection "master"
[0m10:33:00.569405 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:33:00.580697 [debug] [MainThread]: SQL status: SELECT 5 in 0.011 seconds
[0m10:33:00.582825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED74BDCEF0>]}
[0m10:33:00.583562 [debug] [MainThread]: On master: ROLLBACK
[0m10:33:00.584222 [debug] [MainThread]: Using postgres connection "master"
[0m10:33:00.584570 [debug] [MainThread]: On master: BEGIN
[0m10:33:00.585423 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m10:33:00.585798 [debug] [MainThread]: On master: COMMIT
[0m10:33:00.586141 [debug] [MainThread]: Using postgres connection "master"
[0m10:33:00.586452 [debug] [MainThread]: On master: COMMIT
[0m10:33:00.586922 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:33:00.587310 [debug] [MainThread]: On master: Close
[0m10:33:00.592427 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:33:00.593087 [info ] [Thread-1 (]: 1 of 1 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:33:00.593857 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:33:00.594416 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:33:00.603107 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:33:00.604955 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:33:00.648639 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:33:00.650492 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:33:00.650983 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:33:00.651325 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:33:00.744627 [debug] [Thread-1 (]: SQL status: BEGIN in 0.093 seconds
[0m10:33:00.745111 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:33:00.745473 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:33:00.747458 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:33:00.747849 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:33:00.748939 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:33:00.759166 [debug] [Thread-1 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:33:00.762154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e4e1214-8dd3-493c-87ea-a10882b8ae6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED749A7C50>]}
[0m10:33:00.763251 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.17s]
[0m10:33:00.764896 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:33:00.765688 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:33:00.767815 [debug] [MainThread]: Using postgres connection "master"
[0m10:33:00.768212 [debug] [MainThread]: On master: BEGIN
[0m10:33:00.768500 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:33:00.956712 [debug] [MainThread]: SQL status: BEGIN in 0.188 seconds
[0m10:33:00.957338 [debug] [MainThread]: On master: COMMIT
[0m10:33:00.957646 [debug] [MainThread]: Using postgres connection "master"
[0m10:33:00.957914 [debug] [MainThread]: On master: COMMIT
[0m10:33:00.958455 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:33:00.958848 [debug] [MainThread]: On master: Close
[0m10:33:00.959377 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:33:00.959680 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:33:00.959925 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:33:00.960273 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:33:00.960591 [info ] [MainThread]: 
[0m10:33:00.961168 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.78 seconds (0.78s).
[0m10:33:00.962175 [debug] [MainThread]: Command end result
[0m10:33:01.055835 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:33:01.058718 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:33:01.066022 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:33:01.066405 [info ] [MainThread]: 
[0m10:33:01.066981 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:33:01.067562 [info ] [MainThread]: 
[0m10:33:01.068152 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:33:01.068778 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:33:01.069404 [info ] [MainThread]: 
[0m10:33:01.069991 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:33:01.070484 [info ] [MainThread]: 
[0m10:33:01.071029 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m10:33:01.072295 [debug] [MainThread]: Command `dbt run` failed at 10:33:01.072131 after 2.09 seconds
[0m10:33:01.072685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED749EB540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED7459B9D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED7459BE30>]}
[0m10:33:01.073067 [debug] [MainThread]: Flushing usage events
[0m10:33:02.042881 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:35:25.946632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BD8330980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BD8DDCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BD942BD90>]}


============================== 10:35:25.983827 | 5c117747-64d8-4c4e-baa4-f60d5a0c55fb ==============================
[0m10:35:25.983827 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:35:25.985302 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select courier_performance', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:35:26.256642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BD8798770>]}
[0m10:35:26.341322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BD92CEE00>]}
[0m10:35:26.342886 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:35:26.766202 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:35:26.970087 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:35:26.998712 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:35:27.062984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDADF5650>]}
[0m10:35:27.178356 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:35:27.184394 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:35:27.217169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BD92BFD40>]}
[0m10:35:27.218245 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:35:27.219328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDA9B7D90>]}
[0m10:35:27.222012 [info ] [MainThread]: 
[0m10:35:27.222826 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:35:27.223554 [info ] [MainThread]: 
[0m10:35:27.224590 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:35:27.225892 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:35:27.354068 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:35:27.354610 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:35:27.355019 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:35:27.485967 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.131 seconds
[0m10:35:27.487807 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:35:27.496306 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:35:27.503474 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:35:27.504083 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:35:27.504698 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:35:27.565724 [debug] [ThreadPool]: SQL status: BEGIN in 0.061 seconds
[0m10:35:27.566304 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:35:27.566715 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:35:27.574338 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.007 seconds
[0m10:35:27.576843 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:35:27.577545 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:35:27.586881 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:27.587352 [debug] [MainThread]: On master: BEGIN
[0m10:35:27.587762 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:35:27.649425 [debug] [MainThread]: SQL status: BEGIN in 0.062 seconds
[0m10:35:27.650039 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:27.650493 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:35:27.659838 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m10:35:27.661940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDB0FCEF0>]}
[0m10:35:27.662510 [debug] [MainThread]: On master: ROLLBACK
[0m10:35:27.663263 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:27.663850 [debug] [MainThread]: On master: BEGIN
[0m10:35:27.664946 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:35:27.665364 [debug] [MainThread]: On master: COMMIT
[0m10:35:27.665758 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:27.666126 [debug] [MainThread]: On master: COMMIT
[0m10:35:27.666764 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:35:27.667187 [debug] [MainThread]: On master: Close
[0m10:35:27.673855 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:35:27.674833 [info ] [Thread-1 (]: 1 of 1 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:35:27.676138 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:35:27.676798 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:35:27.685883 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:35:27.689229 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:35:27.744453 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:35:27.747681 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:35:27.748401 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:35:27.749088 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:35:27.816043 [debug] [Thread-1 (]: SQL status: BEGIN in 0.067 seconds
[0m10:35:27.816882 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:35:27.817635 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:35:27.819978 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:35:27.820605 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:35:27.821947 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:35:27.832033 [debug] [Thread-1 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:35:27.834485 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c117747-64d8-4c4e-baa4-f60d5a0c55fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDAEC7C50>]}
[0m10:35:27.835342 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.16s]
[0m10:35:27.836685 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:35:27.837636 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:35:27.840304 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:27.840731 [debug] [MainThread]: On master: BEGIN
[0m10:35:27.841094 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:35:27.902974 [debug] [MainThread]: SQL status: BEGIN in 0.062 seconds
[0m10:35:27.903614 [debug] [MainThread]: On master: COMMIT
[0m10:35:27.904098 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:27.904518 [debug] [MainThread]: On master: COMMIT
[0m10:35:27.905258 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:35:27.905861 [debug] [MainThread]: On master: Close
[0m10:35:27.906533 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:35:27.906934 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:35:27.907342 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:35:27.907681 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:35:27.908063 [info ] [MainThread]: 
[0m10:35:27.908756 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.68 seconds (0.68s).
[0m10:35:27.910083 [debug] [MainThread]: Command end result
[0m10:35:28.015920 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:35:28.019923 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:35:28.028929 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:35:28.029428 [info ] [MainThread]: 
[0m10:35:28.030159 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:35:28.030880 [info ] [MainThread]: 
[0m10:35:28.031692 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:35:28.032451 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:35:28.033200 [info ] [MainThread]: 
[0m10:35:28.034140 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:35:28.034886 [info ] [MainThread]: 
[0m10:35:28.035651 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m10:35:28.037532 [debug] [MainThread]: Command `dbt run` failed at 10:35:28.037279 after 2.37 seconds
[0m10:35:28.038304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDAF0B540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDAABB9D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028BDAABBE30>]}
[0m10:35:28.039055 [debug] [MainThread]: Flushing usage events
[0m10:35:29.157988 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:35:36.498888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272ED2E8980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EDD8CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EE3D7D90>]}


============================== 10:35:36.506356 | 1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9 ==============================
[0m10:35:36.506356 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:35:36.507539 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:35:36.747960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272ED748770>]}
[0m10:35:36.829807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EE27EE00>]}
[0m10:35:36.831358 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:35:37.243046 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:35:37.443132 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:35:37.443871 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:35:37.503585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EFD19650>]}
[0m10:35:37.628382 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:35:37.633895 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:35:37.676052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EE26FD40>]}
[0m10:35:37.677032 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:35:37.678566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EF537D90>]}
[0m10:35:37.682249 [info ] [MainThread]: 
[0m10:35:37.683030 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:35:37.683830 [info ] [MainThread]: 
[0m10:35:37.684878 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:35:37.691803 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:35:37.836053 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:35:37.836668 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:35:37.837218 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:35:37.959394 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.122 seconds
[0m10:35:37.961203 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:35:37.964390 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:35:37.971960 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:35:37.972463 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:35:37.972819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:35:38.034464 [debug] [ThreadPool]: SQL status: BEGIN in 0.061 seconds
[0m10:35:38.035115 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:35:38.035565 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:35:38.043782 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.008 seconds
[0m10:35:38.046459 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:35:38.047209 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:35:38.057344 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:38.057894 [debug] [MainThread]: On master: BEGIN
[0m10:35:38.058291 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:35:38.118634 [debug] [MainThread]: SQL status: BEGIN in 0.060 seconds
[0m10:35:38.119299 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:38.120203 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:35:38.129874 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m10:35:38.131579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272F0020FC0>]}
[0m10:35:38.132147 [debug] [MainThread]: On master: ROLLBACK
[0m10:35:38.132862 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:38.133271 [debug] [MainThread]: On master: BEGIN
[0m10:35:38.134299 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:35:38.134701 [debug] [MainThread]: On master: COMMIT
[0m10:35:38.135091 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:38.135485 [debug] [MainThread]: On master: COMMIT
[0m10:35:38.136145 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:35:38.136558 [debug] [MainThread]: On master: Close
[0m10:35:38.143375 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:35:38.144309 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:35:38.145029 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:35:38.146733 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:35:38.145676 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:35:38.147482 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:35:38.148303 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:35:38.158597 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.159491 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:35:38.163289 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.165998 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:35:38.166732 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:35:38.226690 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.233069 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.236776 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.237765 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.238466 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:35:38.239013 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:35:38.239680 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:35:38.240394 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:35:38.325576 [debug] [Thread-2 (]: SQL status: BEGIN in 0.085 seconds
[0m10:35:38.326173 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.326660 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    s.shipment_id,
    ca.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    ca.delivered_at,
    s.price,

    case
        when ca.delivered_at is null then null
        when ca.delivered_at::date > s.expected_delivery_date then true
        else false
    end as late_delivery

from "delivery_analytics"."raw"."shipments" s
left join "delivery_analytics"."raw"."courier_assignments" ca
    on s.shipment_id = ca.shipment_id
  );
  
[0m10:35:38.335935 [debug] [Thread-1 (]: SQL status: BEGIN in 0.096 seconds
[0m10:35:38.336451 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.336959 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m10:35:38.337578 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.010 seconds
[0m10:35:38.349121 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.349671 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.012 seconds
[0m10:35:38.350486 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:35:38.357568 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.358490 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:35:38.359211 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:35:38.359889 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:35:38.362909 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.366602 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.367193 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:35:38.367790 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:35:38.369531 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:35:38.370095 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:35:38.459264 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:35:38.461739 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:35:38.462625 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.463270 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.464007 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:35:38.464588 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:35:38.496729 [debug] [Thread-1 (]: SQL status: COMMIT in 0.031 seconds
[0m10:35:38.497819 [debug] [Thread-2 (]: SQL status: COMMIT in 0.032 seconds
[0m10:35:38.506612 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:35:38.510283 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:35:38.517019 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:35:38.518705 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:35:38.519580 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:35:38.520247 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:35:38.527876 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.007 seconds
[0m10:35:38.528402 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m10:35:38.532136 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:35:38.533956 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:35:38.537404 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EFDE7B90>]}
[0m10:35:38.537927 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EFE2B960>]}
[0m10:35:38.539029 [info ] [Thread-2 (]: 2 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.39s]
[0m10:35:38.540910 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:35:38.539993 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.39s]
[0m10:35:38.542036 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:35:38.543263 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:35:38.543893 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:35:38.544585 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:35:38.545353 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:35:38.548317 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:35:38.546176 [info ] [Thread-2 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:35:38.549116 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:35:38.549818 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments_revenue, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:35:38.547218 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:35:38.553502 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.554434 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:35:38.555468 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:35:38.558819 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:35:38.559539 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:35:38.563607 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:35:38.564820 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:35:38.569264 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.570892 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:35:38.571659 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:35:38.576720 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:35:38.581041 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:35:38.582234 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.582814 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:35:38.583575 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:35:38.585243 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:35:38.586073 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:35:38.587182 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:35:38.587888 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:35:38.588524 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:35:38.589378 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:35:38.667572 [debug] [Thread-4 (]: SQL status: BEGIN in 0.084 seconds
[0m10:35:38.668307 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.668967 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m10:35:38.673326 [debug] [Thread-3 (]: SQL status: BEGIN in 0.085 seconds
[0m10:35:38.673960 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:35:38.674444 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:35:38.674997 [debug] [Thread-2 (]: SQL status: BEGIN in 0.086 seconds
[0m10:35:38.675635 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:35:38.676108 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,
        (delivered_at::date - expected_delivery_date::date) as delivery_delay_days,
        case
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery
    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:35:38.677131 [debug] [Thread-3 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:35:38.677717 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "delivered_at" does not exist
LINE 28:         delivered_at,
                 ^

[0m10:35:38.678172 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:35:38.678742 [debug] [Thread-4 (]: SQL status: SELECT 9 in 0.009 seconds
[0m10:35:38.679318 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: ROLLBACK
[0m10:35:38.683446 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.684134 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:35:38.684908 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m10:35:38.685708 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:35:38.689196 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m10:35:38.693678 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.694480 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m10:35:38.696134 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:35:38.698359 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:35:38.699081 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.699674 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:35:38.701950 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m10:35:38.705814 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m10:35:38.707195 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:35:38.708361 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m10:35:38.714940 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.006 seconds
[0m10:35:38.720410 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:35:38.721668 [debug] [Thread-3 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:35:38.722770 [debug] [Thread-2 (]: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:35:38.723745 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EF9A5950>]}
[0m10:35:38.724412 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EFE57B60>]}
[0m10:35:38.725107 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e6bffc2-87d5-4ec7-b3f6-e6159607d7d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272F00B6DD0>]}
[0m10:35:38.726222 [info ] [Thread-4 (]: 4 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.18s]
[0m10:35:38.728860 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:35:38.727038 [error] [Thread-3 (]: 3 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.17s]
[0m10:35:38.728032 [error] [Thread-2 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_sla .............. [[31mERROR[0m in 0.18s]
[0m10:35:38.730189 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:35:38.731006 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:35:38.731928 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:35:38.733999 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_sla' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql.
[0m10:35:38.736314 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:38.736858 [debug] [MainThread]: On master: BEGIN
[0m10:35:38.737254 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:35:38.801149 [debug] [MainThread]: SQL status: BEGIN in 0.064 seconds
[0m10:35:38.801884 [debug] [MainThread]: On master: COMMIT
[0m10:35:38.802320 [debug] [MainThread]: Using postgres connection "master"
[0m10:35:38.802790 [debug] [MainThread]: On master: COMMIT
[0m10:35:38.803502 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:35:38.804030 [debug] [MainThread]: On master: Close
[0m10:35:38.804669 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:35:38.805096 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:35:38.805423 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:35:38.805885 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m10:35:38.806336 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:35:38.806757 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:35:38.807084 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:35:38.807585 [info ] [MainThread]: 
[0m10:35:38.808553 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.12 seconds (1.12s).
[0m10:35:38.810669 [debug] [MainThread]: Command end result
[0m10:35:38.840899 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:35:38.844925 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:35:38.854262 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:35:38.855045 [info ] [MainThread]: 
[0m10:35:38.855832 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m10:35:38.856687 [info ] [MainThread]: 
[0m10:35:38.857657 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:35:38.858457 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:35:38.859139 [info ] [MainThread]: 
[0m10:35:38.859973 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:35:38.860724 [info ] [MainThread]: 
[0m10:35:38.861612 [error] [MainThread]: [31mFailure in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)[0m
[0m10:35:38.862709 [error] [MainThread]:   Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:35:38.863602 [info ] [MainThread]: 
[0m10:35:38.864562 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:35:38.865337 [info ] [MainThread]: 
[0m10:35:38.866099 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=5
[0m10:35:38.868042 [debug] [MainThread]: Command `dbt run` failed at 10:35:38.867794 after 2.58 seconds
[0m10:35:38.868854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272ED6D7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EDDAC230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272EDDAC6B0>]}
[0m10:35:38.869685 [debug] [MainThread]: Flushing usage events
[0m10:35:40.045863 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:39:02.212800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F26D4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F317CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F37CBD90>]}


============================== 10:39:02.219130 | 9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6 ==============================
[0m10:39:02.219130 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:39:02.221139 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:39:02.485787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F2B38770>]}
[0m10:39:02.578377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F366EE00>]}
[0m10:39:02.580185 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:39:03.034467 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:39:03.258042 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:39:03.259372 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments_sla.sql
[0m10:39:03.645650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F50F1B50>]}
[0m10:39:03.771618 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:39:03.775966 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:39:03.884198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F365FD40>]}
[0m10:39:03.884942 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:39:03.885719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F5102F90>]}
[0m10:39:03.888308 [info ] [MainThread]: 
[0m10:39:03.889120 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:39:03.889915 [info ] [MainThread]: 
[0m10:39:03.890966 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:39:03.897318 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:39:04.034817 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:39:04.035374 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:39:04.035754 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:39:04.170280 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.134 seconds
[0m10:39:04.172031 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:39:04.175153 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:39:04.184809 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:39:04.185342 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:39:04.185707 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:39:04.259736 [debug] [ThreadPool]: SQL status: BEGIN in 0.074 seconds
[0m10:39:04.260754 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:39:04.261506 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:39:04.269315 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.007 seconds
[0m10:39:04.271557 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:39:04.272237 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:39:04.283597 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.284334 [debug] [MainThread]: On master: BEGIN
[0m10:39:04.284959 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:39:04.349307 [debug] [MainThread]: SQL status: BEGIN in 0.064 seconds
[0m10:39:04.349945 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.350418 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:39:04.360053 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m10:39:04.363177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F540FEE0>]}
[0m10:39:04.363794 [debug] [MainThread]: On master: ROLLBACK
[0m10:39:04.364605 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.365089 [debug] [MainThread]: On master: BEGIN
[0m10:39:04.366060 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:39:04.366472 [debug] [MainThread]: On master: COMMIT
[0m10:39:04.366878 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.367242 [debug] [MainThread]: On master: COMMIT
[0m10:39:04.367860 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:39:04.368278 [debug] [MainThread]: On master: Close
[0m10:39:04.374333 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:39:04.375110 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:39:04.375828 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:39:04.378007 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:39:04.376682 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:39:04.378806 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:39:04.379509 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:39:04.390183 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.390958 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:39:04.395828 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.398688 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:39:04.399380 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:39:04.478987 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.484411 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.487107 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.487880 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.488484 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:39:04.489061 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:39:04.489625 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:39:04.490174 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:39:04.564841 [debug] [Thread-1 (]: SQL status: BEGIN in 0.075 seconds
[0m10:39:04.565537 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.566039 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m10:39:04.583233 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.017 seconds
[0m10:39:04.595947 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.596537 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:39:04.597795 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:39:04.601252 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.601765 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:39:04.603270 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:39:04.619021 [debug] [Thread-2 (]: SQL status: BEGIN in 0.129 seconds
[0m10:39:04.625451 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:39:04.626086 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.626968 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.627744 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    s.shipment_id,
    ca.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    ca.delivered_at,
    s.price,

    case
        when ca.delivered_at is null then null
        when ca.delivered_at::date > s.expected_delivery_date then true
        else false
    end as late_delivery

from "delivery_analytics"."raw"."shipments" s
left join "delivery_analytics"."raw"."courier_assignments" ca
    on s.shipment_id = ca.shipment_id
  );
  
[0m10:39:04.628417 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:39:04.630549 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m10:39:04.638628 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:39:04.639226 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.010 seconds
[0m10:39:04.646269 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:39:04.650036 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.650828 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:39:04.651519 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:39:04.652942 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:39:04.655984 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.656477 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:39:04.657355 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m10:39:04.658027 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:39:04.661823 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:39:04.663788 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:39:04.664537 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.667538 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:39:04.668693 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F567C290>]}
[0m10:39:04.670171 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m10:39:04.669619 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.29s]
[0m10:39:04.673359 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:39:04.674486 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:39:04.675536 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:39:04.676745 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:39:04.677706 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:39:04.678305 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:39:04.678872 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:39:04.679551 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:39:04.681988 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:39:04.680336 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:39:04.682747 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:39:04.683410 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.006 seconds
[0m10:39:04.684401 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:39:04.681213 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:39:04.687955 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.690070 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:39:04.690705 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:39:04.691818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:39:04.697859 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:39:04.698816 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F5578D60>]}
[0m10:39:04.699361 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:39:04.701525 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:39:04.700869 [info ] [Thread-2 (]: 2 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.32s]
[0m10:39:04.706195 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:39:04.712389 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.713458 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:39:04.714812 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:39:04.719523 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:39:04.720991 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.721639 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:39:04.722382 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:39:04.726634 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:39:04.727631 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:39:04.728517 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:39:04.729609 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:39:04.730158 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:39:04.731316 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:39:04.731866 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:39:04.732365 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:39:04.807866 [debug] [Thread-4 (]: SQL status: BEGIN in 0.080 seconds
[0m10:39:04.808585 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.809074 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m10:39:04.817163 [debug] [Thread-3 (]: SQL status: BEGIN in 0.087 seconds
[0m10:39:04.817824 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:39:04.818379 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:39:04.819268 [debug] [Thread-1 (]: SQL status: BEGIN in 0.087 seconds
[0m10:39:04.819760 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:39:04.820326 [debug] [Thread-4 (]: SQL status: SELECT 9 in 0.011 seconds
[0m10:39:04.820914 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,

        case
            when delivered_at is null then null
            else (delivered_at::date - expected_delivery_date::date)
        end as delivery_delay_days,

        case
            when delivered_at is null then null
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery

    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:39:04.821582 [debug] [Thread-3 (]: Postgres adapter: Postgres error: column "late_delivery" does not exist
LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                           ^

[0m10:39:04.825695 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.826519 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m10:39:04.827273 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m10:39:04.828155 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "delivered_at" does not exist
LINE 28:         delivered_at,
                 ^

[0m10:39:04.828865 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:39:04.829391 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: ROLLBACK
[0m10:39:04.829936 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:39:04.835105 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.835862 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:39:04.836499 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m10:39:04.838640 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:39:04.840842 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:39:04.841542 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.842050 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:39:04.844346 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m10:39:04.851896 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m10:39:04.853048 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:39:04.853876 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m10:39:04.861457 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.007 seconds
[0m10:39:04.862743 [debug] [Thread-3 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:39:04.864705 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:39:04.865744 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F571DDB0>]}
[0m10:39:04.869704 [debug] [Thread-1 (]: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:39:04.871329 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F554ACD0>]}
[0m10:39:04.872024 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e1ce1b1-be32-4a7b-9bfb-3eeeb863a1f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F554ABD0>]}
[0m10:39:04.870643 [error] [Thread-3 (]: 3 of 5 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.18s]
[0m10:39:04.873268 [info ] [Thread-4 (]: 4 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.19s]
[0m10:39:04.875138 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:39:04.876145 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:39:04.874100 [error] [Thread-1 (]: 5 of 5 ERROR creating sql table model analytics.fct_shipments_sla .............. [[31mERROR[0m in 0.18s]
[0m10:39:04.877268 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m10:39:04.878322 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:39:04.880087 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.fct_shipments_sla' to be skipped because of status 'error'.  Reason: Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql.
[0m10:39:04.882367 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.882890 [debug] [MainThread]: On master: BEGIN
[0m10:39:04.883290 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:39:04.949417 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m10:39:04.950096 [debug] [MainThread]: On master: COMMIT
[0m10:39:04.950706 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.951282 [debug] [MainThread]: On master: COMMIT
[0m10:39:04.951974 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:39:04.952658 [debug] [MainThread]: On master: Close
[0m10:39:04.953510 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:39:04.953897 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:39:04.954262 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:39:04.954743 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:39:04.955247 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m10:39:04.955600 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:39:04.956009 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:39:04.956546 [info ] [MainThread]: 
[0m10:39:04.957356 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.07 seconds (1.07s).
[0m10:39:04.959504 [debug] [MainThread]: Command end result
[0m10:39:04.992443 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:39:04.997346 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:39:05.006441 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:39:05.007036 [info ] [MainThread]: 
[0m10:39:05.007875 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m10:39:05.008676 [info ] [MainThread]: 
[0m10:39:05.009436 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m10:39:05.010450 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  column "late_delivery" does not exist
  LINE 15:     sum(case when late_delivery = false then 1 else 0 end) a...
                             ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:39:05.011371 [info ] [MainThread]: 
[0m10:39:05.012268 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m10:39:05.013013 [info ] [MainThread]: 
[0m10:39:05.013859 [error] [MainThread]: [31mFailure in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)[0m
[0m10:39:05.014764 [error] [MainThread]:   Database Error in model fct_shipments_sla (models\marts\analytics\fct_shipments_sla.sql)
  column "delivered_at" does not exist
  LINE 28:         delivered_at,
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:39:05.015472 [info ] [MainThread]: 
[0m10:39:05.016216 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\fct_shipments_sla.sql
[0m10:39:05.016914 [info ] [MainThread]: 
[0m10:39:05.017746 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=5
[0m10:39:05.019328 [debug] [MainThread]: Command `dbt run` failed at 10:39:05.019159 after 3.05 seconds
[0m10:39:05.019846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F4DA3E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F319EF30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5F3668FB0>]}
[0m10:39:05.020366 [debug] [MainThread]: Flushing usage events
[0m10:39:06.246014 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:40:35.069636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D93A74980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D9451CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D94B6BD90>]}


============================== 10:40:35.106561 | 062476c9-f9ca-4b07-9bee-b5a759248d53 ==============================
[0m10:40:35.106561 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:40:35.108311 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:40:35.373325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D93ED8770>]}
[0m10:40:35.463937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D94A0EE00>]}
[0m10:40:35.466075 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:40:35.927100 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:40:36.160284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:40:36.161937 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments.sql
[0m10:40:36.724976 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m10:40:36.726529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D964B5C50>]}
[0m10:40:36.939504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D94BC3020>]}
[0m10:40:37.099652 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:40:37.103651 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:40:37.135617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D961C4830>]}
[0m10:40:37.136383 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:40:37.137177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D9659FEE0>]}
[0m10:40:37.140689 [info ] [MainThread]: 
[0m10:40:37.141431 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:40:37.142185 [info ] [MainThread]: 
[0m10:40:37.143298 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:40:37.149929 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:40:37.284518 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:40:37.285109 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:40:37.285784 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:37.393631 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.108 seconds
[0m10:40:37.395332 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:40:37.399029 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:40:37.408295 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:40:37.408889 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:40:37.409848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:37.478426 [debug] [ThreadPool]: SQL status: BEGIN in 0.069 seconds
[0m10:40:37.478993 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:40:37.479420 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:40:37.488167 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.008 seconds
[0m10:40:37.490144 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:40:37.490890 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:40:37.500529 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:37.501055 [debug] [MainThread]: On master: BEGIN
[0m10:40:37.501425 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:40:37.567192 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m10:40:37.567750 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:37.568203 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:40:37.578932 [debug] [MainThread]: SQL status: SELECT 5 in 0.010 seconds
[0m10:40:37.582370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96A1C110>]}
[0m10:40:37.583027 [debug] [MainThread]: On master: ROLLBACK
[0m10:40:37.583826 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:37.584241 [debug] [MainThread]: On master: BEGIN
[0m10:40:37.585175 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:40:37.585581 [debug] [MainThread]: On master: COMMIT
[0m10:40:37.585954 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:37.586333 [debug] [MainThread]: On master: COMMIT
[0m10:40:37.586942 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:40:37.587368 [debug] [MainThread]: On master: Close
[0m10:40:37.593202 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:40:37.593837 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:37.594585 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:40:37.596611 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:40:37.595434 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:40:37.597547 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:40:37.598327 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:40:37.608025 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.608692 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:37.613173 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.615638 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:37.616202 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:40:37.670886 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.675300 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.678021 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.678585 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.679250 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:40:37.679816 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:40:37.680723 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:40:37.681658 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:40:37.758525 [debug] [Thread-2 (]: SQL status: BEGIN in 0.077 seconds
[0m10:40:37.759142 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.759708 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    s.shipment_id,
    ca.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    ca.delivered_at,
    s.price,

    case
        when ca.delivered_at is null then null
        when ca.delivered_at::date > s.expected_delivery_date then true
        else false
    end as late_delivery

from "delivery_analytics"."raw"."shipments" s
left join "delivery_analytics"."raw"."courier_assignments" ca
    on s.shipment_id = ca.shipment_id
  );
  
[0m10:40:37.760581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.080 seconds
[0m10:40:37.761048 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.761525 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."raw"."shipments"
),

assignments as (
    select
        shipment_id,
        courier_id,
        delivered_at
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    s.shipment_id,
    a.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    a.delivered_at,
    s.price,

    case
        when a.delivered_at is null then null
        when a.delivered_at::date > s.expected_delivery_date::date then true
        else false
    end as late_delivery

from shipments s
left join assignments a
    on s.shipment_id = a.shipment_id
  );
  
[0m10:40:37.773682 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.013 seconds
[0m10:40:37.774377 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.012 seconds
[0m10:40:37.789281 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.798362 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.799155 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:40:37.799800 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:40:37.801332 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:37.801885 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:37.805231 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.809026 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.809659 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:40:37.810402 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:40:37.812024 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:37.812528 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:37.834135 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:40:37.836524 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:40:37.837231 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.837902 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.838525 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:40:37.839121 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:40:37.841503 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m10:40:37.842100 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m10:40:37.851238 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:40:37.854584 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:40:37.861634 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:37.862788 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:37.863538 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:40:37.864264 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:40:37.871113 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m10:40:37.871700 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.007 seconds
[0m10:40:37.874906 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:40:37.876669 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:40:37.880212 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D969ED390>]}
[0m10:40:37.880979 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D93E54C30>]}
[0m10:40:37.882051 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 6[0m in 0.28s]
[0m10:40:37.884073 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:40:37.882967 [info ] [Thread-2 (]: 2 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.28s]
[0m10:40:37.885345 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:37.885894 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:37.886424 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:37.887017 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:40:37.887923 [info ] [Thread-1 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:40:37.890141 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:40:37.888609 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:40:37.890880 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:37.891758 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:40:37.889507 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:40:37.895916 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:37.896591 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:37.897575 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:40:37.901299 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:37.901934 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:40:37.905878 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:40:37.907272 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:37.911296 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:37.912561 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:40:37.913297 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:37.918936 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:40:37.923502 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:37.924889 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:37.925469 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:40:37.926085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:40:37.927511 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:37.928125 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:37.928637 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:40:37.929228 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:40:37.929765 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:40:37.930595 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:40:38.003197 [debug] [Thread-1 (]: SQL status: BEGIN in 0.077 seconds
[0m10:40:38.003937 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:38.004468 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,

        case
            when delivered_at is null then null
            else (delivered_at::date - expected_delivery_date::date)
        end as delivery_delay_days,

        case
            when delivered_at is null then null
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery

    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:40:38.014095 [debug] [Thread-3 (]: SQL status: BEGIN in 0.084 seconds
[0m10:40:38.014854 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:38.015444 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.010 seconds
[0m10:40:38.016017 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:40:38.020166 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:38.021037 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
alter table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp" rename to "fct_shipments_sla"
[0m10:40:38.021946 [debug] [Thread-4 (]: SQL status: BEGIN in 0.091 seconds
[0m10:40:38.022475 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:38.022960 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:38.023561 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m10:40:38.025386 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: COMMIT
[0m10:40:38.026279 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:38.026861 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: COMMIT
[0m10:40:38.027503 [debug] [Thread-4 (]: Postgres adapter: Postgres error: column "status" does not exist
LINE 19:     status,
             ^

[0m10:40:38.028158 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: ROLLBACK
[0m10:40:38.029081 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:40:38.029634 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m10:40:38.030266 [debug] [Thread-3 (]: SQL status: SELECT 3 in 0.009 seconds
[0m10:40:38.033158 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_sla__dbt_backup"
[0m10:40:38.038712 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:38.039906 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:38.040591 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
alter table "delivery_analytics"."analytics"."courier_performance__dbt_tmp" rename to "courier_performance"
[0m10:40:38.041510 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_sla__dbt_backup" cascade
[0m10:40:38.043510 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m10:40:38.045410 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:40:38.045962 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.004 seconds
[0m10:40:38.048169 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: COMMIT
[0m10:40:38.048944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96952350>]}
[0m10:40:38.049515 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:38.051223 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: COMMIT
[0m10:40:38.050676 [info ] [Thread-1 (]: 5 of 5 OK created sql table model analytics.fct_shipments_sla .................. [[32mSELECT 6[0m in 0.16s]
[0m10:40:38.052664 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:38.053503 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m10:40:38.056326 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."courier_performance__dbt_backup"
[0m10:40:38.057272 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:38.057758 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
drop table if exists "delivery_analytics"."analytics"."courier_performance__dbt_backup" cascade
[0m10:40:38.058776 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m10:40:38.061043 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:40:38.062135 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96B2B3F0>]}
[0m10:40:38.063148 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.courier_performance ................ [[32mSELECT 3[0m in 0.16s]
[0m10:40:38.064760 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:40:38.070183 [debug] [Thread-4 (]: Database Error in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)
  column "status" does not exist
  LINE 19:     status,
               ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql
[0m10:40:38.070909 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '062476c9-f9ca-4b07-9bee-b5a759248d53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96BAF230>]}
[0m10:40:38.071886 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.daily_shipments_status ......... [[31mERROR[0m in 0.18s]
[0m10:40:38.073202 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:38.073983 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.daily_shipments_status' to be skipped because of status 'error'.  Reason: Database Error in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)
  column "status" does not exist
  LINE 19:     status,
               ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql.
[0m10:40:38.077306 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:38.077741 [debug] [MainThread]: On master: BEGIN
[0m10:40:38.078155 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:40:38.143092 [debug] [MainThread]: SQL status: BEGIN in 0.065 seconds
[0m10:40:38.143748 [debug] [MainThread]: On master: COMMIT
[0m10:40:38.144273 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:38.144640 [debug] [MainThread]: On master: COMMIT
[0m10:40:38.145331 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:40:38.146088 [debug] [MainThread]: On master: Close
[0m10:40:38.147009 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:40:38.147413 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:40:38.147771 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:40:38.148256 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:40:38.148759 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m10:40:38.149265 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:40:38.149775 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:40:38.150261 [info ] [MainThread]: 
[0m10:40:38.151018 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.01 seconds (1.01s).
[0m10:40:38.153221 [debug] [MainThread]: Command end result
[0m10:40:38.182607 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:40:38.186618 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:40:38.196739 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:40:38.197533 [info ] [MainThread]: 
[0m10:40:38.198593 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:40:38.199550 [info ] [MainThread]: 
[0m10:40:38.200388 [error] [MainThread]: [31mFailure in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)[0m
[0m10:40:38.201251 [error] [MainThread]:   Database Error in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)
  column "status" does not exist
  LINE 19:     status,
               ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql
[0m10:40:38.201975 [info ] [MainThread]: 
[0m10:40:38.202834 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql
[0m10:40:38.203624 [info ] [MainThread]: 
[0m10:40:38.204440 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m10:40:38.205439 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m10:40:38.206955 [debug] [MainThread]: Command `dbt run` failed at 10:40:38.206800 after 3.35 seconds
[0m10:40:38.207567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D944EBB30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96C23B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96C23D70>]}
[0m10:40:38.208035 [debug] [MainThread]: Flushing usage events
[0m10:40:39.464066 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:40:55.391292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A7018980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A7ACCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A8107D90>]}


============================== 10:40:55.402620 | e831bf36-10d1-4665-8a18-6c43c1abeed8 ==============================
[0m10:40:55.402620 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:40:55.404859 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:40:55.772313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A7478770>]}
[0m10:40:55.906222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A7FAEE00>]}
[0m10:40:55.908898 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:40:56.556993 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:40:56.848224 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:40:56.848914 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:40:56.948467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A9A4D650>]}
[0m10:40:57.122799 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:40:57.128050 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:40:57.174856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A7F9FD40>]}
[0m10:40:57.175753 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:40:57.176807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A82975B0>]}
[0m10:40:57.180287 [info ] [MainThread]: 
[0m10:40:57.181070 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:40:57.182029 [info ] [MainThread]: 
[0m10:40:57.183518 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:40:57.192877 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:40:57.373536 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:40:57.374254 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:40:57.374820 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:57.548136 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.173 seconds
[0m10:40:57.550853 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:40:57.555396 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:40:57.566465 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:40:57.567564 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:40:57.568481 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:57.665051 [debug] [ThreadPool]: SQL status: BEGIN in 0.096 seconds
[0m10:40:57.665834 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:40:57.666647 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:40:57.682749 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.015 seconds
[0m10:40:57.686794 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:40:57.688274 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:40:57.701071 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:57.701951 [debug] [MainThread]: On master: BEGIN
[0m10:40:57.702505 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:40:57.835658 [debug] [MainThread]: SQL status: BEGIN in 0.133 seconds
[0m10:40:57.836456 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:57.837195 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:40:57.850913 [debug] [MainThread]: SQL status: SELECT 5 in 0.013 seconds
[0m10:40:57.853907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A9D30EF0>]}
[0m10:40:57.854701 [debug] [MainThread]: On master: ROLLBACK
[0m10:40:57.855800 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:57.856436 [debug] [MainThread]: On master: BEGIN
[0m10:40:57.857773 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:40:57.858395 [debug] [MainThread]: On master: COMMIT
[0m10:40:57.858932 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:57.859419 [debug] [MainThread]: On master: COMMIT
[0m10:40:57.860230 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:40:57.860818 [debug] [MainThread]: On master: Close
[0m10:40:57.869679 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:57.870723 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:40:57.871868 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:40:57.874233 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:40:57.872913 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:40:57.875224 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:57.876274 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:40:57.890644 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:57.891669 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:40:57.897833 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:57.899858 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:57.967602 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:40:57.992846 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:57.992199 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:57.996761 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:57.997561 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:57.998363 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:40:57.999316 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:40:58.000460 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:40:58.001444 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:40:58.112241 [debug] [Thread-1 (]: SQL status: BEGIN in 0.111 seconds
[0m10:40:58.113029 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:58.113723 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."raw"."shipments"
),

assignments as (
    select
        shipment_id,
        courier_id,
        delivered_at
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    s.shipment_id,
    a.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    a.delivered_at,
    s.price,

    case
        when a.delivered_at is null then null
        when a.delivered_at::date > s.expected_delivery_date::date then true
        else false
    end as late_delivery

from shipments s
left join assignments a
    on s.shipment_id = a.shipment_id
  );
  
[0m10:40:58.121128 [debug] [Thread-2 (]: SQL status: BEGIN in 0.121 seconds
[0m10:40:58.121927 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:58.122660 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    s.shipment_id,
    ca.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    ca.delivered_at,
    s.price,

    case
        when ca.delivered_at is null then null
        when ca.delivered_at::date > s.expected_delivery_date then true
        else false
    end as late_delivery

from "delivery_analytics"."raw"."shipments" s
left join "delivery_analytics"."raw"."courier_assignments" ca
    on s.shipment_id = ca.shipment_id
  );
  
[0m10:40:58.130875 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.016 seconds
[0m10:40:58.147970 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:58.148914 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.025 seconds
[0m10:40:58.150473 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:40:58.160239 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:58.161264 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:40:58.162223 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:58.163048 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:58.168254 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:58.172889 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:58.173762 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:40:58.174788 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:40:58.177680 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:40:58.178465 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:40:58.297297 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:40:58.301159 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:40:58.302223 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:58.303120 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:58.303968 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:40:58.304721 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:40:58.307329 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m10:40:58.318328 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:40:58.319148 [debug] [Thread-2 (]: SQL status: COMMIT in 0.014 seconds
[0m10:40:58.328174 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:40:58.333088 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:40:58.334151 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:40:58.335560 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:40:58.336513 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:40:58.345543 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.008 seconds
[0m10:40:58.346373 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.010 seconds
[0m10:40:58.351264 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:40:58.353996 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:40:58.358439 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A9AF3A10>]}
[0m10:40:58.359142 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A9B3F330>]}
[0m10:40:58.360699 [info ] [Thread-2 (]: 2 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.48s]
[0m10:40:58.363502 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:40:58.362141 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 6[0m in 0.48s]
[0m10:40:58.365375 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:40:58.367588 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:58.368790 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:58.370045 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:40:58.371105 [info ] [Thread-2 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:40:58.372114 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:40:58.374660 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments_revenue, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:40:58.376141 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:40:58.373454 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:40:58.377341 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:58.378175 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:58.379248 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:40:58.385328 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.389929 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:58.390857 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:40:58.396541 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.398490 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:58.399533 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:58.408322 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.414377 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:58.416593 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:40:58.423717 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.425761 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:58.426627 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:40:58.427480 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.428338 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:40:58.429381 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:40:58.430745 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:40:58.431636 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.432887 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:40:58.433927 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:40:58.535340 [debug] [Thread-4 (]: SQL status: BEGIN in 0.107 seconds
[0m10:40:58.536178 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:40:58.536840 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m10:40:58.538996 [debug] [Thread-4 (]: Postgres adapter: Postgres error: column "status" does not exist
LINE 19:     status,
             ^

[0m10:40:58.539750 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: ROLLBACK
[0m10:40:58.541085 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:40:58.546874 [debug] [Thread-2 (]: SQL status: BEGIN in 0.116 seconds
[0m10:40:58.547866 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.548704 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,

        case
            when delivered_at is null then null
            else (delivered_at::date - expected_delivery_date::date)
        end as delivery_delay_days,

        case
            when delivered_at is null then null
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery

    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:40:58.552292 [debug] [Thread-3 (]: SQL status: BEGIN in 0.118 seconds
[0m10:40:58.553261 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.554044 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:40:58.560380 [debug] [Thread-4 (]: Database Error in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)
  column "status" does not exist
  LINE 19:     status,
               ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql
[0m10:40:58.561492 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A9F4E5D0>]}
[0m10:40:58.563543 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.013 seconds
[0m10:40:58.562762 [error] [Thread-4 (]: 4 of 5 ERROR creating sql table model analytics.daily_shipments_status ......... [[31mERROR[0m in 0.19s]
[0m10:40:58.570575 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.571532 [debug] [Thread-3 (]: SQL status: SELECT 3 in 0.017 seconds
[0m10:40:58.573042 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:40:58.574081 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
alter table "delivery_analytics"."analytics"."fct_shipments_sla" rename to "fct_shipments_sla__dbt_backup"
[0m10:40:58.580390 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.581859 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.daily_shipments_status' to be skipped because of status 'error'.  Reason: Database Error in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)
  column "status" does not exist
  LINE 19:     status,
               ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql.
[0m10:40:58.583161 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
alter table "delivery_analytics"."analytics"."courier_performance" rename to "courier_performance__dbt_backup"
[0m10:40:58.584119 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:58.590962 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.591744 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.005 seconds
[0m10:40:58.592571 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
alter table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp" rename to "fct_shipments_sla"
[0m10:40:58.597502 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.598647 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
alter table "delivery_analytics"."analytics"."courier_performance__dbt_tmp" rename to "courier_performance"
[0m10:40:58.600242 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:40:58.601352 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:40:58.604288 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: COMMIT
[0m10:40:58.607075 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: COMMIT
[0m10:40:58.607984 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.608975 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.609872 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: COMMIT
[0m10:40:58.610746 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: COMMIT
[0m10:40:58.614021 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m10:40:58.614880 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m10:40:58.619266 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_sla__dbt_backup"
[0m10:40:58.623324 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."courier_performance__dbt_backup"
[0m10:40:58.624896 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:40:58.626511 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:40:58.627442 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_sla__dbt_backup" cascade
[0m10:40:58.628373 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
drop table if exists "delivery_analytics"."analytics"."courier_performance__dbt_backup" cascade
[0m10:40:58.640318 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.011 seconds
[0m10:40:58.641357 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.012 seconds
[0m10:40:58.644048 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:40:58.646549 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:40:58.647883 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A96BF450>]}
[0m10:40:58.648969 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e831bf36-10d1-4665-8a18-6c43c1abeed8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0AA000150>]}
[0m10:40:58.650628 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.courier_performance ................ [[32mSELECT 3[0m in 0.27s]
[0m10:40:58.653543 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:40:58.652040 [info ] [Thread-2 (]: 5 of 5 OK created sql table model analytics.fct_shipments_sla .................. [[32mSELECT 6[0m in 0.27s]
[0m10:40:58.655449 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:40:58.658460 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:58.659190 [debug] [MainThread]: On master: BEGIN
[0m10:40:58.659775 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:40:58.746327 [debug] [MainThread]: SQL status: BEGIN in 0.086 seconds
[0m10:40:58.747223 [debug] [MainThread]: On master: COMMIT
[0m10:40:58.747783 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:58.748387 [debug] [MainThread]: On master: COMMIT
[0m10:40:58.749631 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:40:58.750376 [debug] [MainThread]: On master: Close
[0m10:40:58.751450 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:40:58.752068 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:40:58.752558 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:40:58.753073 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:40:58.753523 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m10:40:58.754048 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:40:58.754481 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:40:58.755143 [info ] [MainThread]: 
[0m10:40:58.756236 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.57 seconds (1.57s).
[0m10:40:58.759043 [debug] [MainThread]: Command end result
[0m10:40:58.807527 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:40:58.812898 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:40:58.829032 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:40:58.829731 [info ] [MainThread]: 
[0m10:40:58.830810 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:40:58.831994 [info ] [MainThread]: 
[0m10:40:58.833332 [error] [MainThread]: [31mFailure in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)[0m
[0m10:40:58.834511 [error] [MainThread]:   Database Error in model daily_shipments_status (models\marts\analytics\daily_shipments_status.sql)
  column "status" does not exist
  LINE 19:     status,
               ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql
[0m10:40:58.835570 [info ] [MainThread]: 
[0m10:40:58.836899 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\daily_shipments_status.sql
[0m10:40:58.838170 [info ] [MainThread]: 
[0m10:40:58.839231 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m10:40:58.842111 [debug] [MainThread]: Command `dbt run` failed at 10:40:58.841737 after 3.79 seconds
[0m10:40:58.843079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A6C34A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A8151550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C0A9673C50>]}
[0m10:40:58.843822 [debug] [MainThread]: Flushing usage events
[0m10:41:00.314566 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:44:03.134535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF0F2E0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF0FD8CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF103D7D90>]}


============================== 10:44:03.174381 | 5d50b152-b0bd-4597-a770-b3ffb10514f4 ==============================
[0m10:44:03.174381 [info ] [MainThread]: Running with dbt=1.10.15
[0m10:44:03.176063 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select marts.analytics', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m10:44:03.532819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF0F748770>]}
[0m10:44:03.658597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF1027EE00>]}
[0m10:44:03.660517 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:44:04.327505 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m10:44:04.641978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:44:04.643294 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\daily_shipments_status.sql
[0m10:44:05.219841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF11CED850>]}
[0m10:44:05.388341 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:44:05.394686 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:44:05.527534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF1026FD40>]}
[0m10:44:05.528526 [info ] [MainThread]: Found 13 models, 5 data tests, 5 sources, 459 macros
[0m10:44:05.529715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF11CC6DD0>]}
[0m10:44:05.533315 [info ] [MainThread]: 
[0m10:44:05.534301 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:44:05.535305 [info ] [MainThread]: 
[0m10:44:05.536704 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:44:05.546397 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m10:44:05.735727 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m10:44:05.736452 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:44:05.737009 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:44:05.938373 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.201 seconds
[0m10:44:05.941252 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m10:44:05.945610 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m10:44:05.957412 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:44:05.958337 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m10:44:05.958856 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:44:06.065367 [debug] [ThreadPool]: SQL status: BEGIN in 0.106 seconds
[0m10:44:06.066454 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m10:44:06.067172 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:44:06.083183 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.015 seconds
[0m10:44:06.085968 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m10:44:06.086983 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m10:44:06.100803 [debug] [MainThread]: Using postgres connection "master"
[0m10:44:06.101523 [debug] [MainThread]: On master: BEGIN
[0m10:44:06.102100 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:44:06.209329 [debug] [MainThread]: SQL status: BEGIN in 0.107 seconds
[0m10:44:06.210069 [debug] [MainThread]: Using postgres connection "master"
[0m10:44:06.210749 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:44:06.231351 [debug] [MainThread]: SQL status: SELECT 5 in 0.020 seconds
[0m10:44:06.235248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF11FDBEE0>]}
[0m10:44:06.236135 [debug] [MainThread]: On master: ROLLBACK
[0m10:44:06.237323 [debug] [MainThread]: Using postgres connection "master"
[0m10:44:06.238340 [debug] [MainThread]: On master: BEGIN
[0m10:44:06.239862 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:44:06.240570 [debug] [MainThread]: On master: COMMIT
[0m10:44:06.241236 [debug] [MainThread]: Using postgres connection "master"
[0m10:44:06.241764 [debug] [MainThread]: On master: COMMIT
[0m10:44:06.242780 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:44:06.243580 [debug] [MainThread]: On master: Close
[0m10:44:06.252117 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:44:06.253107 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m10:44:06.254146 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:44:06.255559 [info ] [Thread-1 (]: 1 of 5 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m10:44:06.257027 [info ] [Thread-2 (]: 2 of 5 START sql table model analytics.fct_shipments ........................... [RUN]
[0m10:44:06.260015 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m10:44:06.261194 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m10:44:06.258599 [info ] [Thread-3 (]: 3 of 5 START sql table model analytics.fct_shipments_revenue ................... [RUN]
[0m10:44:06.262234 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m10:44:06.263087 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m10:44:06.264160 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments_revenue'
[0m10:44:06.278002 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.284464 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.285451 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:44:06.293629 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.295763 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m10:44:06.296699 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m10:44:06.403668 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:44:06.405018 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.406396 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.413107 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.417101 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.418075 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.419164 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.420317 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m10:44:06.449093 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m10:44:06.450356 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: BEGIN
[0m10:44:06.451275 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:44:06.452272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:44:06.453239 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:44:06.609371 [debug] [Thread-2 (]: SQL status: BEGIN in 0.158 seconds
[0m10:44:06.610264 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.611024 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."raw"."shipments"
),

assignments as (
    select
        shipment_id,
        courier_id,
        delivered_at
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    s.shipment_id,
    a.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    a.delivered_at,
    s.price,

    case
        when a.delivered_at is null then null
        when a.delivered_at::date > s.expected_delivery_date::date then true
        else false
    end as late_delivery

from shipments s
left join assignments a
    on s.shipment_id = a.shipment_id
  );
  
[0m10:44:06.613607 [debug] [Thread-1 (]: SQL status: BEGIN in 0.161 seconds
[0m10:44:06.614367 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.615027 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    select
    status_timestamp::date as shipment_date,
    status,
    count(*) as shipments_count
from "delivery_analytics"."analytics"."stg_shipment_status"
group by
    status_timestamp::date,
    status
order by
    shipment_date,
    status
  );
  
[0m10:44:06.621013 [debug] [Thread-3 (]: SQL status: BEGIN in 0.168 seconds
[0m10:44:06.621924 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.622725 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp"
  
  
    as
  
  (
    -- Analiza prihoda po danu, po kuriru ili po mjesecu.

select
    s.shipment_id,
    ca.courier_id,
    s.shipment_date,
    s.expected_delivery_date,
    ca.delivered_at,
    s.price,

    case
        when ca.delivered_at is null then null
        when ca.delivered_at::date > s.expected_delivery_date then true
        else false
    end as late_delivery

from "delivery_analytics"."raw"."shipments" s
left join "delivery_analytics"."raw"."courier_assignments" ca
    on s.shipment_id = ca.shipment_id
  );
  
[0m10:44:06.627507 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.016 seconds
[0m10:44:06.645452 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.646326 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.031 seconds
[0m10:44:06.647161 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m10:44:06.647981 [debug] [Thread-3 (]: SQL status: SELECT 6 in 0.024 seconds
[0m10:44:06.652989 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.658933 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.659876 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m10:44:06.660784 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.007 seconds
[0m10:44:06.661812 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue" rename to "fct_shipments_revenue__dbt_backup"
[0m10:44:06.667196 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.668056 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.005 seconds
[0m10:44:06.669101 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m10:44:06.674041 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.674899 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.006 seconds
[0m10:44:06.676061 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m10:44:06.680820 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.681823 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.006 seconds
[0m10:44:06.682900 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
alter table "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_tmp" rename to "fct_shipments_revenue"
[0m10:44:06.697171 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.014 seconds
[0m10:44:06.714882 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:44:06.715900 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m10:44:06.718723 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:44:06.719634 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.723501 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:44:06.724451 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.725461 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m10:44:06.726465 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.727488 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m10:44:06.728742 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: COMMIT
[0m10:44:06.730526 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m10:44:06.741840 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m10:44:06.742736 [debug] [Thread-1 (]: SQL status: COMMIT in 0.013 seconds
[0m10:44:06.752347 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m10:44:06.753132 [debug] [Thread-3 (]: SQL status: COMMIT in 0.023 seconds
[0m10:44:06.758063 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m10:44:06.759007 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m10:44:06.763000 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup"
[0m10:44:06.764507 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m10:44:06.766268 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_revenue"
[0m10:44:06.767279 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m10:44:06.768181 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_revenue"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_revenue__dbt_backup" cascade
[0m10:44:06.773122 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.008 seconds
[0m10:44:06.777639 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m10:44:06.778533 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.009 seconds
[0m10:44:06.779337 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.010 seconds
[0m10:44:06.782471 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.fct_shipments_revenue: Close
[0m10:44:06.787392 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m10:44:06.790205 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF121FD190>]}
[0m10:44:06.791120 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF1214C7E0>]}
[0m10:44:06.791879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF1214CCB0>]}
[0m10:44:06.793152 [info ] [Thread-2 (]: 2 of 5 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 6[0m in 0.52s]
[0m10:44:06.797558 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m10:44:06.794506 [info ] [Thread-3 (]: 3 of 5 OK created sql table model analytics.fct_shipments_revenue .............. [[32mSELECT 6[0m in 0.53s]
[0m10:44:06.796031 [info ] [Thread-1 (]: 1 of 5 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 5[0m in 0.53s]
[0m10:44:06.800319 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_revenue
[0m10:44:06.801159 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:44:06.801987 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m10:44:06.803196 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m10:44:06.804751 [info ] [Thread-2 (]: 5 of 5 START sql table model analytics.fct_shipments_sla ....................... [RUN]
[0m10:44:06.805940 [info ] [Thread-4 (]: 4 of 5 START sql table model analytics.courier_performance ..................... [RUN]
[0m10:44:06.807819 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.fct_shipments, now model.dbt_delivery_analytics.fct_shipments_sla)
[0m10:44:06.809241 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m10:44:06.810170 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:44:06.811109 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m10:44:06.816084 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:06.820816 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m10:44:06.825659 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:44:06.826510 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m10:44:06.832006 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:06.846769 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m10:44:06.850760 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:44:06.851670 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:06.852513 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m10:44:06.853582 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: BEGIN
[0m10:44:06.854532 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:44:06.855775 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:44:06.961954 [debug] [Thread-2 (]: SQL status: BEGIN in 0.106 seconds
[0m10:44:06.962863 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:06.963807 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp"
  
  
    as
  
  (
    /*

Upoređujemo planirani datum isporuke 
(expected_delivery_date) sa stvarnim datumom 
isporuke (delivered_at). Izračunavamo trajanje 
isporuke i označavamo late_delivery kao true/false.

*/


with sla as (
    select
        shipment_id,
        courier_id,
        shipment_date,
        expected_delivery_date,
        delivered_at,

        case
            when delivered_at is null then null
            else (delivered_at::date - expected_delivery_date::date)
        end as delivery_delay_days,

        case
            when delivered_at is null then null
            when delivered_at::date > expected_delivery_date::date then true
            else false
        end as late_delivery

    from "delivery_analytics"."analytics"."fct_shipments"
)

select *
from sla
  );
  
[0m10:44:06.966996 [debug] [Thread-4 (]: SQL status: BEGIN in 0.113 seconds
[0m10:44:06.967817 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:44:06.968452 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when late_delivery = false then 1 else 0 end) as on_time_shipments,
    sum(case when late_delivery = true then 1 else 0 end) as late_shipments
from "delivery_analytics"."analytics"."fct_shipments"
group by courier_id
  );
  
[0m10:44:06.978489 [debug] [Thread-2 (]: SQL status: SELECT 6 in 0.014 seconds
[0m10:44:06.983742 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:06.984529 [debug] [Thread-4 (]: SQL status: SELECT 3 in 0.015 seconds
[0m10:44:06.985378 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
alter table "delivery_analytics"."analytics"."fct_shipments_sla" rename to "fct_shipments_sla__dbt_backup"
[0m10:44:06.991237 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:44:06.992258 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
alter table "delivery_analytics"."analytics"."courier_performance" rename to "courier_performance__dbt_backup"
[0m10:44:06.993010 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:44:06.998002 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:06.998791 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.005 seconds
[0m10:44:06.999565 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
alter table "delivery_analytics"."analytics"."fct_shipments_sla__dbt_tmp" rename to "fct_shipments_sla"
[0m10:44:07.003998 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:44:07.005194 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
alter table "delivery_analytics"."analytics"."courier_performance__dbt_tmp" rename to "courier_performance"
[0m10:44:07.006615 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:44:07.007416 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:44:07.010281 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: COMMIT
[0m10:44:07.013167 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: COMMIT
[0m10:44:07.014086 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:07.015019 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:44:07.015852 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: COMMIT
[0m10:44:07.016881 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: COMMIT
[0m10:44:07.019400 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m10:44:07.024128 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments_sla__dbt_backup"
[0m10:44:07.024923 [debug] [Thread-4 (]: SQL status: COMMIT in 0.007 seconds
[0m10:44:07.026383 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments_sla"
[0m10:44:07.030015 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."courier_performance__dbt_backup"
[0m10:44:07.030933 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments_sla"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments_sla__dbt_backup" cascade
[0m10:44:07.032564 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m10:44:07.033747 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */
drop table if exists "delivery_analytics"."analytics"."courier_performance__dbt_backup" cascade
[0m10:44:07.042838 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.008 seconds
[0m10:44:07.043748 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.010 seconds
[0m10:44:07.046348 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m10:44:07.048934 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.fct_shipments_sla: Close
[0m10:44:07.050255 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF120F2ED0>]}
[0m10:44:07.052455 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d50b152-b0bd-4597-a770-b3ffb10514f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF1236A580>]}
[0m10:44:07.051496 [info ] [Thread-4 (]: 4 of 5 OK created sql table model analytics.courier_performance ................ [[32mSELECT 3[0m in 0.24s]
[0m10:44:07.055451 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m10:44:07.054166 [info ] [Thread-2 (]: 5 of 5 OK created sql table model analytics.fct_shipments_sla .................. [[32mSELECT 6[0m in 0.24s]
[0m10:44:07.057584 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.fct_shipments_sla
[0m10:44:07.060647 [debug] [MainThread]: Using postgres connection "master"
[0m10:44:07.061367 [debug] [MainThread]: On master: BEGIN
[0m10:44:07.061944 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:44:07.151061 [debug] [MainThread]: SQL status: BEGIN in 0.089 seconds
[0m10:44:07.152045 [debug] [MainThread]: On master: COMMIT
[0m10:44:07.152639 [debug] [MainThread]: Using postgres connection "master"
[0m10:44:07.153164 [debug] [MainThread]: On master: COMMIT
[0m10:44:07.154247 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:44:07.155245 [debug] [MainThread]: On master: Close
[0m10:44:07.156275 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:44:07.156877 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m10:44:07.157353 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m10:44:07.157863 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m10:44:07.158319 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_sla' was properly closed.
[0m10:44:07.158840 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments_revenue' was properly closed.
[0m10:44:07.159272 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m10:44:07.159939 [info ] [MainThread]: 
[0m10:44:07.161154 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 1.62 seconds (1.62s).
[0m10:44:07.163891 [debug] [MainThread]: Command end result
[0m10:44:07.210547 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m10:44:07.215892 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m10:44:07.229130 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m10:44:07.230004 [info ] [MainThread]: 
[0m10:44:07.231306 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:44:07.232348 [info ] [MainThread]: 
[0m10:44:07.233523 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m10:44:07.235554 [debug] [MainThread]: Command `dbt run` succeeded at 10:44:07.235324 after 4.40 seconds
[0m10:44:07.236236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF0F699B50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF11BDA5D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF10218830>]}
[0m10:44:07.237133 [debug] [MainThread]: Flushing usage events
[0m10:44:08.682488 [debug] [MainThread]: An error was encountered while trying to flush usage events
