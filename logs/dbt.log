[0m11:39:00.930236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC6FC24980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC706DCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC70D17D90>]}


============================== 11:39:00.966587 | 62c1d1e8-b40c-4ef0-aca1-8a5916122bf2 ==============================
[0m11:39:00.966587 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:39:00.967622 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'logs'}
[0m11:39:00.989349 [info ] [MainThread]: dbt version: 1.10.15
[0m11:39:00.990021 [info ] [MainThread]: python version: 3.13.3
[0m11:39:00.990630 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m11:39:00.991464 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m11:39:01.131578 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m11:39:01.132669 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m11:39:01.133224 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m11:39:01.134550 [info ] [MainThread]: Configuration:
[0m11:39:01.135123 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m11:39:01.135651 [info ] [MainThread]:   dbt_project.yml file [[31mERROR invalid[0m]
[0m11:39:01.136107 [info ] [MainThread]: Required dependencies:
[0m11:39:01.136628 [debug] [MainThread]: Executing "git --help"
[0m11:39:03.703129 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:39:03.703774 [debug] [MainThread]: STDERR: "b''"
[0m11:39:03.704220 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:39:03.704788 [info ] [MainThread]: Connection test skipped since no profile was found
[0m11:39:03.705410 [info ] [MainThread]: [31m2 checks failed:[0m
[0m11:39:03.705908 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "dbt_delivery_analytics", target "dev" invalid: 1234 is not of type 'string'


[0m11:39:03.706633 [info ] [MainThread]: Project loading failed for the following reason:
Runtime Error
  dbt_project.yml does not parse to a dictionary


[0m11:39:03.707974 [debug] [MainThread]: Command `dbt debug` failed at 11:39:03.707831 after 2.98 seconds
[0m11:39:03.708388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC7231CE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC722F7410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC72222E00>]}
[0m11:39:03.708788 [debug] [MainThread]: Flushing usage events
[0m11:39:04.688852 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:40:45.613509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964E8C4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964F36CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964F9A7D90>]}


============================== 11:40:45.617854 | 6792b6b5-c5a5-4799-9309-15e2b3bbb402 ==============================
[0m11:40:45.617854 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:40:45.618602 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:40:45.638747 [info ] [MainThread]: dbt version: 1.10.15
[0m11:40:45.639445 [info ] [MainThread]: python version: 3.13.3
[0m11:40:45.639916 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m11:40:45.640406 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m11:40:45.728115 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m11:40:45.728802 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m11:40:45.729522 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m11:40:45.730907 [info ] [MainThread]: adapter type: postgres
[0m11:40:45.731431 [info ] [MainThread]: adapter version: 1.9.1
[0m11:40:45.839369 [info ] [MainThread]: Configuration:
[0m11:40:45.840080 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:40:45.840628 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:40:45.841177 [info ] [MainThread]: Required dependencies:
[0m11:40:45.841691 [debug] [MainThread]: Executing "git --help"
[0m11:40:46.110288 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:40:46.110956 [debug] [MainThread]: STDERR: "b''"
[0m11:40:46.111375 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:40:46.111861 [info ] [MainThread]: Connection:
[0m11:40:46.112413 [info ] [MainThread]:   host: localhost
[0m11:40:46.112986 [info ] [MainThread]:   port: 5433
[0m11:40:46.113392 [info ] [MainThread]:   user: postgres
[0m11:40:46.113874 [info ] [MainThread]:   database: delivery_analytics
[0m11:40:46.114323 [info ] [MainThread]:   schema: analytics
[0m11:40:46.114746 [info ] [MainThread]:   connect_timeout: 10
[0m11:40:46.115297 [info ] [MainThread]:   role: None
[0m11:40:46.115786 [info ] [MainThread]:   search_path: None
[0m11:40:46.116251 [info ] [MainThread]:   keepalives_idle: 0
[0m11:40:46.116754 [info ] [MainThread]:   sslmode: None
[0m11:40:46.117246 [info ] [MainThread]:   sslcert: None
[0m11:40:46.117813 [info ] [MainThread]:   sslkey: None
[0m11:40:46.118360 [info ] [MainThread]:   sslrootcert: None
[0m11:40:46.118858 [info ] [MainThread]:   application_name: dbt
[0m11:40:46.119332 [info ] [MainThread]:   retries: 1
[0m11:40:46.120321 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:40:46.474860 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m11:40:46.593480 [debug] [MainThread]: Using postgres connection "debug"
[0m11:40:46.593925 [debug] [MainThread]: On debug: select 1 as id
[0m11:40:46.594209 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:40:46.740773 [debug] [MainThread]: SQL status: SELECT 1 in 0.146 seconds
[0m11:40:46.741971 [debug] [MainThread]: On debug: Close
[0m11:40:46.742429 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:40:46.743087 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:40:46.744658 [debug] [MainThread]: Command `dbt debug` succeeded at 11:40:46.744510 after 1.37 seconds
[0m11:40:46.745099 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:40:46.745892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019650FC2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196510996D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001964FAA7CE0>]}
[0m11:40:46.746531 [debug] [MainThread]: Flushing usage events
[0m11:40:47.689720 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:45:57.529102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002260FD34980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226107ECB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610E27D90>]}


============================== 11:45:57.535392 | 304ef73a-6129-45b7-9ed8-d675138210ca ==============================
[0m11:45:57.535392 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:45:57.536426 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select staging', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:45:57.887994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '304ef73a-6129-45b7-9ed8-d675138210ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610198770>]}
[0m11:45:57.983603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '304ef73a-6129-45b7-9ed8-d675138210ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610CCEE00>]}
[0m11:45:57.984754 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:45:58.500227 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:45:58.501608 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:45:58.502232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '304ef73a-6129-45b7-9ed8-d675138210ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610F39850>]}
[0m11:46:00.223659 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:46:00.225936 [debug] [MainThread]: Command `dbt run` failed at 11:46:00.225764 after 2.91 seconds
[0m11:46:00.226577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226126597C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022612659310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022610E2FE70>]}
[0m11:46:00.227160 [debug] [MainThread]: Flushing usage events
[0m11:46:01.344658 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:46:07.344705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B4940980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B53ECB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B5A37D90>]}


============================== 11:46:07.349543 | 456eaf34-f993-4609-91fe-da358f7a28a0 ==============================
[0m11:46:07.349543 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:46:07.350464 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select marts.core', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:46:07.610603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '456eaf34-f993-4609-91fe-da358f7a28a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B4DA8770>]}
[0m11:46:07.687838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '456eaf34-f993-4609-91fe-da358f7a28a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B58DEE00>]}
[0m11:46:07.689286 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:46:08.119298 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:46:08.121016 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:46:08.121747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '456eaf34-f993-4609-91fe-da358f7a28a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B6E69850>]}
[0m11:46:09.406988 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:46:09.408722 [debug] [MainThread]: Command `dbt run` failed at 11:46:09.408554 after 2.25 seconds
[0m11:46:09.409208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B72397C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B7239310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B3B5A3FE70>]}
[0m11:46:09.409665 [debug] [MainThread]: Flushing usage events
[0m11:46:10.347604 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:49:25.797287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD974A0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD97F4CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD98597D90>]}


============================== 11:49:25.803045 | f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc ==============================
[0m11:49:25.803045 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:49:25.804440 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:49:26.083893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD97908770>]}
[0m11:49:26.167721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD9843EE00>]}
[0m11:49:26.169330 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:49:26.619007 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:49:26.620390 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:49:26.621130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f8ab7a31-48fa-4ed9-9ecd-a305ec0996cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD99A49850>]}
[0m11:49:27.946544 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:49:27.948888 [debug] [MainThread]: Command `dbt run` failed at 11:49:27.948681 after 2.47 seconds
[0m11:49:27.949408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD99E197C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD99E19310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BD9859FE70>]}
[0m11:49:27.949979 [debug] [MainThread]: Flushing usage events
[0m11:49:29.053301 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:51:34.783279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADAF00980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADB9ACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADBFEBD90>]}


============================== 11:51:34.788081 | 8e67c9ca-5b38-4a02-9e9c-d922793088d9 ==============================
[0m11:51:34.788081 [info ] [MainThread]: Running with dbt=1.10.15
[0m11:51:34.788980 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m11:51:35.045404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e67c9ca-5b38-4a02-9e9c-d922793088d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADB368770>]}
[0m11:51:35.117685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e67c9ca-5b38-4a02-9e9c-d922793088d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADBE8EE00>]}
[0m11:51:35.119027 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m11:51:35.515165 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m11:51:35.517142 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:51:35.518348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8e67c9ca-5b38-4a02-9e9c-d922793088d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADD0C9850>]}
[0m11:51:36.653875 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m11:51:36.655459 [debug] [MainThread]: Command `dbt run` failed at 11:51:36.655315 after 2.13 seconds
[0m11:51:36.655868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADD8497C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADD849310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AADBFEFE70>]}
[0m11:51:36.656269 [debug] [MainThread]: Flushing usage events
[0m11:51:37.699693 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:13.945713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656AE80980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656B92CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656BF7BD90>]}


============================== 12:25:13.953709 | e27b91c9-2c9c-45d2-b30c-7c9cd64b1605 ==============================
[0m12:25:13.953709 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:25:13.955705 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select marts.core', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:25:14.319441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e27b91c9-2c9c-45d2-b30c-7c9cd64b1605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656B2E8770>]}
[0m12:25:14.404468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e27b91c9-2c9c-45d2-b30c-7c9cd64b1605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656BE1EE00>]}
[0m12:25:14.406300 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:25:14.944330 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:25:14.945724 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:25:14.946595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e27b91c9-2c9c-45d2-b30c-7c9cd64b1605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656D429850>]}
[0m12:25:16.241544 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m12:25:16.243595 [debug] [MainThread]: Command `dbt run` failed at 12:25:16.243399 after 2.62 seconds
[0m12:25:16.244133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656D7F97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656D7F9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002656BF7FE70>]}
[0m12:25:16.244609 [debug] [MainThread]: Flushing usage events
[0m12:25:17.368044 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:32.430866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3B2A4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3BD4CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3C397D90>]}


============================== 12:26:32.438699 | 39d1507c-397f-4c93-b6a3-7efef8d16296 ==============================
[0m12:26:32.438699 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:26:32.440034 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:26:32.478658 [info ] [MainThread]: dbt version: 1.10.15
[0m12:26:32.479901 [info ] [MainThread]: python version: 3.13.3
[0m12:26:32.480938 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m12:26:32.481822 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m12:26:32.638699 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m12:26:32.639633 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m12:26:32.640373 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m12:26:32.641965 [info ] [MainThread]: adapter type: postgres
[0m12:26:32.642520 [info ] [MainThread]: adapter version: 1.9.1
[0m12:26:32.843454 [info ] [MainThread]: Configuration:
[0m12:26:32.844470 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:26:32.845177 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:26:32.845858 [info ] [MainThread]: Required dependencies:
[0m12:26:32.846531 [debug] [MainThread]: Executing "git --help"
[0m12:26:33.525081 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:26:33.525803 [debug] [MainThread]: STDERR: "b''"
[0m12:26:33.526321 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:26:33.527039 [info ] [MainThread]: Connection:
[0m12:26:33.527826 [info ] [MainThread]:   host: localhost
[0m12:26:33.528500 [info ] [MainThread]:   port: 5433
[0m12:26:33.529141 [info ] [MainThread]:   user: postgres
[0m12:26:33.529813 [info ] [MainThread]:   database: delivery_analytics
[0m12:26:33.530485 [info ] [MainThread]:   schema: analytics
[0m12:26:33.531163 [info ] [MainThread]:   connect_timeout: 10
[0m12:26:33.532000 [info ] [MainThread]:   role: None
[0m12:26:33.532879 [info ] [MainThread]:   search_path: None
[0m12:26:33.533646 [info ] [MainThread]:   keepalives_idle: 0
[0m12:26:33.534247 [info ] [MainThread]:   sslmode: None
[0m12:26:33.534993 [info ] [MainThread]:   sslcert: None
[0m12:26:33.535836 [info ] [MainThread]:   sslkey: None
[0m12:26:33.536561 [info ] [MainThread]:   sslrootcert: None
[0m12:26:33.537406 [info ] [MainThread]:   application_name: dbt
[0m12:26:33.538007 [info ] [MainThread]:   retries: 1
[0m12:26:33.539275 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:26:34.131814 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m12:26:34.299492 [debug] [MainThread]: Using postgres connection "debug"
[0m12:26:34.300085 [debug] [MainThread]: On debug: select 1 as id
[0m12:26:34.300453 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:34.463907 [debug] [MainThread]: SQL status: SELECT 1 in 0.163 seconds
[0m12:26:34.465223 [debug] [MainThread]: On debug: Close
[0m12:26:34.465919 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:26:34.466881 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:26:34.468975 [debug] [MainThread]: Command `dbt debug` succeeded at 12:26:34.468786 after 2.26 seconds
[0m12:26:34.469692 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:26:34.470253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3D9B2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3DA896D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE3C4B7CE0>]}
[0m12:26:34.470909 [debug] [MainThread]: Flushing usage events
[0m12:26:35.630461 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:41.714321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F7830980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F82DCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F8927D90>]}


============================== 12:26:41.719601 | 206981eb-d5a2-470f-9ca0-997803c9a5af ==============================
[0m12:26:41.719601 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:26:41.720723 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt source freshness', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:26:41.972655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '206981eb-d5a2-470f-9ca0-997803c9a5af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F7C98770>]}
[0m12:26:42.034752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '206981eb-d5a2-470f-9ca0-997803c9a5af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F87CEE00>]}
[0m12:26:42.036326 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:26:42.466553 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:26:42.467999 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:26:42.468762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '206981eb-d5a2-470f-9ca0-997803c9a5af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F9D79850>]}
[0m12:26:43.491770 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m12:26:43.493751 [debug] [MainThread]: Command `dbt source freshness` failed at 12:26:43.493526 after 1.95 seconds
[0m12:26:43.494553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194FA14E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194FA14C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194F892CC90>]}
[0m12:26:43.495177 [debug] [MainThread]: Flushing usage events
[0m12:26:44.485942 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:28:40.348471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808CC18980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808D6BCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808DD07D90>]}


============================== 12:28:40.354458 | f7484a1b-bd5e-4e88-9730-d75ccb13b435 ==============================
[0m12:28:40.354458 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:28:40.355792 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt clean', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:28:40.553399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7484a1b-bd5e-4e88-9730-d75ccb13b435', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808D078770>]}
[0m12:28:40.593118 [debug] [MainThread]: Command `dbt clean` succeeded at 12:28:40.592927 after 0.55 seconds
[0m12:28:40.593799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808DBAFCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808DBAF680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001808F24E150>]}
[0m12:28:40.594448 [debug] [MainThread]: Flushing usage events
[0m12:28:41.781598 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:28:46.631466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E882474980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E882F2CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E88356BD90>]}


============================== 12:28:46.638381 | ac79a14b-6f4c-4e4b-9c3d-479766383284 ==============================
[0m12:28:46.638381 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:28:46.639401 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt deps', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:28:46.839355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac79a14b-6f4c-4e4b-9c3d-479766383284', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8828D8770>]}
[0m12:28:46.878718 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:28:46.880622 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:28:46.882388 [debug] [MainThread]: Command `dbt deps` succeeded at 12:28:46.882239 after 0.44 seconds
[0m12:28:46.882783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E88340FF00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E88340F130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8833EBA50>]}
[0m12:28:46.883231 [debug] [MainThread]: Flushing usage events
[0m12:28:47.953216 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:28:53.811007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7394C4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A739F6CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73A5A7D90>]}


============================== 12:28:53.816491 | 66bf7b68-0b76-4869-ba0d-b62d167617bf ==============================
[0m12:28:53.816491 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:28:53.818059 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:28:53.847771 [info ] [MainThread]: dbt version: 1.10.15
[0m12:28:53.848690 [info ] [MainThread]: python version: 3.13.3
[0m12:28:53.849715 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m12:28:53.850531 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m12:28:53.964537 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m12:28:53.965436 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m12:28:53.966010 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m12:28:53.967664 [info ] [MainThread]: adapter type: postgres
[0m12:28:53.968164 [info ] [MainThread]: adapter version: 1.9.1
[0m12:28:54.093236 [info ] [MainThread]: Configuration:
[0m12:28:54.094398 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:28:54.094956 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:28:54.095560 [info ] [MainThread]: Required dependencies:
[0m12:28:54.096116 [debug] [MainThread]: Executing "git --help"
[0m12:28:54.365707 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:28:54.366230 [debug] [MainThread]: STDERR: "b''"
[0m12:28:54.366633 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:28:54.367156 [info ] [MainThread]: Connection:
[0m12:28:54.367711 [info ] [MainThread]:   host: localhost
[0m12:28:54.368142 [info ] [MainThread]:   port: 5433
[0m12:28:54.368645 [info ] [MainThread]:   user: postgres
[0m12:28:54.369172 [info ] [MainThread]:   database: delivery_analytics
[0m12:28:54.369774 [info ] [MainThread]:   schema: analytics
[0m12:28:54.370271 [info ] [MainThread]:   connect_timeout: 10
[0m12:28:54.370782 [info ] [MainThread]:   role: None
[0m12:28:54.371384 [info ] [MainThread]:   search_path: None
[0m12:28:54.371931 [info ] [MainThread]:   keepalives_idle: 0
[0m12:28:54.372447 [info ] [MainThread]:   sslmode: None
[0m12:28:54.372983 [info ] [MainThread]:   sslcert: None
[0m12:28:54.373493 [info ] [MainThread]:   sslkey: None
[0m12:28:54.374037 [info ] [MainThread]:   sslrootcert: None
[0m12:28:54.374492 [info ] [MainThread]:   application_name: dbt
[0m12:28:54.374898 [info ] [MainThread]:   retries: 1
[0m12:28:54.375649 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:28:54.983980 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m12:28:55.145396 [debug] [MainThread]: Using postgres connection "debug"
[0m12:28:55.145885 [debug] [MainThread]: On debug: select 1 as id
[0m12:28:55.146425 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:28:55.266956 [debug] [MainThread]: SQL status: SELECT 1 in 0.120 seconds
[0m12:28:55.268598 [debug] [MainThread]: On debug: Close
[0m12:28:55.269207 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:28:55.269968 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:28:55.271345 [debug] [MainThread]: Command `dbt debug` succeeded at 12:28:55.271219 after 1.66 seconds
[0m12:28:55.271710 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:28:55.272221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73BBC2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73BC996D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A73B697CE0>]}
[0m12:28:55.272669 [debug] [MainThread]: Flushing usage events
[0m12:28:56.330253 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:01.173226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4014980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4ACCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A5107D90>]}


============================== 12:29:01.179714 | 510d9f84-dd19-4e84-91b1-7fb59660ef8e ==============================
[0m12:29:01.179714 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:29:01.180889 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt source freshness', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:29:01.507506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '510d9f84-dd19-4e84-91b1-7fb59660ef8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4478770>]}
[0m12:29:01.596227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '510d9f84-dd19-4e84-91b1-7fb59660ef8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A4FAEE00>]}
[0m12:29:01.598300 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:29:02.119266 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:29:02.120522 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:29:02.121130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '510d9f84-dd19-4e84-91b1-7fb59660ef8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A61E9850>]}
[0m12:29:03.614967 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.std_shipment_status' (models\staging\std_shipment_status.sql) depends on a source named 'raw.shipment_status' which was not found
[0m12:29:03.616898 [debug] [MainThread]: Command `dbt source freshness` failed at 12:29:03.616730 after 2.63 seconds
[0m12:29:03.617573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A694E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A694C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212A510CC90>]}
[0m12:29:03.618169 [debug] [MainThread]: Flushing usage events
[0m12:29:04.698742 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:43.436907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CDBA4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CE65CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CEC97D90>]}


============================== 12:29:43.443248 | c3b38175-532b-427a-b78a-048a8ca27261 ==============================
[0m12:29:43.443248 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:29:43.444218 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt source freshness', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:29:43.808394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c3b38175-532b-427a-b78a-048a8ca27261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CE008770>]}
[0m12:29:43.877786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c3b38175-532b-427a-b78a-048a8ca27261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CEB3EE00>]}
[0m12:29:43.879580 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:29:44.509449 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:29:44.511124 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:29:44.511827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c3b38175-532b-427a-b78a-048a8ca27261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CFD79850>]}
[0m12:29:45.904118 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:29:45.906140 [debug] [MainThread]: Command `dbt source freshness` failed at 12:29:45.905995 after 2.69 seconds
[0m12:29:45.906530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7D04EE7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7D04EC320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7CEC9CC90>]}
[0m12:29:45.906914 [debug] [MainThread]: Flushing usage events
[0m12:29:47.057553 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:32:17.211920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FCE14980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FD8CCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FDF07D90>]}


============================== 12:32:17.218235 | 04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8 ==============================
[0m12:32:17.218235 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:32:17.219384 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt source freshness', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:32:17.578961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FD278770>]}
[0m12:32:17.684133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FDDAEE00>]}
[0m12:32:17.686041 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:32:18.498963 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:32:18.501007 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:32:18.501905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04ab8250-ad3a-46c5-be2f-a1ec28fcb0b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FF339850>]}
[0m12:32:19.815616 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:32:19.817689 [debug] [MainThread]: Command `dbt source freshness` failed at 12:32:19.817537 after 2.93 seconds
[0m12:32:19.818140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FF70E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FF70C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FDF0CC90>]}
[0m12:32:19.818705 [debug] [MainThread]: Flushing usage events
[0m12:32:20.802630 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:32:43.392183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CAFEC4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB096CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0FBBD90>]}


============================== 12:32:43.398902 | 3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35 ==============================
[0m12:32:43.398902 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:32:43.400377 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:32:43.692066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0328770>]}
[0m12:32:43.776225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0E5EE00>]}
[0m12:32:43.778111 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:32:44.312393 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:32:44.313928 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:32:44.314716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3e4cdd9a-a56b-4ec4-bab7-7eed0616dd35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB10C9850>]}
[0m12:32:45.619926 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:32:45.621912 [debug] [MainThread]: Command `dbt run` failed at 12:32:45.621744 after 2.44 seconds
[0m12:32:45.622519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB28197C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB2819310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014CB0FBFE70>]}
[0m12:32:45.623017 [debug] [MainThread]: Flushing usage events
[0m12:32:46.676640 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:33:47.779163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A775980980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A77643CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A776A77D90>]}


============================== 12:33:47.785470 | bbc386af-26db-4dc5-ba5c-870671bda6f2 ==============================
[0m12:33:47.785470 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:33:47.787000 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:33:48.109542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bbc386af-26db-4dc5-ba5c-870671bda6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A775DE8770>]}
[0m12:33:48.202185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bbc386af-26db-4dc5-ba5c-870671bda6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A77691EE00>]}
[0m12:33:48.215566 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:33:48.746932 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:33:48.748429 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:33:48.749206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bbc386af-26db-4dc5-ba5c-870671bda6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A777EA9850>]}
[0m12:33:49.953791 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:33:49.956007 [debug] [MainThread]: Command `dbt run` failed at 12:33:49.955811 after 2.42 seconds
[0m12:33:49.956552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A7782797C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A778279310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A776A7FE70>]}
[0m12:33:49.957027 [debug] [MainThread]: Flushing usage events
[0m12:33:51.023877 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:34:47.825257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D33FC4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D34A7CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D350B7D90>]}


============================== 12:34:47.831265 | 06ae78a2-7e82-47f5-b076-4414b39d6fda ==============================
[0m12:34:47.831265 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:34:47.832571 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:34:48.153118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06ae78a2-7e82-47f5-b076-4414b39d6fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D34428770>]}
[0m12:34:48.244423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06ae78a2-7e82-47f5-b076-4414b39d6fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D34F5EE00>]}
[0m12:34:48.246539 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:34:48.788128 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:34:48.790174 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:34:48.790863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '06ae78a2-7e82-47f5-b076-4414b39d6fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D364E9850>]}
[0m12:34:50.110402 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:34:50.112386 [debug] [MainThread]: Command `dbt run` failed at 12:34:50.112142 after 2.51 seconds
[0m12:34:50.112984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D368B97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D368B9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D350BFE70>]}
[0m12:34:50.113478 [debug] [MainThread]: Flushing usage events
[0m12:34:51.235923 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:15.057554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D30BF4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D3169CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D31CE7D90>]}


============================== 12:41:15.063480 | 6a9fc7d7-8416-4b99-9924-fe9ee1e7a41c ==============================
[0m12:41:15.063480 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:41:15.064657 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:41:15.104106 [info ] [MainThread]: dbt version: 1.10.15
[0m12:41:15.105184 [info ] [MainThread]: python version: 3.13.3
[0m12:41:15.105990 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m12:41:15.106800 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m12:41:15.212164 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m12:41:15.213274 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m12:41:15.214266 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m12:41:15.216017 [info ] [MainThread]: adapter type: postgres
[0m12:41:15.216840 [info ] [MainThread]: adapter version: 1.9.1
[0m12:41:15.360794 [info ] [MainThread]: Configuration:
[0m12:41:15.362047 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:41:15.362997 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:41:15.363828 [info ] [MainThread]: Required dependencies:
[0m12:41:15.364814 [debug] [MainThread]: Executing "git --help"
[0m12:41:15.641912 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:41:15.642926 [debug] [MainThread]: STDERR: "b''"
[0m12:41:15.643485 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:41:15.644309 [info ] [MainThread]: Connection:
[0m12:41:15.645184 [info ] [MainThread]:   host: localhost
[0m12:41:15.645957 [info ] [MainThread]:   port: 5433
[0m12:41:15.646725 [info ] [MainThread]:   user: postgres
[0m12:41:15.647547 [info ] [MainThread]:   database: delivery_analytics
[0m12:41:15.648341 [info ] [MainThread]:   schema: analytics
[0m12:41:15.649182 [info ] [MainThread]:   connect_timeout: 10
[0m12:41:15.649889 [info ] [MainThread]:   role: None
[0m12:41:15.650601 [info ] [MainThread]:   search_path: None
[0m12:41:15.651382 [info ] [MainThread]:   keepalives_idle: 0
[0m12:41:15.652059 [info ] [MainThread]:   sslmode: None
[0m12:41:15.652669 [info ] [MainThread]:   sslcert: None
[0m12:41:15.653355 [info ] [MainThread]:   sslkey: None
[0m12:41:15.653993 [info ] [MainThread]:   sslrootcert: None
[0m12:41:15.654650 [info ] [MainThread]:   application_name: dbt
[0m12:41:15.655305 [info ] [MainThread]:   retries: 1
[0m12:41:15.656534 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:41:16.212599 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m12:41:16.383368 [debug] [MainThread]: Using postgres connection "debug"
[0m12:41:16.383874 [debug] [MainThread]: On debug: select 1 as id
[0m12:41:16.384257 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:16.536812 [debug] [MainThread]: SQL status: SELECT 1 in 0.152 seconds
[0m12:41:16.538618 [debug] [MainThread]: On debug: Close
[0m12:41:16.539137 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:41:16.539973 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:41:16.542419 [debug] [MainThread]: Command `dbt debug` succeeded at 12:41:16.542263 after 1.80 seconds
[0m12:41:16.542847 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:41:16.543401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D33362B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D3343D6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D331C7CE0>]}
[0m12:41:16.544138 [debug] [MainThread]: Flushing usage events
[0m12:41:17.632073 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:23.461518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCBD94980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCC82CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCCE77D90>]}


============================== 12:41:23.466407 | d59166be-e54d-4ee4-b87e-a055730a2fea ==============================
[0m12:41:23.466407 [info ] [MainThread]: Running with dbt=1.10.15
[0m12:41:23.467302 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m12:41:23.700430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd59166be-e54d-4ee4-b87e-a055730a2fea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCC1F8770>]}
[0m12:41:23.761943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd59166be-e54d-4ee4-b87e-a055730a2fea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCCD1EE00>]}
[0m12:41:23.763525 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m12:41:24.170871 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m12:41:24.172146 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:41:24.172901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd59166be-e54d-4ee4-b87e-a055730a2fea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCE329850>]}
[0m12:41:25.185511 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m12:41:25.187357 [debug] [MainThread]: Command `dbt run` failed at 12:41:25.187217 after 1.88 seconds
[0m12:41:25.187875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCE6F97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCE6F9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CCCE7FE70>]}
[0m12:41:25.188377 [debug] [MainThread]: Flushing usage events
[0m12:41:26.177168 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:48:45.989927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E264880980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E26532CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E265977D90>]}


============================== 13:48:45.996954 | eab4d17c-c281-4435-9620-9b2f3506958a ==============================
[0m13:48:45.996954 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:48:45.998505 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'use_colors': 'True', 'invocation_command': 'dbt run --select staging', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:48:46.334626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eab4d17c-c281-4435-9620-9b2f3506958a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E264CE8770>]}
[0m13:48:46.427844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eab4d17c-c281-4435-9620-9b2f3506958a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E26581EE00>]}
[0m13:48:46.429863 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:48:46.918174 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:48:46.919439 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:48:46.920193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eab4d17c-c281-4435-9620-9b2f3506958a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E266DA9850>]}
[0m13:48:47.974368 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:48:47.976137 [debug] [MainThread]: Command `dbt run` failed at 13:48:47.975995 after 2.34 seconds
[0m13:48:47.976755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E2671797C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E267179310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E26597FE70>]}
[0m13:48:47.977263 [debug] [MainThread]: Flushing usage events
[0m13:48:49.115236 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:54.810474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE88AC4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8957CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE89BB7D90>]}


============================== 13:49:54.816816 | 82b47af0-44e4-4b74-9b8a-34ebcea07274 ==============================
[0m13:49:54.816816 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:49:54.818188 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:49:55.112730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '82b47af0-44e4-4b74-9b8a-34ebcea07274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE88F28770>]}
[0m13:49:55.195988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '82b47af0-44e4-4b74-9b8a-34ebcea07274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE89A5EE00>]}
[0m13:49:55.197738 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:49:55.716590 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:49:55.717940 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:49:55.718554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '82b47af0-44e4-4b74-9b8a-34ebcea07274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8B0C9850>]}
[0m13:49:56.720365 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:49:56.722062 [debug] [MainThread]: Command `dbt run` failed at 13:49:56.721897 after 2.13 seconds
[0m13:49:56.722526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8B4997C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE8B499310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE89BBFE70>]}
[0m13:49:56.722981 [debug] [MainThread]: Flushing usage events
[0m13:49:57.676580 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:51:33.046019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF1894980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF233CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF2987D90>]}


============================== 13:51:33.055917 | f56b7041-1bf1-4990-bcee-a42b428e736c ==============================
[0m13:51:33.055917 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:51:33.057332 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt source snapshot-freshness', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:51:33.361417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f56b7041-1bf1-4990-bcee-a42b428e736c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF1CF8770>]}
[0m13:51:33.453758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f56b7041-1bf1-4990-bcee-a42b428e736c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF282EE00>]}
[0m13:51:33.455809 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:51:34.018295 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:51:34.020003 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:51:34.020737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f56b7041-1bf1-4990-bcee-a42b428e736c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF3DE9850>]}
[0m13:51:35.339146 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:51:35.341299 [debug] [MainThread]: Command `dbt source snapshot-freshness` failed at 13:51:35.341119 after 2.64 seconds
[0m13:51:35.341813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF41C27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF41C0320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF298CC90>]}
[0m13:51:35.342289 [debug] [MainThread]: Flushing usage events
[0m13:51:36.452829 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:52:36.733388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89B884980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C32CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C977D90>]}


============================== 13:52:36.739291 | 13bacde7-4be0-4c46-8239-2cef1b15bbf2 ==============================
[0m13:52:36.739291 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:52:36.740677 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt source snapshot-freshness', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:52:37.072612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13bacde7-4be0-4c46-8239-2cef1b15bbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89BCE8770>]}
[0m13:52:37.165681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13bacde7-4be0-4c46-8239-2cef1b15bbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C81EE00>]}
[0m13:52:37.169662 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:52:37.860194 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:52:37.862299 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:52:37.863557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '13bacde7-4be0-4c46-8239-2cef1b15bbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89CE89850>]}
[0m13:52:39.121764 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:52:39.124241 [debug] [MainThread]: Command `dbt source snapshot-freshness` failed at 13:52:39.124035 after 2.64 seconds
[0m13:52:39.124659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89E22E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89E22C320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A89C97CC90>]}
[0m13:52:39.125097 [debug] [MainThread]: Flushing usage events
[0m13:52:40.117248 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:54:16.446804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231CFC70980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D072CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D0D6BD90>]}


============================== 13:54:16.453166 | a52d5d50-ef11-43c7-845d-4cc643cbd88b ==============================
[0m13:54:16.453166 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:54:16.454622 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt ls --resource-type source', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:54:16.777828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a52d5d50-ef11-43c7-845d-4cc643cbd88b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D00D8770>]}
[0m13:54:16.860476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a52d5d50-ef11-43c7-845d-4cc643cbd88b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D0C0EF10>]}
[0m13:54:16.862484 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:54:17.407856 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:54:17.409571 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:54:17.410570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a52d5d50-ef11-43c7-845d-4cc643cbd88b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D2199850>]}
[0m13:54:18.738653 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_delivery_analytics.stg_couriers' (models\staging\stg_couriers.sql) depends on a source named 'raw.couriers' which was not found
[0m13:54:18.740619 [debug] [MainThread]: Command `dbt ls` failed at 13:54:18.740448 after 2.59 seconds
[0m13:54:18.741137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D256A6C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D2568230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D0D6FE70>]}
[0m13:54:18.741614 [debug] [MainThread]: Flushing usage events
[0m13:54:19.817483 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:04.046895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A335714980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A3361ACB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A3367F7D90>]}


============================== 13:57:04.051819 | 5b818468-9b15-4aac-b0a2-e216a692e801 ==============================
[0m13:57:04.051819 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:04.052819 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt clean', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:04.243329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b818468-9b15-4aac-b0a2-e216a692e801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A335B78770>]}
[0m13:57:04.276209 [debug] [MainThread]: Command `dbt clean` succeeded at 13:57:04.276056 after 0.47 seconds
[0m13:57:04.276813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A33669FCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A33669F680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A337D0E150>]}
[0m13:57:04.277326 [debug] [MainThread]: Flushing usage events
[0m13:57:05.455994 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:11.222256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAA9C0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB46CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FABABBD90>]}


============================== 13:57:11.227188 | 260b6779-cc26-4336-8a0f-1de9215a560f ==============================
[0m13:57:11.227188 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:11.228341 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt deps', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:11.437840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '260b6779-cc26-4336-8a0f-1de9215a560f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAAE28770>]}
[0m13:57:11.487684 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:57:11.492598 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:57:11.494860 [debug] [MainThread]: Command `dbt deps` succeeded at 13:57:11.494551 after 0.47 seconds
[0m13:57:11.495415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB95FF00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB95F130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027FAB93BA50>]}
[0m13:57:11.495952 [debug] [MainThread]: Flushing usage events
[0m13:57:12.584064 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:20.222982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDD564980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDE00CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDE65BD90>]}


============================== 13:57:20.228038 | 40f9d7f2-ef3c-4999-8037-11105efa282a ==============================
[0m13:57:20.228038 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:20.228873 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:20.260163 [info ] [MainThread]: dbt version: 1.10.15
[0m13:57:20.260902 [info ] [MainThread]: python version: 3.13.3
[0m13:57:20.261427 [info ] [MainThread]: python path: C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\venv\Scripts\python.exe
[0m13:57:20.261951 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m13:57:20.387320 [info ] [MainThread]: Using profiles dir at C:\Users\Korisnik\.dbt
[0m13:57:20.387928 [info ] [MainThread]: Using profiles.yml file at C:\Users\Korisnik\.dbt\profiles.yml
[0m13:57:20.388480 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\dbt_project.yml
[0m13:57:20.390485 [info ] [MainThread]: adapter type: postgres
[0m13:57:20.391142 [info ] [MainThread]: adapter version: 1.9.1
[0m13:57:20.526169 [info ] [MainThread]: Configuration:
[0m13:57:20.527030 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:57:20.527678 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:57:20.528215 [info ] [MainThread]: Required dependencies:
[0m13:57:20.528831 [debug] [MainThread]: Executing "git --help"
[0m13:57:21.285089 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:57:21.285940 [debug] [MainThread]: STDERR: "b''"
[0m13:57:21.286649 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:57:21.287509 [info ] [MainThread]: Connection:
[0m13:57:21.288160 [info ] [MainThread]:   host: localhost
[0m13:57:21.289052 [info ] [MainThread]:   port: 5433
[0m13:57:21.289582 [info ] [MainThread]:   user: postgres
[0m13:57:21.290293 [info ] [MainThread]:   database: delivery_analytics
[0m13:57:21.290867 [info ] [MainThread]:   schema: analytics
[0m13:57:21.291478 [info ] [MainThread]:   connect_timeout: 10
[0m13:57:21.292082 [info ] [MainThread]:   role: None
[0m13:57:21.292634 [info ] [MainThread]:   search_path: None
[0m13:57:21.293177 [info ] [MainThread]:   keepalives_idle: 0
[0m13:57:21.293725 [info ] [MainThread]:   sslmode: None
[0m13:57:21.294257 [info ] [MainThread]:   sslcert: None
[0m13:57:21.294888 [info ] [MainThread]:   sslkey: None
[0m13:57:21.295435 [info ] [MainThread]:   sslrootcert: None
[0m13:57:21.295925 [info ] [MainThread]:   application_name: dbt
[0m13:57:21.296612 [info ] [MainThread]:   retries: 1
[0m13:57:21.297703 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:57:21.904178 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m13:57:22.097544 [debug] [MainThread]: Using postgres connection "debug"
[0m13:57:22.098152 [debug] [MainThread]: On debug: select 1 as id
[0m13:57:22.098640 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:57:22.211902 [debug] [MainThread]: SQL status: SELECT 1 in 0.113 seconds
[0m13:57:22.213001 [debug] [MainThread]: On debug: Close
[0m13:57:22.213468 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:57:22.214196 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:57:22.215877 [debug] [MainThread]: Command `dbt debug` succeeded at 13:57:22.215687 after 2.19 seconds
[0m13:57:22.216323 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:57:22.216799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDFC32B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDFD096D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013BDFA97CE0>]}
[0m13:57:22.217201 [debug] [MainThread]: Flushing usage events
[0m13:57:23.267990 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:57:28.672770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CB890980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC33CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC987D90>]}


============================== 13:57:28.679211 | 058f2b60-19b5-41da-90bc-1f25f9c87593 ==============================
[0m13:57:28.679211 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:57:28.680257 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt ls --resource-type source', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:57:28.960676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CBCF8770>]}
[0m13:57:29.039757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC82EF10>]}
[0m13:57:29.041232 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:57:29.575926 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:57:29.577064 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:57:29.577667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CDE09850>]}
[0m13:57:31.059273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC9E3D40>]}
[0m13:57:31.138140 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:57:31.163498 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:57:31.203161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CDF38E50>]}
[0m13:57:31.203679 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:57:31.204341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '058f2b60-19b5-41da-90bc-1f25f9c87593', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CDE91230>]}
[0m13:57:31.205643 [info ] [MainThread]: source:dbt_delivery_analytics.raw.courier_assignments
[0m13:57:31.206249 [info ] [MainThread]: source:dbt_delivery_analytics.raw.couriers
[0m13:57:31.206780 [info ] [MainThread]: source:dbt_delivery_analytics.raw.shipment_status
[0m13:57:31.207335 [info ] [MainThread]: source:dbt_delivery_analytics.raw.shipments
[0m13:57:31.207965 [info ] [MainThread]: source:dbt_delivery_analytics.raw.users
[0m13:57:31.209301 [debug] [MainThread]: Command `dbt ls` succeeded at 13:57:31.209178 after 2.72 seconds
[0m13:57:31.209683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CC753590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CE4628E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9CE462990>]}
[0m13:57:31.210031 [debug] [MainThread]: Flushing usage events
[0m13:57:32.283618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:58:18.188041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C965688980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96612CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96677BD90>]}


============================== 13:58:18.192993 | a785f218-1083-4e43-92cc-02925959720b ==============================
[0m13:58:18.192993 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:58:18.193995 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:58:18.526805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C965AE8770>]}
[0m13:58:18.610808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96661EE00>]}
[0m13:58:18.612517 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:58:19.061958 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:58:19.268221 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:58:19.268954 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:58:19.338857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9680A4150>]}
[0m13:58:19.449986 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:19.455687 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:19.500629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C96660FD40>]}
[0m13:58:19.501449 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:58:19.502147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C966C77310>]}
[0m13:58:19.505503 [info ] [MainThread]: 
[0m13:58:19.506328 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:58:19.506986 [info ] [MainThread]: 
[0m13:58:19.507980 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:58:19.514989 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m13:58:19.706212 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m13:58:19.706814 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:58:19.707240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:19.868681 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.161 seconds
[0m13:58:19.870961 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m13:58:19.872409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_delivery_analytics, now create_delivery_analytics_analytics)
[0m13:58:19.873242 [debug] [ThreadPool]: Creating schema "database: "delivery_analytics"
schema: "analytics"
"
[0m13:58:19.880923 [debug] [ThreadPool]: Using postgres connection "create_delivery_analytics_analytics"
[0m13:58:19.881497 [debug] [ThreadPool]: On create_delivery_analytics_analytics: BEGIN
[0m13:58:19.881851 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:58:19.977932 [debug] [ThreadPool]: SQL status: BEGIN in 0.096 seconds
[0m13:58:19.978617 [debug] [ThreadPool]: Using postgres connection "create_delivery_analytics_analytics"
[0m13:58:19.979093 [debug] [ThreadPool]: On create_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "create_delivery_analytics_analytics"} */
create schema if not exists "analytics"
[0m13:58:19.980799 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m13:58:19.982415 [debug] [ThreadPool]: On create_delivery_analytics_analytics: COMMIT
[0m13:58:19.982956 [debug] [ThreadPool]: Using postgres connection "create_delivery_analytics_analytics"
[0m13:58:19.983443 [debug] [ThreadPool]: On create_delivery_analytics_analytics: COMMIT
[0m13:58:19.985185 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m13:58:19.985636 [debug] [ThreadPool]: On create_delivery_analytics_analytics: Close
[0m13:58:19.989765 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m13:58:19.999439 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:20.000227 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m13:58:20.000785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:20.086487 [debug] [ThreadPool]: SQL status: BEGIN in 0.086 seconds
[0m13:58:20.087327 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:20.087884 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:58:20.101234 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.013 seconds
[0m13:58:20.103145 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m13:58:20.104569 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m13:58:20.113412 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.114081 [debug] [MainThread]: On master: BEGIN
[0m13:58:20.114577 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:58:20.190380 [debug] [MainThread]: SQL status: BEGIN in 0.076 seconds
[0m13:58:20.191037 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.191642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m13:58:20.203827 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m13:58:20.205955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9684C8600>]}
[0m13:58:20.206617 [debug] [MainThread]: On master: ROLLBACK
[0m13:58:20.207416 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.207844 [debug] [MainThread]: On master: BEGIN
[0m13:58:20.208677 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:58:20.209077 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.209420 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.209744 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.210260 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:20.210570 [debug] [MainThread]: On master: Close
[0m13:58:20.217908 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.218644 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.219227 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.219755 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.220489 [info ] [Thread-2 (]: 2 of 8 START sql view model analytics.stg_couriers ............................. [RUN]
[0m13:58:20.221159 [info ] [Thread-1 (]: 1 of 8 START sql view model analytics.stg_courier_assigments ................... [RUN]
[0m13:58:20.223394 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_couriers'
[0m13:58:20.221971 [info ] [Thread-3 (]: 3 of 8 START sql view model analytics.stg_shipment_status ...................... [RUN]
[0m13:58:20.224342 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_courier_assigments'
[0m13:58:20.222723 [info ] [Thread-4 (]: 4 of 8 START sql view model analytics.stg_shipments ............................ [RUN]
[0m13:58:20.225009 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.225778 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipment_status'
[0m13:58:20.226494 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.227110 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipments'
[0m13:58:20.234478 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.235142 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.238652 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.239242 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.242517 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.245746 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.251972 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.252504 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.253308 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.288065 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.307292 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.310490 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.314519 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.317659 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.325295 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.326099 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.326747 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: BEGIN
[0m13:58:20.327332 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: BEGIN
[0m13:58:20.327927 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.328414 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.328988 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:58:20.329472 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:58:20.330002 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: BEGIN
[0m13:58:20.330564 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: BEGIN
[0m13:58:20.331498 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:58:20.332002 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:58:20.409807 [debug] [Thread-2 (]: SQL status: BEGIN in 0.080 seconds
[0m13:58:20.410637 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:20.411228 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */

  create view "delivery_analytics"."analytics"."stg_couriers__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."couriers"
)

select
    courier_id,
    user_id,
    vehicle_type,
    city
from source;
  );
[0m13:58:20.414126 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 17: from source;
                    ^

[0m13:58:20.414837 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: ROLLBACK
[0m13:58:20.415799 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: Close
[0m13:58:20.431106 [debug] [Thread-2 (]: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:20.431881 [debug] [Thread-1 (]: SQL status: BEGIN in 0.103 seconds
[0m13:58:20.433834 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:20.434546 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */

  create view "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    assignment_id,
    courier_id,
    shipment_id,
    assigned_at,
    delivered_at
from source;
  );
[0m13:58:20.435924 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:20.436630 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C968116A50>]}
[0m13:58:20.437214 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: ROLLBACK
[0m13:58:20.438179 [error] [Thread-2 (]: 2 of 8 ERROR creating sql view model analytics.stg_couriers .................... [[31mERROR[0m in 0.21s]
[0m13:58:20.439230 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:20.439851 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: Close
[0m13:58:20.440481 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_users
[0m13:58:20.441179 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_couriers' to be skipped because of status 'error'.  Reason: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql.
[0m13:58:20.441957 [info ] [Thread-2 (]: 5 of 8 START sql view model analytics.stg_users ................................ [RUN]
[0m13:58:20.444761 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.stg_couriers, now model.dbt_delivery_analytics.stg_users)
[0m13:58:20.445429 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_users
[0m13:58:20.449511 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.451287 [debug] [Thread-3 (]: SQL status: BEGIN in 0.120 seconds
[0m13:58:20.451832 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:20.452833 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */

  create view "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipment_status"
)

select
    shipment_status_id,
    shipment_id,
    status,
    status_timestamp,
    courier_id
from source;
  );
[0m13:58:20.456767 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:20.457559 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_users
[0m13:58:20.458651 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: ROLLBACK
[0m13:58:20.459886 [debug] [Thread-1 (]: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:20.471291 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.472394 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9681322B0>]}
[0m13:58:20.472979 [debug] [Thread-4 (]: SQL status: BEGIN in 0.141 seconds
[0m13:58:20.473567 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: Close
[0m13:58:20.474958 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:20.474475 [error] [Thread-1 (]: 1 of 8 ERROR creating sql view model analytics.stg_courier_assigments .......... [[31mERROR[0m in 0.25s]
[0m13:58:20.475906 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */

  create view "delivery_analytics"."analytics"."stg_shipments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipments"
)

select
    shipment_id,
    sender_id,
    receiver_id,
    shipment_date,
    expected_delivery_date,
    price
from source;
  );
[0m13:58:20.477992 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:20.478632 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.479753 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_courier_assigments' to be skipped because of status 'error'.  Reason: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql.
[0m13:58:20.480313 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: from source;
                    ^

[0m13:58:20.480802 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: BEGIN
[0m13:58:20.481594 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: ROLLBACK
[0m13:58:20.482164 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:58:20.483145 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: Close
[0m13:58:20.489565 [debug] [Thread-3 (]: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:20.490730 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9683DA990>]}
[0m13:58:20.491967 [error] [Thread-3 (]: 3 of 8 ERROR creating sql view model analytics.stg_shipment_status ............. [[31mERROR[0m in 0.26s]
[0m13:58:20.493099 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:20.493884 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipment_status' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql.
[0m13:58:20.498758 [debug] [Thread-4 (]: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:20.499648 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9683F5850>]}
[0m13:58:20.500751 [error] [Thread-4 (]: 4 of 8 ERROR creating sql view model analytics.stg_shipments ................... [[31mERROR[0m in 0.27s]
[0m13:58:20.502022 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:20.502726 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipments' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql.
[0m13:58:20.503562 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.dim_dates
[0m13:58:20.504172 [info ] [Thread-1 (]: 6 of 8 SKIP relation analytics.dim_dates ....................................... [[33mSKIP[0m]
[0m13:58:20.504961 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.dim_dates
[0m13:58:20.608113 [debug] [Thread-2 (]: SQL status: BEGIN in 0.126 seconds
[0m13:58:20.608735 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:20.609178 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */

  create view "delivery_analytics"."analytics"."stg_users__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from source;
  );
[0m13:58:20.610022 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:20.610529 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: ROLLBACK
[0m13:58:20.611283 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_users: Close
[0m13:58:20.618241 [debug] [Thread-2 (]: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:20.618905 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a785f218-1083-4e43-92cc-02925959720b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C968526B30>]}
[0m13:58:20.619616 [error] [Thread-2 (]: 5 of 8 ERROR creating sql view model analytics.stg_users ....................... [[31mERROR[0m in 0.17s]
[0m13:58:20.620388 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_users
[0m13:58:20.621050 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_users' to be skipped because of status 'error'.  Reason: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql.
[0m13:58:20.622009 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.dim_users
[0m13:58:20.623078 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.dim_couriers
[0m13:58:20.622515 [info ] [Thread-4 (]: 8 of 8 SKIP relation analytics.dim_users ....................................... [[33mSKIP[0m]
[0m13:58:20.624428 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.dim_users
[0m13:58:20.623812 [info ] [Thread-3 (]: 7 of 8 SKIP relation analytics.dim_couriers .................................... [[33mSKIP[0m]
[0m13:58:20.625340 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.dim_couriers
[0m13:58:20.627099 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.627561 [debug] [MainThread]: On master: BEGIN
[0m13:58:20.627847 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:58:20.735795 [debug] [MainThread]: SQL status: BEGIN in 0.108 seconds
[0m13:58:20.736264 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.736566 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:20.736834 [debug] [MainThread]: On master: COMMIT
[0m13:58:20.737268 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:20.737573 [debug] [MainThread]: On master: Close
[0m13:58:20.738115 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:58:20.738532 [debug] [MainThread]: Connection 'create_delivery_analytics_analytics' was properly closed.
[0m13:58:20.738805 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m13:58:20.739277 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_users' was properly closed.
[0m13:58:20.739674 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_courier_assigments' was properly closed.
[0m13:58:20.740142 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipment_status' was properly closed.
[0m13:58:20.740505 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipments' was properly closed.
[0m13:58:20.741029 [info ] [MainThread]: 
[0m13:58:20.741813 [info ] [MainThread]: Finished running 3 table models, 5 view models in 0 hours 0 minutes and 1.23 seconds (1.23s).
[0m13:58:20.743408 [debug] [MainThread]: Command end result
[0m13:58:20.857690 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:20.862329 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:20.870576 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m13:58:20.871305 [info ] [MainThread]: 
[0m13:58:20.872049 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m13:58:20.872576 [info ] [MainThread]: 
[0m13:58:20.873127 [error] [MainThread]: [31mFailure in model stg_couriers (models\staging\stg_couriers.sql)[0m
[0m13:58:20.873622 [error] [MainThread]:   Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:20.874172 [info ] [MainThread]: 
[0m13:58:20.874737 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:20.875202 [info ] [MainThread]: 
[0m13:58:20.875761 [error] [MainThread]: [31mFailure in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)[0m
[0m13:58:20.876304 [error] [MainThread]:   Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:20.876808 [info ] [MainThread]: 
[0m13:58:20.877449 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:20.877918 [info ] [MainThread]: 
[0m13:58:20.878551 [error] [MainThread]: [31mFailure in model stg_shipment_status (models\staging\stg_shipment_status.sql)[0m
[0m13:58:20.879279 [error] [MainThread]:   Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:20.879817 [info ] [MainThread]: 
[0m13:58:20.880432 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:20.880951 [info ] [MainThread]: 
[0m13:58:20.881600 [error] [MainThread]: [31mFailure in model stg_shipments (models\staging\stg_shipments.sql)[0m
[0m13:58:20.882303 [error] [MainThread]:   Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:20.882897 [info ] [MainThread]: 
[0m13:58:20.883530 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:20.884091 [info ] [MainThread]: 
[0m13:58:20.884709 [error] [MainThread]: [31mFailure in model stg_users (models\staging\stg_users.sql)[0m
[0m13:58:20.885822 [error] [MainThread]:   Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:20.886567 [info ] [MainThread]: 
[0m13:58:20.887334 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:20.888447 [info ] [MainThread]: 
[0m13:58:20.889064 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=3 NO-OP=0 TOTAL=8
[0m13:58:20.892089 [debug] [MainThread]: Command `dbt run` failed at 13:58:20.891765 after 2.90 seconds
[0m13:58:20.892802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9652E4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C965967470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C967CD7D10>]}
[0m13:58:20.893195 [debug] [MainThread]: Flushing usage events
[0m13:58:22.120898 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:58:31.637041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D490FF0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491A9CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4920E7D90>]}


============================== 13:58:31.642708 | f87eca52-3f68-4181-ac3e-923b893f22a7 ==============================
[0m13:58:31.642708 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:58:31.643445 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run --select staging', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:58:31.875676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491458770>]}
[0m13:58:31.943564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491F8AE00>]}
[0m13:58:31.945160 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:58:32.386923 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:58:32.556928 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:58:32.557373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:58:32.614898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493A60150>]}
[0m13:58:32.692542 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:32.696474 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:32.728944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491F7FD40>]}
[0m13:58:32.729575 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:58:32.730074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D492277310>]}
[0m13:58:32.732210 [info ] [MainThread]: 
[0m13:58:32.732790 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:58:32.733325 [info ] [MainThread]: 
[0m13:58:32.733979 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:58:32.738210 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m13:58:32.885732 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m13:58:32.886198 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:58:32.886497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:32.992348 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.106 seconds
[0m13:58:32.993839 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m13:58:32.996661 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m13:58:33.002950 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:33.003431 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m13:58:33.003703 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:58:33.071623 [debug] [ThreadPool]: SQL status: BEGIN in 0.068 seconds
[0m13:58:33.072152 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:58:33.072518 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:58:33.082056 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.009 seconds
[0m13:58:33.083385 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m13:58:33.083885 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m13:58:33.089943 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.090436 [debug] [MainThread]: On master: BEGIN
[0m13:58:33.090798 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:58:33.178999 [debug] [MainThread]: SQL status: BEGIN in 0.088 seconds
[0m13:58:33.179599 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.180210 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m13:58:33.189700 [debug] [MainThread]: SQL status: SELECT 0 in 0.009 seconds
[0m13:58:33.191613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493C7BBA0>]}
[0m13:58:33.192328 [debug] [MainThread]: On master: ROLLBACK
[0m13:58:33.193066 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.193520 [debug] [MainThread]: On master: BEGIN
[0m13:58:33.194343 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:58:33.194778 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.195191 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.195579 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.196155 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:33.196605 [debug] [MainThread]: On master: Close
[0m13:58:33.202937 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.203534 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.207380 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.208763 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.209607 [info ] [Thread-1 (]: 1 of 5 START sql view model analytics.stg_courier_assigments ................... [RUN]
[0m13:58:33.210126 [info ] [Thread-4 (]: 4 of 5 START sql view model analytics.stg_shipments ............................ [RUN]
[0m13:58:33.212659 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipments'
[0m13:58:33.213125 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.212000 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_courier_assigments'
[0m13:58:33.225352 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.210709 [info ] [Thread-2 (]: 2 of 5 START sql view model analytics.stg_couriers ............................. [RUN]
[0m13:58:33.231153 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.211246 [info ] [Thread-3 (]: 3 of 5 START sql view model analytics.stg_shipment_status ...................... [RUN]
[0m13:58:33.232455 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_couriers'
[0m13:58:33.236730 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.237586 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipment_status'
[0m13:58:33.238094 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.238739 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.239220 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.242524 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.244883 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.280397 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.286137 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.289881 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.291024 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.294387 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.295653 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.296132 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.296555 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.297005 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: BEGIN
[0m13:58:33.300223 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.300659 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: BEGIN
[0m13:58:33.301071 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.301464 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:58:33.302150 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:58:33.302625 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: BEGIN
[0m13:58:33.303500 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:58:33.304102 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.304656 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: BEGIN
[0m13:58:33.305254 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:58:33.371500 [debug] [Thread-4 (]: SQL status: BEGIN in 0.070 seconds
[0m13:58:33.372016 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:58:33.372600 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */

  create view "delivery_analytics"."analytics"."stg_shipments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipments"
)

select
    shipment_id,
    sender_id,
    receiver_id,
    shipment_date,
    expected_delivery_date,
    price
from source;
  );
[0m13:58:33.373710 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 19: from source;
                    ^

[0m13:58:33.374358 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: ROLLBACK
[0m13:58:33.375262 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: Close
[0m13:58:33.385533 [debug] [Thread-4 (]: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:33.388200 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493ADB410>]}
[0m13:58:33.388965 [error] [Thread-4 (]: 4 of 5 ERROR creating sql view model analytics.stg_shipments ................... [[31mERROR[0m in 0.17s]
[0m13:58:33.390013 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_shipments
[0m13:58:33.390450 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_users
[0m13:58:33.391081 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipments' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql.
[0m13:58:33.391754 [info ] [Thread-4 (]: 5 of 5 START sql view model analytics.stg_users ................................ [RUN]
[0m13:58:33.393593 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.stg_shipments, now model.dbt_delivery_analytics.stg_users)
[0m13:58:33.394282 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_users
[0m13:58:33.398075 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.399939 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_users
[0m13:58:33.404065 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.405361 [debug] [Thread-1 (]: SQL status: BEGIN in 0.103 seconds
[0m13:58:33.405974 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.406611 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:58:33.407110 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: BEGIN
[0m13:58:33.407632 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */

  create view "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    assignment_id,
    courier_id,
    shipment_id,
    assigned_at,
    delivered_at
from source;
  );
[0m13:58:33.408143 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:58:33.409403 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:33.409844 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: ROLLBACK
[0m13:58:33.410602 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: Close
[0m13:58:33.421022 [debug] [Thread-1 (]: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:33.422010 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493AF9B20>]}
[0m13:58:33.422809 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model analytics.stg_courier_assigments .......... [[31mERROR[0m in 0.21s]
[0m13:58:33.424002 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:58:33.424714 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_courier_assigments' to be skipped because of status 'error'.  Reason: Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql.
[0m13:58:33.427621 [debug] [Thread-2 (]: SQL status: BEGIN in 0.124 seconds
[0m13:58:33.428133 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:58:33.428495 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */

  create view "delivery_analytics"."analytics"."stg_couriers__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."couriers"
)

select
    courier_id,
    user_id,
    vehicle_type,
    city
from source;
  );
[0m13:58:33.429484 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 17: from source;
                    ^

[0m13:58:33.430022 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: ROLLBACK
[0m13:58:33.430861 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: Close
[0m13:58:33.437815 [debug] [Thread-2 (]: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:33.438429 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4913D4C30>]}
[0m13:58:33.439061 [error] [Thread-2 (]: 2 of 5 ERROR creating sql view model analytics.stg_couriers .................... [[31mERROR[0m in 0.21s]
[0m13:58:33.440002 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_couriers
[0m13:58:33.440672 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_couriers' to be skipped because of status 'error'.  Reason: Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql.
[0m13:58:33.444255 [debug] [Thread-3 (]: SQL status: BEGIN in 0.139 seconds
[0m13:58:33.444732 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:58:33.445087 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */

  create view "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipment_status"
)

select
    shipment_status_id,
    shipment_id,
    status,
    status_timestamp,
    courier_id
from source;
  );
[0m13:58:33.445914 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:33.446363 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: ROLLBACK
[0m13:58:33.447152 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: Close
[0m13:58:33.453772 [debug] [Thread-3 (]: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:33.454426 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D48EFA4450>]}
[0m13:58:33.455144 [error] [Thread-3 (]: 3 of 5 ERROR creating sql view model analytics.stg_shipment_status ............. [[31mERROR[0m in 0.22s]
[0m13:58:33.455950 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:58:33.456654 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_shipment_status' to be skipped because of status 'error'.  Reason: Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql.
[0m13:58:33.483896 [debug] [Thread-4 (]: SQL status: BEGIN in 0.076 seconds
[0m13:58:33.484429 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:58:33.484772 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */

  create view "delivery_analytics"."analytics"."stg_users__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from source;
  );
[0m13:58:33.485670 [debug] [Thread-4 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 18: from source;
                    ^

[0m13:58:33.486112 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: ROLLBACK
[0m13:58:33.486799 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: Close
[0m13:58:33.492128 [debug] [Thread-4 (]: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:33.492718 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f87eca52-3f68-4181-ac3e-923b893f22a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D493F5FD90>]}
[0m13:58:33.493329 [error] [Thread-4 (]: 5 of 5 ERROR creating sql view model analytics.stg_users ....................... [[31mERROR[0m in 0.10s]
[0m13:58:33.494224 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_users
[0m13:58:33.494836 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.stg_users' to be skipped because of status 'error'.  Reason: Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql.
[0m13:58:33.496650 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.497204 [debug] [MainThread]: On master: BEGIN
[0m13:58:33.497543 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:58:33.563632 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m13:58:33.564116 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.564419 [debug] [MainThread]: Using postgres connection "master"
[0m13:58:33.564700 [debug] [MainThread]: On master: COMMIT
[0m13:58:33.565133 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:58:33.565432 [debug] [MainThread]: On master: Close
[0m13:58:33.565930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:58:33.566195 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m13:58:33.566449 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m13:58:33.566691 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_courier_assigments' was properly closed.
[0m13:58:33.566974 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_users' was properly closed.
[0m13:58:33.567215 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_couriers' was properly closed.
[0m13:58:33.567457 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipment_status' was properly closed.
[0m13:58:33.567857 [info ] [MainThread]: 
[0m13:58:33.568439 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.83 seconds (0.83s).
[0m13:58:33.570254 [debug] [MainThread]: Command end result
[0m13:58:33.664708 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:58:33.668318 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:58:33.675246 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m13:58:33.675670 [info ] [MainThread]: 
[0m13:58:33.676272 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m13:58:33.676813 [info ] [MainThread]: 
[0m13:58:33.677429 [error] [MainThread]: [31mFailure in model stg_shipments (models\staging\stg_shipments.sql)[0m
[0m13:58:33.678038 [error] [MainThread]:   Database Error in model stg_shipments (models\staging\stg_shipments.sql)
  syntax error at or near ";"
  LINE 19: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:33.678636 [info ] [MainThread]: 
[0m13:58:33.679202 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipments.sql
[0m13:58:33.679779 [info ] [MainThread]: 
[0m13:58:33.680327 [error] [MainThread]: [31mFailure in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)[0m
[0m13:58:33.680942 [error] [MainThread]:   Database Error in model stg_courier_assigments (models\staging\stg_courier_assigments.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:33.681516 [info ] [MainThread]: 
[0m13:58:33.682123 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_courier_assigments.sql
[0m13:58:33.682614 [info ] [MainThread]: 
[0m13:58:33.683228 [error] [MainThread]: [31mFailure in model stg_couriers (models\staging\stg_couriers.sql)[0m
[0m13:58:33.683949 [error] [MainThread]:   Database Error in model stg_couriers (models\staging\stg_couriers.sql)
  syntax error at or near ";"
  LINE 17: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:33.684472 [info ] [MainThread]: 
[0m13:58:33.685094 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_couriers.sql
[0m13:58:33.685673 [info ] [MainThread]: 
[0m13:58:33.686371 [error] [MainThread]: [31mFailure in model stg_shipment_status (models\staging\stg_shipment_status.sql)[0m
[0m13:58:33.687132 [error] [MainThread]:   Database Error in model stg_shipment_status (models\staging\stg_shipment_status.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:33.687841 [info ] [MainThread]: 
[0m13:58:33.688382 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_shipment_status.sql
[0m13:58:33.688857 [info ] [MainThread]: 
[0m13:58:33.689445 [error] [MainThread]: [31mFailure in model stg_users (models\staging\stg_users.sql)[0m
[0m13:58:33.690027 [error] [MainThread]:   Database Error in model stg_users (models\staging\stg_users.sql)
  syntax error at or near ";"
  LINE 18: from source;
                      ^
  compiled code at target\run\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:33.690478 [info ] [MainThread]: 
[0m13:58:33.690996 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\staging\stg_users.sql
[0m13:58:33.691488 [info ] [MainThread]: 
[0m13:58:33.692067 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 NO-OP=0 TOTAL=5
[0m13:58:33.693732 [debug] [MainThread]: Command `dbt run` failed at 13:58:33.693588 after 2.22 seconds
[0m13:58:33.694145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491A95FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D491333AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4936F08F0>]}
[0m13:58:33.694516 [debug] [MainThread]: Flushing usage events
[0m13:58:34.721407 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:59:34.512828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD268D4980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD2737CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD279CBD90>]}


============================== 13:59:34.518025 | e216441e-60d6-468b-88cc-51556d6cf323 ==============================
[0m13:59:34.518025 [info ] [MainThread]: Running with dbt=1.10.15
[0m13:59:34.519017 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select staging', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m13:59:34.775508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD26D38770>]}
[0m13:59:34.843360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD2786EE00>]}
[0m13:59:34.845399 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m13:59:35.284785 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m13:59:35.434338 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m13:59:35.435306 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_shipments.sql
[0m13:59:35.435732 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_couriers.sql
[0m13:59:35.436103 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_shipment_status.sql
[0m13:59:35.436460 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_users.sql
[0m13:59:35.436816 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\staging\stg_courier_assigments.sql
[0m13:59:35.737085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD28E59850>]}
[0m13:59:35.819247 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:59:35.823534 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:59:35.865021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD2785FD40>]}
[0m13:59:35.865975 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m13:59:35.866683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD29475EF0>]}
[0m13:59:35.869126 [info ] [MainThread]: 
[0m13:59:35.869746 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:59:35.870249 [info ] [MainThread]: 
[0m13:59:35.871015 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:59:35.876165 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m13:59:36.099825 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m13:59:36.100249 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:59:36.100541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:36.223725 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.123 seconds
[0m13:59:36.225263 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m13:59:36.228101 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m13:59:36.234081 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:59:36.234490 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m13:59:36.234779 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:36.305804 [debug] [ThreadPool]: SQL status: BEGIN in 0.071 seconds
[0m13:59:36.306325 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m13:59:36.306706 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:59:36.315587 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m13:59:36.316848 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m13:59:36.317329 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m13:59:36.322984 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.323578 [debug] [MainThread]: On master: BEGIN
[0m13:59:36.323870 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:59:36.398967 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m13:59:36.399508 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.399956 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m13:59:36.409154 [debug] [MainThread]: SQL status: SELECT 0 in 0.009 seconds
[0m13:59:36.410559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD294EADD0>]}
[0m13:59:36.411115 [debug] [MainThread]: On master: ROLLBACK
[0m13:59:36.411685 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.412058 [debug] [MainThread]: On master: BEGIN
[0m13:59:36.412769 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:59:36.413150 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.413495 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.413816 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.414298 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:59:36.414596 [debug] [MainThread]: On master: Close
[0m13:59:36.420046 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.420611 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.420997 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.421361 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.422127 [info ] [Thread-4 (]: 4 of 5 START sql view model analytics.stg_shipments ............................ [RUN]
[0m13:59:36.422836 [info ] [Thread-2 (]: 2 of 5 START sql view model analytics.stg_couriers ............................. [RUN]
[0m13:59:36.425111 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipments'
[0m13:59:36.423623 [info ] [Thread-1 (]: 1 of 5 START sql view model analytics.stg_courier_assigments ................... [RUN]
[0m13:59:36.425963 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_couriers'
[0m13:59:36.426592 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.424257 [info ] [Thread-3 (]: 3 of 5 START sql view model analytics.stg_shipment_status ...................... [RUN]
[0m13:59:36.427456 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_courier_assigments'
[0m13:59:36.427955 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.434847 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.435525 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.stg_shipment_status'
[0m13:59:36.436047 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.439359 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.440199 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.443373 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.446145 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.447208 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.485351 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.486503 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.490208 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.491025 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.494612 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.495243 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.495773 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.496331 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: BEGIN
[0m13:59:36.499618 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.500118 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:59:36.501043 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.501635 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.502183 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: BEGIN
[0m13:59:36.502757 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: BEGIN
[0m13:59:36.503143 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:59:36.503661 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:59:36.504303 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.505242 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: BEGIN
[0m13:59:36.505819 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:59:36.568610 [debug] [Thread-4 (]: SQL status: BEGIN in 0.068 seconds
[0m13:59:36.569341 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.569921 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */

  create view "delivery_analytics"."analytics"."stg_shipments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipments"
)

select
    shipment_id,
    sender_id,
    receiver_id,
    shipment_date,
    expected_delivery_date,
    price
from source
  );
[0m13:59:36.580395 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m13:59:36.586709 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.587276 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */
alter table "delivery_analytics"."analytics"."stg_shipments__dbt_tmp" rename to "stg_shipments"
[0m13:59:36.588037 [debug] [Thread-3 (]: SQL status: BEGIN in 0.085 seconds
[0m13:59:36.588606 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.589227 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */

  create view "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."shipment_status"
)

select
    shipment_status_id,
    shipment_id,
    status,
    status_timestamp,
    courier_id
from source
  );
[0m13:59:36.591325 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m13:59:36.605525 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: COMMIT
[0m13:59:36.606054 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.016 seconds
[0m13:59:36.606496 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.609958 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.610486 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: COMMIT
[0m13:59:36.611062 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */
alter table "delivery_analytics"."analytics"."stg_shipment_status__dbt_tmp" rename to "stg_shipment_status"
[0m13:59:36.611832 [debug] [Thread-2 (]: SQL status: BEGIN in 0.108 seconds
[0m13:59:36.612271 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:59:36.612707 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.613083 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m13:59:36.614491 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: COMMIT
[0m13:59:36.614963 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */

  create view "delivery_analytics"."analytics"."stg_couriers__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."couriers"
)

select
    courier_id,
    user_id,
    vehicle_type,
    city
from source
  );
[0m13:59:36.620979 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_shipments__dbt_backup"
[0m13:59:36.621491 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.626636 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipments"
[0m13:59:36.627131 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: COMMIT
[0m13:59:36.627640 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipments"} */
drop view if exists "delivery_analytics"."analytics"."stg_shipments__dbt_backup" cascade
[0m13:59:36.628250 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m13:59:36.631479 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.631991 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.003 seconds
[0m13:59:36.632443 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m13:59:36.632867 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */
alter table "delivery_analytics"."analytics"."stg_couriers__dbt_tmp" rename to "stg_couriers"
[0m13:59:36.635217 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_shipments: Close
[0m13:59:36.637266 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_shipment_status__dbt_backup"
[0m13:59:36.638292 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.stg_shipment_status"
[0m13:59:36.638858 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:59:36.639305 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_shipment_status"} */
drop view if exists "delivery_analytics"."analytics"."stg_shipment_status__dbt_backup" cascade
[0m13:59:36.642518 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: COMMIT
[0m13:59:36.643010 [debug] [Thread-1 (]: SQL status: BEGIN in 0.137 seconds
[0m13:59:36.643595 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.644090 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.001 seconds
[0m13:59:36.644516 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.644930 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: COMMIT
[0m13:59:36.646341 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.stg_shipment_status: Close
[0m13:59:36.646797 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */

  create view "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."courier_assignments"
)

select
    assignment_id,
    courier_id,
    shipment_id,
    assigned_at,
    delivered_at
from source
  );
[0m13:59:36.647258 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD298DC350>]}
[0m13:59:36.648206 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD29542D00>]}
[0m13:59:36.649582 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m13:59:36.649081 [info ] [Thread-4 (]: 4 of 5 OK created sql view model analytics.stg_shipments ....................... [[32mCREATE VIEW[0m in 0.22s]
[0m13:59:36.653792 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_couriers__dbt_backup"
[0m13:59:36.650474 [info ] [Thread-3 (]: 3 of 5 OK created sql view model analytics.stg_shipment_status ................. [[32mCREATE VIEW[0m in 0.21s]
[0m13:59:36.654844 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_shipments
[0m13:59:36.655274 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m13:59:36.656075 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.stg_couriers"
[0m13:59:36.656699 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.stg_shipment_status
[0m13:59:36.657198 [debug] [Thread-4 (]: Began running node model.dbt_delivery_analytics.stg_users
[0m13:59:36.660325 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.660801 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_couriers"} */
drop view if exists "delivery_analytics"."analytics"."stg_couriers__dbt_backup" cascade
[0m13:59:36.662112 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */
alter table "delivery_analytics"."analytics"."stg_courier_assigments__dbt_tmp" rename to "stg_courier_assigments"
[0m13:59:36.661700 [info ] [Thread-4 (]: 5 of 5 START sql view model analytics.stg_users ................................ [RUN]
[0m13:59:36.662974 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.dbt_delivery_analytics.stg_shipments, now model.dbt_delivery_analytics.stg_users)
[0m13:59:36.663494 [debug] [Thread-4 (]: Began compiling node model.dbt_delivery_analytics.stg_users
[0m13:59:36.664003 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:59:36.664418 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.002 seconds
[0m13:59:36.667718 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.669451 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: COMMIT
[0m13:59:36.670999 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.stg_couriers: Close
[0m13:59:36.671594 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.672117 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: COMMIT
[0m13:59:36.672651 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD298ECEB0>]}
[0m13:59:36.674211 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m13:59:36.674850 [debug] [Thread-4 (]: Began executing node model.dbt_delivery_analytics.stg_users
[0m13:59:36.673633 [info ] [Thread-2 (]: 2 of 5 OK created sql view model analytics.stg_couriers ........................ [[32mCREATE VIEW[0m in 0.25s]
[0m13:59:36.678087 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_courier_assigments__dbt_backup"
[0m13:59:36.681748 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.682503 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.stg_couriers
[0m13:59:36.683286 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.stg_courier_assigments"
[0m13:59:36.684064 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_courier_assigments"} */
drop view if exists "delivery_analytics"."analytics"."stg_courier_assigments__dbt_backup" cascade
[0m13:59:36.684947 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m13:59:36.686428 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.stg_courier_assigments: Close
[0m13:59:36.686873 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.687387 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: BEGIN
[0m13:59:36.688055 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD294385D0>]}
[0m13:59:36.688590 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:59:36.689443 [info ] [Thread-1 (]: 1 of 5 OK created sql view model analytics.stg_courier_assigments .............. [[32mCREATE VIEW[0m in 0.26s]
[0m13:59:36.690512 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.stg_courier_assigments
[0m13:59:36.761152 [debug] [Thread-4 (]: SQL status: BEGIN in 0.072 seconds
[0m13:59:36.761709 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.762113 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */

  create view "delivery_analytics"."analytics"."stg_users__dbt_tmp"
    
    
  as (
    with source as (
    select *
    from "delivery_analytics"."raw"."users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from source
  );
[0m13:59:36.768100 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m13:59:36.771127 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.771525 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */
alter table "delivery_analytics"."analytics"."stg_users__dbt_tmp" rename to "stg_users"
[0m13:59:36.772381 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:59:36.773750 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: COMMIT
[0m13:59:36.774116 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.774450 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: COMMIT
[0m13:59:36.775806 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m13:59:36.778343 [debug] [Thread-4 (]: Applying DROP to: "delivery_analytics"."analytics"."stg_users__dbt_backup"
[0m13:59:36.778975 [debug] [Thread-4 (]: Using postgres connection "model.dbt_delivery_analytics.stg_users"
[0m13:59:36.779312 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.stg_users"} */
drop view if exists "delivery_analytics"."analytics"."stg_users__dbt_backup" cascade
[0m13:59:36.779931 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.000 seconds
[0m13:59:36.781400 [debug] [Thread-4 (]: On model.dbt_delivery_analytics.stg_users: Close
[0m13:59:36.782136 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e216441e-60d6-468b-88cc-51556d6cf323', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD298F6120>]}
[0m13:59:36.782732 [info ] [Thread-4 (]: 5 of 5 OK created sql view model analytics.stg_users ........................... [[32mCREATE VIEW[0m in 0.12s]
[0m13:59:36.783529 [debug] [Thread-4 (]: Finished running node model.dbt_delivery_analytics.stg_users
[0m13:59:36.785245 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.785603 [debug] [MainThread]: On master: BEGIN
[0m13:59:36.785916 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:59:36.857565 [debug] [MainThread]: SQL status: BEGIN in 0.072 seconds
[0m13:59:36.858101 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.858524 [debug] [MainThread]: Using postgres connection "master"
[0m13:59:36.858818 [debug] [MainThread]: On master: COMMIT
[0m13:59:36.859256 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:59:36.859575 [debug] [MainThread]: On master: Close
[0m13:59:36.860066 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:59:36.860376 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m13:59:36.860736 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m13:59:36.861090 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_users' was properly closed.
[0m13:59:36.861425 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_couriers' was properly closed.
[0m13:59:36.861785 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_courier_assigments' was properly closed.
[0m13:59:36.862151 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.stg_shipment_status' was properly closed.
[0m13:59:36.862666 [info ] [MainThread]: 
[0m13:59:36.863280 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m13:59:36.865137 [debug] [MainThread]: Command end result
[0m13:59:36.901986 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m13:59:36.906009 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m13:59:36.913925 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m13:59:36.914326 [info ] [MainThread]: 
[0m13:59:36.914892 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:59:36.915370 [info ] [MainThread]: 
[0m13:59:36.915894 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m13:59:36.917244 [debug] [MainThread]: Command `dbt run` succeeded at 13:59:36.917126 after 2.61 seconds
[0m13:59:36.917604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD26CCEB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD28FCB590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CD28FC9BB0>]}
[0m13:59:36.917971 [debug] [MainThread]: Flushing usage events
[0m13:59:38.083843 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:14:09.307235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023591C60980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002359271CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592D57D90>]}


============================== 14:14:09.313804 | c2798855-b4cc-4265-9773-0ff7141fbe74 ==============================
[0m14:14:09.313804 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:14:09.314779 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.core', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:14:09.614750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235920C8770>]}
[0m14:14:09.697181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592BFEE00>]}
[0m14:14:09.699030 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:14:10.312062 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:14:10.515198 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m14:14:10.516146 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\core\dim_dates.sql
[0m14:14:10.516708 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\core\dim_couriers.sql
[0m14:14:10.517203 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\core\dim_users.sql
[0m14:14:10.867816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235946D1650>]}
[0m14:14:10.965364 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:14:10.969719 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:14:11.011366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592BEFD40>]}
[0m14:14:11.012039 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:14:11.012703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594816270>]}
[0m14:14:11.014859 [info ] [MainThread]: 
[0m14:14:11.015509 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:14:11.016165 [info ] [MainThread]: 
[0m14:14:11.017223 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:14:11.021750 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:14:11.259468 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:14:11.259920 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:14:11.260304 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:14:11.378067 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.118 seconds
[0m14:14:11.379427 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:14:11.382501 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:14:11.391921 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:14:11.392693 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:14:11.393082 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:14:11.453570 [debug] [ThreadPool]: SQL status: BEGIN in 0.060 seconds
[0m14:14:11.454023 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:14:11.454330 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:14:11.461917 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.007 seconds
[0m14:14:11.463362 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:14:11.463938 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:14:11.470888 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.471356 [debug] [MainThread]: On master: BEGIN
[0m14:14:11.471628 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:14:11.532114 [debug] [MainThread]: SQL status: BEGIN in 0.060 seconds
[0m14:14:11.532566 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.532930 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:14:11.540167 [debug] [MainThread]: SQL status: SELECT 5 in 0.007 seconds
[0m14:14:11.541492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594886EA0>]}
[0m14:14:11.541952 [debug] [MainThread]: On master: ROLLBACK
[0m14:14:11.542637 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.542950 [debug] [MainThread]: On master: BEGIN
[0m14:14:11.543689 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:14:11.544001 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.544284 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.544627 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.545104 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:14:11.545405 [debug] [MainThread]: On master: Close
[0m14:14:11.550961 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.551427 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.dim_users
[0m14:14:11.551849 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.552374 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.dim_couriers ............................ [RUN]
[0m14:14:11.554050 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.dim_couriers'
[0m14:14:11.552884 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.dim_users ............................... [RUN]
[0m14:14:11.554612 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.555246 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.dim_users'
[0m14:14:11.553452 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.dim_dates ............................... [RUN]
[0m14:14:11.563832 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.564336 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.dim_users
[0m14:14:11.565000 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.dim_dates'
[0m14:14:11.567766 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.568247 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.570959 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.574338 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.574933 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.dim_users
[0m14:14:11.575393 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.621201 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.626156 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.629543 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.633578 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.634083 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.634450 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.634870 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: BEGIN
[0m14:14:11.635400 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: BEGIN
[0m14:14:11.635875 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: BEGIN
[0m14:14:11.636317 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:14:11.636834 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:14:11.637313 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:14:11.705029 [debug] [Thread-3 (]: SQL status: BEGIN in 0.068 seconds
[0m14:14:11.705664 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.706187 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_users"} */

  
    

  create  table "delivery_analytics"."analytics"."dim_users__dbt_tmp"
  
  
    as
  
  (
    with users as (
    select *
    from "delivery_analytics"."analytics"."stg_users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from users
  );
  
[0m14:14:11.713794 [debug] [Thread-3 (]: SQL status: SELECT 8 in 0.007 seconds
[0m14:14:11.723440 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.723933 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_users"} */
alter table "delivery_analytics"."analytics"."dim_users__dbt_tmp" rename to "dim_users"
[0m14:14:11.724605 [debug] [Thread-1 (]: SQL status: BEGIN in 0.088 seconds
[0m14:14:11.725021 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.725416 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:14:11.725863 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_couriers"} */

  
    

  create  table "delivery_analytics"."analytics"."dim_couriers__dbt_tmp"
  
  
    as
  
  (
    with couriers as (
    select *
    from "delivery_analytics"."analytics"."stg_couriers"
),

users as (
    select user_id, username
    from "delivery_analytics"."analytics"."stg_users"
)

select
    c.courier_id,
    c.user_id,
    u.username,
    c.vehicle_type,
    c.city
from couriers c
left join users u
    on c.user_id = u.user_id
  );
  
[0m14:14:11.740057 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: COMMIT
[0m14:14:11.740794 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.741354 [debug] [Thread-2 (]: SQL status: BEGIN in 0.104 seconds
[0m14:14:11.741771 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: COMMIT
[0m14:14:11.742211 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.742706 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_dates"} */

  
    

  create  table "delivery_analytics"."analytics"."dim_dates__dbt_tmp"
  
  
    as
  
  (
    with users as (
    select *
    from "delivery_analytics"."analytics"."stg_users"
)

select
    user_id,
    username,
    email,
    role,
    created_at
from users
  );
  
[0m14:14:11.743507 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:14:11.749404 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."dim_users__dbt_backup"
[0m14:14:11.749937 [debug] [Thread-2 (]: SQL status: SELECT 8 in 0.007 seconds
[0m14:14:11.750372 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.010 seconds
[0m14:14:11.755249 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.dim_users"
[0m14:14:11.758398 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.761641 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.762140 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_users"} */
drop table if exists "delivery_analytics"."analytics"."dim_users__dbt_backup" cascade
[0m14:14:11.762639 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_dates"} */
alter table "delivery_analytics"."analytics"."dim_dates__dbt_tmp" rename to "dim_dates"
[0m14:14:11.763080 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_couriers"} */
alter table "delivery_analytics"."analytics"."dim_couriers__dbt_tmp" rename to "dim_couriers"
[0m14:14:11.764309 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m14:14:11.764724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:14:11.765100 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m14:14:11.767411 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.dim_users: Close
[0m14:14:11.768712 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: COMMIT
[0m14:14:11.769917 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: COMMIT
[0m14:14:11.770408 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.772016 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.772468 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: COMMIT
[0m14:14:11.772956 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: COMMIT
[0m14:14:11.773662 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594847F50>]}
[0m14:14:11.774780 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:14:11.775179 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m14:14:11.774426 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.dim_users .......................... [[32mSELECT 8[0m in 0.22s]
[0m14:14:11.777834 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."dim_couriers__dbt_backup"
[0m14:14:11.780205 [debug] [Thread-2 (]: Applying DROP to: "delivery_analytics"."analytics"."dim_dates__dbt_backup"
[0m14:14:11.781486 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.dim_users
[0m14:14:11.782373 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.dim_couriers"
[0m14:14:11.783167 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.dim_dates"
[0m14:14:11.783877 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_couriers"} */
drop table if exists "delivery_analytics"."analytics"."dim_couriers__dbt_backup" cascade
[0m14:14:11.784356 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.dim_dates"} */
drop table if exists "delivery_analytics"."analytics"."dim_dates__dbt_backup" cascade
[0m14:14:11.785308 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:14:11.785696 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m14:14:11.787056 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.dim_couriers: Close
[0m14:14:11.788279 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.dim_dates: Close
[0m14:14:11.789024 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235948D7330>]}
[0m14:14:11.789541 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2798855-b4cc-4265-9773-0ff7141fbe74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594315DB0>]}
[0m14:14:11.790189 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.dim_couriers ....................... [[32mSELECT 3[0m in 0.24s]
[0m14:14:11.791740 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.dim_couriers
[0m14:14:11.790768 [info ] [Thread-2 (]: 2 of 3 OK created sql table model analytics.dim_dates .......................... [[32mSELECT 8[0m in 0.22s]
[0m14:14:11.792909 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.dim_dates
[0m14:14:11.794790 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.795245 [debug] [MainThread]: On master: BEGIN
[0m14:14:11.795558 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:14:11.865350 [debug] [MainThread]: SQL status: BEGIN in 0.070 seconds
[0m14:14:11.865804 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.866100 [debug] [MainThread]: Using postgres connection "master"
[0m14:14:11.866400 [debug] [MainThread]: On master: COMMIT
[0m14:14:11.866899 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:14:11.867228 [debug] [MainThread]: On master: Close
[0m14:14:11.867739 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:14:11.868028 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:14:11.868274 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:14:11.868606 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.dim_couriers' was properly closed.
[0m14:14:11.868849 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.dim_users' was properly closed.
[0m14:14:11.869082 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.dim_dates' was properly closed.
[0m14:14:11.869455 [info ] [MainThread]: 
[0m14:14:11.870020 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.85 seconds (0.85s).
[0m14:14:11.871470 [debug] [MainThread]: Command end result
[0m14:14:11.897867 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:14:11.901409 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:14:11.908560 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:14:11.908988 [info ] [MainThread]: 
[0m14:14:11.909573 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:14:11.910111 [info ] [MainThread]: 
[0m14:14:11.910677 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m14:14:11.912071 [debug] [MainThread]: Command `dbt run` succeeded at 14:14:11.911955 after 2.83 seconds
[0m14:14:11.912558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002359488CBD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023594BFD150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023592C6FA80>]}
[0m14:14:11.913016 [debug] [MainThread]: Flushing usage events
[0m14:14:12.956616 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:12.889210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99E0F0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99EB9CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F1E7D90>]}


============================== 14:17:12.895295 | 4ec62e9b-f819-443c-9d87-0993581562d3 ==============================
[0m14:17:12.895295 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:17:12.896598 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:17:13.188851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99E558770>]}
[0m14:17:13.271859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F08EE00>]}
[0m14:17:13.273900 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:17:13.769554 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:17:13.933824 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m14:17:13.934670 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\daily_shipments_status.sql
[0m14:17:13.935199 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\fct_shipments.sql
[0m14:17:13.935697 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:17:14.220058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0B05950>]}
[0m14:17:14.299455 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:17:14.303712 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:17:14.341638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F07FD40>]}
[0m14:17:14.342777 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:17:14.343482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0C465F0>]}
[0m14:17:14.345658 [info ] [MainThread]: 
[0m14:17:14.346463 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:17:14.347008 [info ] [MainThread]: 
[0m14:17:14.347735 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:17:14.351828 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:17:14.562179 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:17:14.562607 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:17:14.562928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:14.702454 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.139 seconds
[0m14:17:14.703918 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:17:14.706192 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:17:14.712382 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:17:14.712857 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:17:14.713192 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:14.777134 [debug] [ThreadPool]: SQL status: BEGIN in 0.064 seconds
[0m14:17:14.777594 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:17:14.777909 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:17:14.784271 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m14:17:14.786262 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:17:14.786953 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:17:14.794207 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.794624 [debug] [MainThread]: On master: BEGIN
[0m14:17:14.794919 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:14.853105 [debug] [MainThread]: SQL status: BEGIN in 0.058 seconds
[0m14:17:14.853603 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.853949 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:17:14.860567 [debug] [MainThread]: SQL status: SELECT 5 in 0.006 seconds
[0m14:17:14.862482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0EB2F70>]}
[0m14:17:14.862924 [debug] [MainThread]: On master: ROLLBACK
[0m14:17:14.863482 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.863853 [debug] [MainThread]: On master: BEGIN
[0m14:17:14.864641 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:17:14.864954 [debug] [MainThread]: On master: COMMIT
[0m14:17:14.865239 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:14.865510 [debug] [MainThread]: On master: COMMIT
[0m14:17:14.866000 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:17:14.866321 [debug] [MainThread]: On master: Close
[0m14:17:14.870822 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:17:14.871644 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:17:14.872548 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:17:14.872919 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:17:14.880775 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.883409 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:17:14.923658 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.926318 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.927207 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:17:14.927795 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:17:14.987217 [debug] [Thread-1 (]: SQL status: BEGIN in 0.059 seconds
[0m14:17:14.987779 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:14.988166 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:17:15.105015 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.116 seconds
[0m14:17:15.115845 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:15.116494 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:17:15.117636 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:17:15.131712 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:17:15.132233 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:15.132663 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:17:15.133959 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:17:15.139547 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:17:15.144180 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:17:15.144553 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:17:15.145296 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:17:15.147827 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:17:15.150436 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0A73590>]}
[0m14:17:15.151252 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.28s]
[0m14:17:15.152387 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:17:15.153376 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.154398 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.154006 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:17:15.155808 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:17:15.155168 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:17:15.156458 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.157009 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:17:15.160048 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.160511 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.163087 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.169494 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.173799 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.174690 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.181448 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.183529 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.184250 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:17:15.184780 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:17:15.187244 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.187782 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:17:15.188269 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:17:15.252587 [debug] [Thread-3 (]: SQL status: BEGIN in 0.068 seconds
[0m14:17:15.253150 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.253519 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:17:15.263105 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.009 seconds
[0m14:17:15.266466 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.267063 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:17:15.267719 [debug] [Thread-2 (]: SQL status: BEGIN in 0.079 seconds
[0m14:17:15.268266 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:17:15.268716 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:17:15.269203 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    avg(s.expected_delivery_date - s.shipment_date) as avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:17:15.270604 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:17:15.271245 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.271752 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:17:15.273287 [debug] [Thread-2 (]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                 ^

[0m14:17:15.273838 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:17:15.274426 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:17:15.278144 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:17:15.279020 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:17:15.279998 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:17:15.280550 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:17:15.282702 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:17:15.284347 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:17:15.285293 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0D176A0>]}
[0m14:17:15.286194 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.13s]
[0m14:17:15.287497 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:17:15.296618 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:17:15.297352 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ec62e9b-f819-443c-9d87-0993581562d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0777110>]}
[0m14:17:15.298069 [error] [Thread-2 (]: 2 of 3 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.14s]
[0m14:17:15.298988 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:17:15.299848 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:17:15.302537 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:15.303133 [debug] [MainThread]: On master: BEGIN
[0m14:17:15.303520 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:17:15.369396 [debug] [MainThread]: SQL status: BEGIN in 0.066 seconds
[0m14:17:15.369844 [debug] [MainThread]: On master: COMMIT
[0m14:17:15.370139 [debug] [MainThread]: Using postgres connection "master"
[0m14:17:15.370420 [debug] [MainThread]: On master: COMMIT
[0m14:17:15.370841 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:17:15.371219 [debug] [MainThread]: On master: Close
[0m14:17:15.371718 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:17:15.371989 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:17:15.372235 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:17:15.372539 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m14:17:15.372785 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:17:15.373022 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:17:15.373374 [info ] [MainThread]: 
[0m14:17:15.373918 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m14:17:15.375602 [debug] [MainThread]: Command end result
[0m14:17:15.404005 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:17:15.408154 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:17:15.416903 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:17:15.417392 [info ] [MainThread]: 
[0m14:17:15.418075 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:17:15.418580 [info ] [MainThread]: 
[0m14:17:15.419344 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:17:15.420020 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     avg(s.expected_delivery_date - s.shipment_date) as avg_d...
                   ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:17:15.420577 [info ] [MainThread]: 
[0m14:17:15.421168 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:17:15.421679 [info ] [MainThread]: 
[0m14:17:15.422217 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m14:17:15.423981 [debug] [MainThread]: Command `dbt run` failed at 14:17:15.423830 after 2.84 seconds
[0m14:17:15.424463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0CC09D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A0FBB2D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99F0FFA80>]}
[0m14:17:15.424919 [debug] [MainThread]: Flushing usage events
[0m14:17:16.505531 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:18:41.446939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC4210980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC4CCCB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC530BD90>]}


============================== 14:18:41.452995 | 1962fec5-49a5-4d57-8198-7de58a63d7f8 ==============================
[0m14:18:41.452995 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:18:41.454223 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:18:41.734997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC4678770>]}
[0m14:18:41.817168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC51AEE00>]}
[0m14:18:41.818966 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:18:42.412622 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:18:42.599636 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:18:42.600849 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:18:42.962123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6C79850>]}
[0m14:18:43.051674 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:18:43.056154 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:18:43.097409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC519FD40>]}
[0m14:18:43.098430 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:18:43.099331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E7E5F0>]}
[0m14:18:43.101713 [info ] [MainThread]: 
[0m14:18:43.102455 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:18:43.103164 [info ] [MainThread]: 
[0m14:18:43.104248 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:18:43.111587 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:18:43.379119 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:18:43.379660 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:18:43.380137 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:18:43.534321 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.154 seconds
[0m14:18:43.536143 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:18:43.539529 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:18:43.547534 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:18:43.548077 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:18:43.548444 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:18:43.621391 [debug] [ThreadPool]: SQL status: BEGIN in 0.073 seconds
[0m14:18:43.621950 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:18:43.622373 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:18:43.629895 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m14:18:43.632126 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:18:43.632858 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:18:43.642255 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.642764 [debug] [MainThread]: On master: BEGIN
[0m14:18:43.643125 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:18:43.716593 [debug] [MainThread]: SQL status: BEGIN in 0.073 seconds
[0m14:18:43.717151 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.717623 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:18:43.727649 [debug] [MainThread]: SQL status: SELECT 5 in 0.009 seconds
[0m14:18:43.730364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC7013040>]}
[0m14:18:43.730975 [debug] [MainThread]: On master: ROLLBACK
[0m14:18:43.731760 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.732296 [debug] [MainThread]: On master: BEGIN
[0m14:18:43.733277 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m14:18:43.733692 [debug] [MainThread]: On master: COMMIT
[0m14:18:43.734108 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:43.734466 [debug] [MainThread]: On master: COMMIT
[0m14:18:43.735117 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:18:43.735538 [debug] [MainThread]: On master: Close
[0m14:18:43.742116 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.743198 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:18:43.744193 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:18:43.744685 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.754159 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.756503 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.808203 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.810544 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.811185 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:18:43.811993 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:18:43.887796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.076 seconds
[0m14:18:43.888452 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.888934 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:18:43.899734 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.010 seconds
[0m14:18:43.912996 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.913518 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:18:43.915088 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:43.918899 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.919398 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:18:43.920949 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:43.941487 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:18:43.942035 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.942486 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:18:43.944414 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:18:43.953776 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:18:43.961215 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:18:43.962600 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:18:43.969932 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m14:18:43.973817 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:18:43.976723 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6BD3890>]}
[0m14:18:43.977590 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.23s]
[0m14:18:43.979216 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:18:43.980493 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:18:43.981128 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:43.981857 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:18:43.983463 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:18:43.984008 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:18:43.982600 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:18:43.987726 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:18:43.988593 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:18:43.989523 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:43.994677 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:43.995882 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:18:44.000752 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:18:44.002280 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:44.006367 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.008110 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:18:44.008953 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:18:44.009810 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:18:44.011079 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.011615 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:18:44.012121 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:18:44.093192 [debug] [Thread-2 (]: SQL status: BEGIN in 0.083 seconds
[0m14:18:44.094110 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:18:44.094872 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shipment_date)) / 86400) AS avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:18:44.098050 [debug] [Thread-2 (]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                     ^

[0m14:18:44.098687 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:18:44.099662 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:18:44.114925 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                       ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:18:44.116047 [debug] [Thread-3 (]: SQL status: BEGIN in 0.104 seconds
[0m14:18:44.116973 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E6BD80>]}
[0m14:18:44.117629 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.119463 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:18:44.118744 [error] [Thread-2 (]: 2 of 3 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.13s]
[0m14:18:44.120533 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:18:44.121288 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                       ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:18:44.129853 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.010 seconds
[0m14:18:44.134870 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.135450 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:18:44.136766 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:44.140203 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.140739 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:18:44.142329 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:18:44.144336 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:18:44.144846 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.145287 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:18:44.147198 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m14:18:44.150561 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:18:44.151477 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:18:44.151943 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:18:44.157011 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.005 seconds
[0m14:18:44.159119 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:18:44.159914 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1962fec5-49a5-4d57-8198-7de58a63d7f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC68A02D0>]}
[0m14:18:44.160874 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.17s]
[0m14:18:44.162279 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:18:44.164523 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:44.165017 [debug] [MainThread]: On master: BEGIN
[0m14:18:44.165418 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:18:44.240058 [debug] [MainThread]: SQL status: BEGIN in 0.074 seconds
[0m14:18:44.240739 [debug] [MainThread]: On master: COMMIT
[0m14:18:44.241217 [debug] [MainThread]: Using postgres connection "master"
[0m14:18:44.241603 [debug] [MainThread]: On master: COMMIT
[0m14:18:44.242274 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:18:44.242688 [debug] [MainThread]: On master: Close
[0m14:18:44.243326 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:18:44.243692 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:18:44.244041 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:18:44.244494 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m14:18:44.244838 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:18:44.245183 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:18:44.245653 [info ] [MainThread]: 
[0m14:18:44.246405 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.14 seconds (1.14s).
[0m14:18:44.248064 [debug] [MainThread]: Command end result
[0m14:18:44.279736 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:18:44.284443 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:18:44.293033 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:18:44.293574 [info ] [MainThread]: 
[0m14:18:44.294331 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:18:44.295181 [info ] [MainThread]: 
[0m14:18:44.295917 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:18:44.296705 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  missing FROM-clause entry for table "s"
  LINE 21:     AVG(EXTRACT(EPOCH FROM (s.expected_delivery_date - s.shi...
                                       ^
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:18:44.297390 [info ] [MainThread]: 
[0m14:18:44.298109 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:18:44.298799 [info ] [MainThread]: 
[0m14:18:44.299669 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m14:18:44.301634 [debug] [MainThread]: Command `dbt run` failed at 14:18:44.301479 after 3.09 seconds
[0m14:18:44.302206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E28950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC6E30AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC521FA80>]}
[0m14:18:44.302660 [debug] [MainThread]: Flushing usage events
[0m14:18:45.344282 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:19:19.612296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215443F0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021544E9CB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215454EBD90>]}


============================== 14:19:19.618293 | bc10e861-d968-4a1c-801a-5442778b6c22 ==============================
[0m14:19:19.618293 [info ] [MainThread]: Running with dbt=1.10.15
[0m14:19:19.620032 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\Korisnik\\.dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select marts.analytics', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\Korisnik\\OneDrive\\Desktop\\dbt_delivery_analytics\\logs'}
[0m14:19:19.920560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021544858770>]}
[0m14:19:20.006230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002154538EE00>]}
[0m14:19:20.008020 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m14:19:20.633002 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m14:19:20.832521 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:19:20.833333 [debug] [MainThread]: Partial parsing: updated file: dbt_delivery_analytics://models\marts\analytics\courier_performance.sql
[0m14:19:21.191065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546E31850>]}
[0m14:19:21.284569 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:19:21.289722 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:19:21.332228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002154537FD40>]}
[0m14:19:21.332945 [info ] [MainThread]: Found 11 models, 5 sources, 459 macros
[0m14:19:21.333746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546FA25F0>]}
[0m14:19:21.336740 [info ] [MainThread]: 
[0m14:19:21.337495 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:19:21.338134 [info ] [MainThread]: 
[0m14:19:21.339054 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:19:21.344666 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics'
[0m14:19:21.657382 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics"
[0m14:19:21.657947 [debug] [ThreadPool]: On list_delivery_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics"} */

    select distinct nspname from pg_namespace
  
[0m14:19:21.658401 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:21.797991 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.139 seconds
[0m14:19:21.799567 [debug] [ThreadPool]: On list_delivery_analytics: Close
[0m14:19:21.802100 [debug] [ThreadPool]: Acquiring new postgres connection 'list_delivery_analytics_analytics'
[0m14:19:21.811648 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:19:21.812313 [debug] [ThreadPool]: On list_delivery_analytics_analytics: BEGIN
[0m14:19:21.812762 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:21.882773 [debug] [ThreadPool]: SQL status: BEGIN in 0.070 seconds
[0m14:19:21.883437 [debug] [ThreadPool]: Using postgres connection "list_delivery_analytics_analytics"
[0m14:19:21.883959 [debug] [ThreadPool]: On list_delivery_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "list_delivery_analytics_analytics"} */
select
      'delivery_analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'delivery_analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m14:19:21.891913 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m14:19:21.894206 [debug] [ThreadPool]: On list_delivery_analytics_analytics: ROLLBACK
[0m14:19:21.894929 [debug] [ThreadPool]: On list_delivery_analytics_analytics: Close
[0m14:19:21.904327 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:21.904930 [debug] [MainThread]: On master: BEGIN
[0m14:19:21.905329 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:19:21.996629 [debug] [MainThread]: SQL status: BEGIN in 0.091 seconds
[0m14:19:21.997275 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:21.997845 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m14:19:22.006473 [debug] [MainThread]: SQL status: SELECT 5 in 0.008 seconds
[0m14:19:22.008681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215471D3040>]}
[0m14:19:22.009301 [debug] [MainThread]: On master: ROLLBACK
[0m14:19:22.009879 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.010225 [debug] [MainThread]: On master: BEGIN
[0m14:19:22.010873 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:19:22.011198 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.011496 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.011786 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.012257 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:19:22.012670 [debug] [MainThread]: On master: Close
[0m14:19:22.018531 [debug] [Thread-1 (]: Began running node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.019384 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.fct_shipments ........................... [RUN]
[0m14:19:22.020266 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.fct_shipments'
[0m14:19:22.020897 [debug] [Thread-1 (]: Began compiling node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.032212 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.034475 [debug] [Thread-1 (]: Began executing node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.087502 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.089895 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.090581 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: BEGIN
[0m14:19:22.091181 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:19:22.162508 [debug] [Thread-1 (]: SQL status: BEGIN in 0.071 seconds
[0m14:19:22.163118 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.163595 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */

  
    

  create  table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp"
  
  
    as
  
  (
    with shipments as (
    select *
    from "delivery_analytics"."analytics"."stg_shipments"
),

shipment_status as (
    select *
    from "delivery_analytics"."analytics"."stg_shipment_status"
),

users as (
    select *
    from "delivery_analytics"."analytics"."dim_users"
),

couriers as (
    select *
    from "delivery_analytics"."analytics"."dim_couriers"
)

select
    s.shipment_id,
    s.sender_id,
    su.username as sender_name,
    s.receiver_id,
    ru.username as receiver_name,
    s.shipment_date,
    s.expected_delivery_date,
    ss.status,
    ss.status_timestamp,
    ss.courier_id,
    c.user_id as courier_user_id,
    c.vehicle_type,
    s.price
from shipments s
left join shipment_status ss on s.shipment_id = ss.shipment_id
left join users su on s.sender_id = su.user_id
left join users ru on s.receiver_id = ru.user_id
left join couriers c on ss.courier_id = c.courier_id
  );
  
[0m14:19:22.174832 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.011 seconds
[0m14:19:22.187022 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.187616 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments" rename to "fct_shipments__dbt_backup"
[0m14:19:22.188615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.192067 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.192579 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
alter table "delivery_analytics"."analytics"."fct_shipments__dbt_tmp" rename to "fct_shipments"
[0m14:19:22.193966 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.212073 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:19:22.212523 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.212857 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: COMMIT
[0m14:19:22.214158 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:19:22.220018 [debug] [Thread-1 (]: Applying DROP to: "delivery_analytics"."analytics"."fct_shipments__dbt_backup"
[0m14:19:22.224671 [debug] [Thread-1 (]: Using postgres connection "model.dbt_delivery_analytics.fct_shipments"
[0m14:19:22.225347 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.fct_shipments"} */
drop table if exists "delivery_analytics"."analytics"."fct_shipments__dbt_backup" cascade
[0m14:19:22.229800 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m14:19:22.232268 [debug] [Thread-1 (]: On model.dbt_delivery_analytics.fct_shipments: Close
[0m14:19:22.234876 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546CEB890>]}
[0m14:19:22.235678 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.fct_shipments ...................... [[32mSELECT 10[0m in 0.21s]
[0m14:19:22.237036 [debug] [Thread-1 (]: Finished running node model.dbt_delivery_analytics.fct_shipments
[0m14:19:22.238323 [debug] [Thread-2 (]: Began running node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.238869 [debug] [Thread-3 (]: Began running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.239413 [info ] [Thread-2 (]: 2 of 3 START sql table model analytics.courier_performance ..................... [RUN]
[0m14:19:22.240195 [info ] [Thread-3 (]: 3 of 3 START sql table model analytics.daily_shipments_status .................. [RUN]
[0m14:19:22.241132 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.courier_performance'
[0m14:19:22.241775 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_delivery_analytics.daily_shipments_status'
[0m14:19:22.242408 [debug] [Thread-2 (]: Began compiling node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.242886 [debug] [Thread-3 (]: Began compiling node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.246657 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.250279 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.253721 [debug] [Thread-3 (]: Began executing node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.254576 [debug] [Thread-2 (]: Began executing node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.260139 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.264468 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.267114 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.267723 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: BEGIN
[0m14:19:22.268371 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.268991 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:19:22.269484 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: BEGIN
[0m14:19:22.270220 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:19:22.343675 [debug] [Thread-3 (]: SQL status: BEGIN in 0.075 seconds
[0m14:19:22.344171 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.344556 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */

  
    

  create  table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    shipment_date,
    status,
    count(*) as shipments_count
from fct
group by shipment_date, status
order by shipment_date, status
  );
  
[0m14:19:22.352986 [debug] [Thread-3 (]: SQL status: SELECT 9 in 0.008 seconds
[0m14:19:22.356981 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.357520 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status" rename to "daily_shipments_status__dbt_backup"
[0m14:19:22.358310 [debug] [Thread-2 (]: SQL status: BEGIN in 0.088 seconds
[0m14:19:22.358740 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.359097 [debug] [Thread-2 (]: Using postgres connection "model.dbt_delivery_analytics.courier_performance"
[0m14:19:22.361580 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.362007 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.courier_performance"} */

  
    

  create  table "delivery_analytics"."analytics"."courier_performance__dbt_tmp"
  
  
    as
  
  (
    with fct as (
    select *
    from "delivery_analytics"."analytics"."fct_shipments"
)

select
    courier_id,
    count(distinct shipment_id) as total_shipments,
    sum(case when status = 'delivered' then 1 else 0 end) as delivered_shipments,
    AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipment_date)) / 86400) AS avg_delivery_time
from fct
group by courier_id
  );
  
[0m14:19:22.362412 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
alter table "delivery_analytics"."analytics"."daily_shipments_status__dbt_tmp" rename to "daily_shipments_status"
[0m14:19:22.363434 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:19:22.364899 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:19:22.365264 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.365941 [debug] [Thread-2 (]: Postgres adapter: Postgres error: function pg_catalog.extract(unknown, integer) does not exist
LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                 ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m14:19:22.366489 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: COMMIT
[0m14:19:22.367095 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: ROLLBACK
[0m14:19:22.367854 [debug] [Thread-2 (]: On model.dbt_delivery_analytics.courier_performance: Close
[0m14:19:22.369534 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m14:19:22.372634 [debug] [Thread-3 (]: Applying DROP to: "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup"
[0m14:19:22.373464 [debug] [Thread-3 (]: Using postgres connection "model.dbt_delivery_analytics.daily_shipments_status"
[0m14:19:22.373882 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: /* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "dbt_delivery_analytics", "target_name": "dev", "node_id": "model.dbt_delivery_analytics.daily_shipments_status"} */
drop table if exists "delivery_analytics"."analytics"."daily_shipments_status__dbt_backup" cascade
[0m14:19:22.381463 [debug] [Thread-2 (]: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:19:22.382313 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021547033AC0>]}
[0m14:19:22.383831 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.009 seconds
[0m14:19:22.383397 [error] [Thread-2 (]: 2 of 3 ERROR creating sql table model analytics.courier_performance ............ [[31mERROR[0m in 0.14s]
[0m14:19:22.385463 [debug] [Thread-3 (]: On model.dbt_delivery_analytics.daily_shipments_status: Close
[0m14:19:22.386050 [debug] [Thread-2 (]: Finished running node model.dbt_delivery_analytics.courier_performance
[0m14:19:22.387002 [debug] [Thread-7 (]: Marking all children of 'model.dbt_delivery_analytics.courier_performance' to be skipped because of status 'error'.  Reason: Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql.
[0m14:19:22.387729 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc10e861-d968-4a1c-801a-5442778b6c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546A651D0>]}
[0m14:19:22.389225 [info ] [Thread-3 (]: 3 of 3 OK created sql table model analytics.daily_shipments_status ............. [[32mSELECT 9[0m in 0.15s]
[0m14:19:22.390280 [debug] [Thread-3 (]: Finished running node model.dbt_delivery_analytics.daily_shipments_status
[0m14:19:22.392107 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.392552 [debug] [MainThread]: On master: BEGIN
[0m14:19:22.392919 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:19:22.458555 [debug] [MainThread]: SQL status: BEGIN in 0.065 seconds
[0m14:19:22.459280 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.459870 [debug] [MainThread]: Using postgres connection "master"
[0m14:19:22.460368 [debug] [MainThread]: On master: COMMIT
[0m14:19:22.461050 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:19:22.461451 [debug] [MainThread]: On master: Close
[0m14:19:22.462150 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:19:22.462515 [debug] [MainThread]: Connection 'list_delivery_analytics' was properly closed.
[0m14:19:22.462787 [debug] [MainThread]: Connection 'list_delivery_analytics_analytics' was properly closed.
[0m14:19:22.463122 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.fct_shipments' was properly closed.
[0m14:19:22.463369 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.courier_performance' was properly closed.
[0m14:19:22.463617 [debug] [MainThread]: Connection 'model.dbt_delivery_analytics.daily_shipments_status' was properly closed.
[0m14:19:22.464004 [info ] [MainThread]: 
[0m14:19:22.464644 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.13 seconds (1.13s).
[0m14:19:22.466520 [debug] [MainThread]: Command end result
[0m14:19:22.495829 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\manifest.json
[0m14:19:22.500111 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\semantic_manifest.json
[0m14:19:22.508571 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Korisnik\OneDrive\Desktop\dbt_delivery_analytics\target\run_results.json
[0m14:19:22.509188 [info ] [MainThread]: 
[0m14:19:22.510000 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:19:22.510608 [info ] [MainThread]: 
[0m14:19:22.511290 [error] [MainThread]: [31mFailure in model courier_performance (models\marts\analytics\courier_performance.sql)[0m
[0m14:19:22.511893 [error] [MainThread]:   Database Error in model courier_performance (models\marts\analytics\courier_performance.sql)
  function pg_catalog.extract(unknown, integer) does not exist
  LINE 21:     AVG(EXTRACT(EPOCH FROM (expected_delivery_date - shipmen...
                   ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target\run\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:19:22.512425 [info ] [MainThread]: 
[0m14:19:22.513014 [info ] [MainThread]:   compiled code at target\compiled\dbt_delivery_analytics\models\marts\analytics\courier_performance.sql
[0m14:19:22.513518 [info ] [MainThread]: 
[0m14:19:22.514061 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m14:19:22.515489 [debug] [MainThread]: Command `dbt run` failed at 14:19:22.515359 after 3.11 seconds
[0m14:19:22.515881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215472C43D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021546FE8950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215453FFA80>]}
[0m14:19:22.516251 [debug] [MainThread]: Flushing usage events
[0m14:19:23.673259 [debug] [MainThread]: An error was encountered while trying to flush usage events
